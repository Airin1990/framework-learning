{"./":{"url":"./","title":"关于framework-learning","keywords":"","body":"framework-learning 以下是我在学习Java以及相关生态知识的过程中整理的一些资料，部分参考了网上一些大神的文章。 我把它们都做成Markdown的文章供各位同学参考， 其中一些我也以XMind方式来对相应部分的知识进行梳理总结。 其中没有更新完或待纠正的部分，我会持续更新，各位同学有好的建议也可以issue或pr。 个人能力有限，总结的知识可能不全或有遗漏和错误，敬请各位同学指教。 为了良好的阅读体验，可以移步到本项目的GitBook网页阅读版: framework-learning 网页阅读版的内容与本项目是同步的，请放心阅读。 本人XMind版本: Linux XMind 8 (XMind为Java所写，所以文件应该是通用的) 如果这份资料帮助到了各位同学，还请各位同学点个star(别下次一定呀 =^_^=),非常感谢... 知识点总览: Jdk&Jvm&Juc知识点一览: Jdk&Jvm&Juc Java知识梳理之JDK&JVM&JUC - XMind 关系型数据库常见知识点一览: 关系型数据库常见知识点 Java知识梳理之关系型数据库 - XMind 非关系型数据库常见知识点一览: 非关系型数据库常见知识点 Java知识梳理之非关系型数据库 - XMind 数据结构与算法(更新中) 推荐一个数据结构与算法的可视化网站，希望能够帮到正在学习数据结构与算法的同学: 数据结构与算法可视化 设计模式(更新中) 计算机网络常见知识点一览: 计算机网络常见知识点 Java知识梳理之计算机网络 - XMind Spring框架常见知识点一览: Spring常见知识点 SpringMVC常见知识点和源码分析 SpringBoot常见知识点 Java知识梳理之Spring - XMind ORM常见知识点一览: ORM常见知识点 Java知识梳理之ORM - XMind Tomcat(待纠正) RabbitMQ(更新中) Zookeeper(待纠正) Dubbo(更新中) Swagger(更新中) "},"gitbook_doc/GitBook_Introduction.html":{"url":"gitbook_doc/GitBook_Introduction.html","title":"关于本电子书","keywords":"","body":"关于本电子书 本电子书是为笔者的开源学习资料: framework-learning 提供一个更为良好的阅读环境。 本电子书的内容会与 framework-learning 的内容进行同步，所以请放心阅读。 笔者联系方式: github: guang19 微信: yg1446125917 QQ: 2196927727@qq.com 项目地址: framework-learning 如果您觉得本项目对您有帮助，请不吝star。如果您有对于本项目或本电子书的建议，欢迎issue/pr，非常感谢您的对本项目的支持! "},"gitbook_doc/jdk_jvm_juc-learning/About.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/About.html","title":"jdk_jvm_juc部分","keywords":"","body":"关于本部分 jdk_jvm_juc-learning部分是对jdk_jvm_juc-learning 模块更细分的讲解。 jdk_jvm_juc-learning知识点一览: XMind下载: Java知识梳理之JDK&JVM&JUC - XMind "},"gitbook_doc/jdk_jvm_juc-learning/Java常见基础知识点.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/Java常见基础知识点.html","title":"Java常见基础知识点","keywords":"","body":" java基础知识(部分图源:JavaGuide) 面向对象和面向过程的区别 OracleJdk与OpenJdk的区别 Java与C 的异同 JVM,JDK和JRE的区别 Java语言的特点 面向对象的特征 重载和重写的区别 接口与抽象类的区别 Object类的方法有哪些? 静态属性方法和成员属性方法区别 子类属性与父类属性初始化顺序 自动拆箱和装箱 String为什么不可变? final关键字的作用 StringBuilder和StringBuffer区别 equals知识点 深拷贝与浅拷贝 IO流分类 使用字节流还是字符流? BigDecimal Java异常体系结构 Comparable和Comparator 为什么要慎用 Arrays.asList()? Java中引用的类型 java基础知识(部分图源:JavaGuide) PS:以下部分内容希望各位同学下载openjdk的源码,亲自实践。 openjdk8u: hotspot:hotspot openjdk:jdk 面向对象和面向过程的区别 首先面向过程和面向对象的语言没有具体的性能高下之分,要依据每种语言的设计来做参考. 个人认为面向过程与面向对象的最大区别在于: 面向过程的语言是结构化的,面向对象的语言是模块化的。 模块化比结构化的代码更易于维护,复用与扩展。 OracleJdk与OpenJdk的区别 OpenJdk是基于Sum捐赠的源代码HotPot的,是开源的. OracleJdk是Oracle对Jdk的商业化版本,由Oracle发布并维护. 因此OracleJdk比OpenJdk更可靠。 Java与C++的异同 Java和C++都是基于面向对象思想的语言。 Java不提供指针来访问内存,而C++允许指针访问内: Java不提供指针来访问内存,而C++允许指针访问内存。 垃圾回收机制: Java无需开发者手动释放内存,因为Java有垃圾回收机制。而C++则需要开发者手动释放内存,因此Java比C++在内存管理上相对安全。 Java不支持多继承，而C++支持。 JVM,JDK和JRE的区别 JVM: JVM(java virtual machine)是java虚拟机 JRE: JRE(java runtime environment)是java运行时环境 JDK: JDK(java development kit)是java开发工具包,不仅包含了jre和jvm,还提供了javac编译器和javadoc等其他开发所需的工具 Java语言的特点 面向对象 平台无关性,也就是跨平台(依靠JVM) 支持多线程 支持便捷的网络编程 编译与解释(JIT) 安全(个人认为所有语言写出来的代码的安全性是开发者决定的, 而不是语言本身决定的,语言能决定的只是提供方便或不便的安全的API) 面向对象的特征 面向对象三大特征:封装,继承,多态。 封装: 封装是隐藏对象属性和的实现细节,只对外提供可访问或修改的接口。 封装的目的是为了简化编程和增加程序的安全性,使得使用者无需了解对象的具体实现细节。 继承: 继承是 在已存在的类上定义新的类的技术。 在Java中,已存在的类被称为基类(父类),新的类叫做派生类(子类).子类拥有父类的所有属性,方法。 但是子类对于父类中私有的方法或属性只是拥有,并不能访问和使用。 继承的目的主要是为了代码的复用. 多态: 多态指的是相同类型的对象,调用其相同的方法,参数也相同,但是它的表现形式也就是结果不同。 多态的目的是为了程序的可扩展性和维护性。 在Java中可以使用继承与接口2大特性实现多态。 重载和重写的区别 个人认为重载和重写完全没有可比性,不知道为啥老有人喜欢拿它们做比较。 重载: 重载是描述一个类中的多个方法函数的名字是一样的,但是参数,类型,返回值,顺序都可能不同的。 重写: 重写是描述子类对父类的某个方法的逻辑进行了重新编写,但变的只是方法的内容, 方法名,参数,类型,顺序,返回值都是不变的。 接口与抽象类的区别 接口需要被实现,而抽象类是需要被继承的。 接口里的方法都是公共抽象的，而抽象类既允许抽象也允许非抽象的方法(在jdk8中,接口被允许定义default方法,jdk9中还允许定义private私有方法)。 一个类允许实现多个接口,但只允许继承一个抽象父类。 接口是对类的规范,规范的是行为能力。而抽象类是对类的抽象,抽象的是逻辑。 Object类的方法有哪些? getClass equals hashCode toString wait wait(long): 让当前对象进入TIMED_WATING状态 wait(long,int):让当前对象进入TIMED_WATING状态 notify nofifyAll clone finalize 静态属性方法和成员属性方法区别 静态属性和方法属于类Class,而成员属性和方法属于实例化的对象。 静态方法只能使用静态方法和静态属性,不能使用成员属性和方法, 因为静态属性和方法在对象还没被实例化的时候就存在了。 简单理解就是不允许一个已存在的事物使用一个不存在的事物。 子类属性与父类属性初始化顺序 无论如何,静态数据首先加载,所以先初始化父类静态变量和静态初始化块,再初始化子类静态变量和静态初始化块。 普通初始化块优先于构造方法,所以接下来加载父类的普通代码块,再调用父类构造方法。 调用子类普通代码块和构造方法。 自动拆箱和装箱 自动拆箱和装箱实际上是Java编译器的一个语法糖。 自动装箱是指: 将基本数据类型转为对应的包装类对象的过程。 自动拆箱是指: 将包装类转为对应的基本数据类型。 自动装箱实际上是调用了包装类对象的valueof方法,如: Integer.valueof(1) 自动拆箱实际上是调用了包装类的xxxValue方法,如: Integer.intValue() 在自动装箱的时候,如果包装类允许缓存并且值在缓存的范围内,那么装箱生成的对象会被缓存到常量池中。 Integer,Byte,Short,Long,Character包装类型具有缓存池, 而其他三种:Float,Double,Boolean不具有缓存池。 包装类的缓存池缓存的范围基本都为: -128 - 127之间， 除了Character的缓存范围为 0 - 127。 String为什么不可变? 先说下我的看法:String是Java中最常使用的类没有之一,如果String是可变的,那么会发生非常多数不清的问题。 如ip地址,人名,邮箱非常多的敏感数据,如果String是可变的,那么就会发生安全问题。 如果String是可变的,那么字符串常量池也就无从谈起了。 String是不可变的,那么它本质上也是线程安全的。 不可变类的缺点就是每个不同的值需要创建一个对象 String 是用final修饰的，保证了String类不能被扩展。 String内部的字段是用final修饰的(我的jdk版本是11,String由byte[]实现)， 并且没有对外提供修改字段的方法。这也是为什么String不可变的原理。 final关键字的作用 被final修饰的类，不能被继承，并且这个类所有的成员方法都为final，不能被重写。 被final修饰的属性变量，不能被修改。如果该变量是基本数据类型的，那么其值在初始化后不能被修改。 如果该变量是引用类型的，那么该引用不能再指向其他对象。 被final修饰的方法不能被子类重写。 StringBuilder和StringBuffer区别 StringBuilder和StringBuffer都是可变的字符串,但是StringBuilder是线程不安全的。 StringBuffer是安全的,因此单线程情况下考虑使用StringBuilder,多线程情况下考虑使用StringBuffer。 他们之间的关系就好比HashMap和HashTable的关系。 equals知识点 == 和 equals区别: ==比较的是对象的内存地址,equals比较的是对象的值。 因此在Java中比较2个对象的值是否相等使用equals,判断2个对象是否是一个对象,使用==。 hashCode方法返回的真是对象内存地址吗? 这个已在对象内存布局部分有讲解，此处就不重复写了。 equals方法重写要求 自反性: x.equals(x) == true 永远成立 非空性: x.equals(null) == false 永远成立 对称性: 如果 x.equals(y) == true , 那 y.equals(x)== true 传递性: 如果 x.equals(y) == true,并且 y.equals(z) == true,那么一定满足x.equals(z) == true 一致性: 如果x.equals(y) == true , 那么只要x和y的值不变,那么x.equals(y) == true　永远成立 为什么重写equals方法一定要重写hashcode方法? 在普通环境下(不涉及hash表),equals方法和hashcode方法一毛钱关系没有的, 此时重写equals但不重写hashcode是没有关系的。 但当使用map,set这些散列表时, 它们会根据对象的hashcode来计算对象在散列表中的位置的。 试想下,如果2个对象的值相等,但是由于它们是2个对象,hashcode却不相等。 那么即使放入map,set(map)仍会存在重复数据。 深拷贝与浅拷贝 深拷贝,听名字就知道,拷贝所有的内容,除了基本数据类型的变量复制一份,连引用类型的的对象也复制一份。 浅拷贝,只是复制基本数据类型的变量,对于引用类型的变量,直接返回这个引用本身。 IO流分类 按照流的流向,分为:输入流和输入流。 按照操作单元,分为:字节流和字符流。 使用字节流还是字符流? 考虑通用性,应该使用字节流。 如果只是文本文件的操作,可以考虑使用字符流。 BigDecimal BigDecimal是Java中表示大浮点数的类型。 在Java中,如果遇到浮点数的判断,可以使用BigDecimal来做计算, 因为如果使用普通数据类型很可能会发生精度丢失的情况,这个时候的结果可能会出乎意料之外. Java异常体系结构 在Java中,异常分为 Exception和Error,这2个类都继承自Throwable。 Exception: Exception异常是程序本身可以处理的。Exception 分为运行时异常(RuntimeException)和 非运行时异常(CheckedException)。 RuntimeException: RuntimeException(运行时异常)是在程序运行时可能会发生的异常,如NullPointException, 这类异常往往是不可预料的,编译器也不会要求你手动try catch或throws。 CheckedException: CheckedException(非运行时异常)是RuntimeException以外的异常,如IOException， 这类异常要求必须显示的try catch或throws ， 如果不处理,那么编译就不会通过。 Error: Error错误是程序无法处理的,表示程序出现了无法解决的问题。 Comparable和Comparator Comparable: 自然排序接口。实现了它的类意味着就支持排序。 Comparator: 外部比较器。无需让需要排序的对象实现排序逻辑，而是根据Comparator定义的逻辑来排序。 Comparator相较于Comparable更加的灵活。 为什么要慎用 Arrays.asList()? 因为Arrays.asList这个方法返回的根本就不是我们期盼的ArrayList, 而是Arrays类内部实现的ArrayList,这个内部类只支持访问和set操作, 并不支持remove,add,clear等修改操作。 Java中引用的类型 Java中引用类型总共有四种: 强引用，软引用，弱引用，虚引用。 强引用(Strong Reference): Java程序中绝大部分都是强引用，一般使用new关键字创建的对象就是强引用。 只要强引用存在，强引用的对象就不会被回收，除非不可达(参考jvm部分) 软引用(Soft Reference): 软引用一般不会回收，但是当堆内存不够的时候， 比如几乎快要发生OOM的时候，就会发生回收掉软引用对象。 弱引用(Weak Reference): 只要垃圾回收开始，就会回收掉弱引用的对象 虚引用(Phantom Reference,又称幽灵引用): 和其他几种引用不同，虚引用不决定对象的生命周期， 它在任何时候都可能被回收掉。 "},"gitbook_doc/jdk_jvm_juc-learning/对象在内存中的布局.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/对象在内存中的布局.html","title":"对象在内存中的布局","keywords":"","body":" 对象在内存中的布局(64位) 对象头 markword和metadata 实例数据 对齐填充 jol工具查看对象布局 查看对象内存布局 hashcode 对象的hashcode返回的是对象的内存地址吗? 对象在内存中的布局(64位) 对象在内存中的布局,在32位和64位上的实现也是不同的，以我的机器为例(64位) 对象在内存中由 对象头,实例数据,对齐填充三部分组成。 其中实例数据和对齐填充是不固定的，下面会讲到。 可以使用openjdk-jol工具查看对象的内存布局 对象头 在hotspot虚拟机中的对象头由2部分组成(如果是数组,对象头还会保存数组长度): mark 和 metadata(包括klass* , compressed_klass)(见oop.hpp文件) 下面是mark/markword的组成(见:markOop.hpp头文件): 对象处于每种状态时的锁标志位都不同(见:markOop.hpp头文件): markword和metadata Mark Word(mark)组成: 锁状态 锁标志 markword组成 无锁 01 由hashcode,分代年龄,是否偏向锁(1位),锁标志位组成 偏向锁 01 由偏向线程的ID,偏向时间戳(epoch),是否偏向锁(1位),分代年龄,锁标志位组成 轻量级锁 00 由指向栈中锁的记录和锁标志位组成 膨胀锁 10 由指向锁的指针和锁标志位组成 GC 11 无数据 Klass Pointer / Compressed Klass: Klass Pointer是指向对象类型的指针，指针指向对象的类元数据。 jvm通过klass pointer判断对象属于哪个类。 在64位的jvm实现中，Klass Pointer的长度为64bit(32位系统, 指针为32bit)，也就意味着,64位系统比32位的系统占用更多内存。 所以jvm提供了压缩指针(Compressed Klass)来节省空间，在64位系统下，压缩指针是默认开启的， 可以使用-XX:-UseCompressedOops来关闭指针压缩。 实例数据 实例数据存储着对象在程序中被定义的各个字段的数据,也就是对象的字段的 数据。如果一个类没有字段，也就不存在实例数据，所以这是它不固定的原因。 对齐填充 Java对象的小必须是8字节的倍数,像13,15这种非8的倍数的对象的大小, 不足或多余的部分就要使用对齐填充数据补齐。 如果Java对象大小正好是8的倍数,那么就无需对齐填充数据。 jol工具查看对象布局 org.openjdk.jol jol-core 0.10 相信各位同学可能还是对上面的概念优点迷糊，那就可以使用jol工具来查看一下 对象的真实布局，在实践之前，请各位同学带着几个问题看下面的内容: hashCode方法返回的真是对象内存地址吗? hashcode真实存在吗? 查看对象内存布局 一下是我自己的一个测试demo，详解了jol的使用: 以上可以看到jol工具很直观的给我们展现了对象的内存布局， 但是在对象的markword之中，我们并没有看到hashcode的值， 难道对象不存在hashcode吗？ hashcode 上一个测试在打印对象内存布局之前，我并没有调用对象的hashcode方法， 相信各位同学也注意到了，我把那2行代码注释掉了。 打开那2行注释再运行看看: 我们发现，在调用hashcode方法后，对象的hashcode的值与打印结果完全一致， 到这里可以初步猜想: hashcode的值也是不固定存在的。 在没有调用对象的hashcode方法之前，对象不存在hashcode。 当调用完对象的hashcode之后，jvm就把生成的hashcode值赋予了对象的markword之中。 对象的hashcode返回的是对象的内存地址吗? 在hotspot中，hashcode返回的不完全是地址 (见：hotspot的/src/share/vm/runtime/synchronizer.cpp): 可以看到hashcode有多种返回策略:随机数，自增长序列，关联地址等多种方式。 "},"gitbook_doc/jdk_jvm_juc-learning/Java多线程.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/Java多线程.html","title":"Java多线程","keywords":"","body":" 多线程 进程和线程 并发和并行 多线程的利弊 什么是上下文切换? 线程的优先级 线程的几种状态 sleep方法和wait方法的区别 stop,suspend,resume等方法为什么会被遗弃 interrupt,interrupted,isInterrupted方法区别 join方法 yield方法 多线程 进程和线程 进程与线程最主要的区别是它们是操作系统管理资源的不同方式的体现。 准确来说进程与线程属于衍生关系。 进程是操作系统执行程序的一次过程,在这个过程中可能会产生多个线程。 比如在使用QQ时，有窗口线程， 文字发送的线程，语音输入的线程，可能不是很恰当，但是就是这个意思。 在Java中，一个进程产生的多个线程共享这个进程内的堆，方法区等共享资源， 每个线程又有自己的程序计数器，虚拟机栈，本地方法栈。 由于系统在线程之间的切换比在进程之间的切换更高效率，所以线程也被成为轻量级进程。 并发和并行 并发: 多个线程任务被一个cpu轮流执行。注意，这里并不是规定一个cpu，多个cpu也是可以的。 并发主要强调的是cpu有处理多个任务的能力。 并行:多个线程被多个cpu同时执行。这里也并不是规定要多个cpu，一个cpu也是可以的， 只要你的cpu能在同一时刻处理多任务。并行强调的是拥有同时处理多任务的能力。 多线程的利弊 利:线程可以比作轻量级的进程，现在是多核cpu时代，意味着多个线程可以被通过cpu同时运行(并行)， 这就减少了上下文的开销，如果可以利用好多线程，那么就可以编写出高并发的程序。 弊:虽然线程带来的好处很多，但是并发编程并不容易，如果控制不好线程， 那么就可能造成死锁，资源闲置，内存泄露等问题。 什么是上下文切换? cpu是采用时间片的轮转制度，在多个线程之间来回切换运行的。 当cpu切换到另一个线程的时候，它会先保存当前线程执行的状态， 以便在下次切换回来执行时，可以重新加载状态，继续运行。 从保存状态再到重新加载回状态的这个过程就叫做上下文切换。 线程的优先级 在Java中可以通过Thread类的setPriority方法来设置线程的优先级， 虽然可以通过这样的方式来设置线程的优先级，但是线程执行的先后顺序并不依赖与线程的优先级。 换句话说就是，线程的优先级不保证线程执行的顺序。 线程的几种状态 见:jdk Thread类源码中的state枚举类 NEW,RUNNABLE,BLOCKED,WAITING,TIMED_WAITING,TERMINATED sleep方法和wait方法的区别 sleep方法是Thread类的方法，而wait方法是Object类的方法 sleep方法会使当前线程让出cpu的调度资源，从而让其他线程有获得被执行的机会， 但是并不会让当前线程释放锁对象。 而wait方法是让当前线程释放锁并进入wait状态， 不参与获取锁的争夺，从而让其他等待资源的线程有机会获取锁， 只有当其他线程调用notify或notifyAll方法是，被wait的线程才能重新与其他线程一起争夺资源。 stop,suspend,resume等方法为什么会被遗弃 stop: stop方法被弃用很好理解，因为stop方法是强行终止线程的执行， 不管线程的run方法是否执行完，资源是否释放完，它都会终止线程的运行，并释放锁。 这在设计上就不合理，不说资源控制的问题，当线程正在执行任务的时候，线程突然就被stop了， 这根本上就是不被允许的。 suspend和resume: suspend方法用于阻塞一个线程,但并不释放锁， 而resume方法的作用只是为了恢复被suspend的线程。 假设A，B线程都争抢同一把锁，A线程成功的获得了锁， 然后被suspend阻塞了，却并没有释放锁，它需要其他线程来唤醒， 但此时B线程需要获得这把锁才能唤醒A，所以此时就陷入了死锁。 interrupt,interrupted,isInterrupted方法区别 interrupt: 这个方法并不是中断当前线程，而是给当前线程设置一个中断状态。 isInterrupted: 当线程调用interrupt方法后，线程就有了一个中断状态， 而使用isInterrupted方法就可以检测到线程的中断状态。 interrupted: 这个方法用于清除interrupt方法设置的中断状态。 如果一个线程之前调用了interrupt方法设置了中断状态， 那么interrupted方法就可以清除这个中断状态。 join方法 join方法的作用是让指定线程加入当线程执行。 假如在main方法里面创建一个线程A执行，并调用A的join方法， 那么当前线程就是main，指定的A线程就会在main之前执行， 等A执行完后，才会继续执行main。 public static void main(String[] args) throws Exception { Thread a = new Thread(()-> { try { TimeUnit.SECONDS.sleep(1); }catch (Exception e){} System.out.println(\"thread join\"); }); a.start(); //a会在main线程之前执行 a.join(); System.out.println(\"main\"); } join方法的底层是wait方法，调用A线程(子线程)的join方法实际上是让main线程wait， 等A线程执行完后，才能继续执行后面的代码。 yield方法 yield属于Thread的静态方法， 它的作用是让当前线程让出cpu调度资源。 yield方法其实就和线程的优先级一样，你虽然指定了， 但是最后的结果不由得你说了算， 即使调用了yield方法，最后仍然可能是这个线程先执行， 只不过说别的线程可能先执行的机会稍大一些。 "},"gitbook_doc/jdk_jvm_juc-learning/Java并发.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/Java并发.html","title":"Java并发","keywords":"","body":" 并发 synchronized synchronized底层原理 synchronized 使用方法 Synchronized和ReentrantLock的区别 乐观锁 悲观锁 独占锁 共享锁 公平锁 非公平锁 可重入锁(递归锁) 偏向锁 轻量级锁 自旋锁 自适应自旋锁 锁消除 锁粗化 死锁 如何避免死锁? volatile volatile保证内存的可见性 volatile禁止指令重排序 volatile如何禁止指令重排序的? volatile不保证原子性 CAS CAS在JAVA中的底层实现(Atomic原子类实现) CAS的缺点 解决ABA问题 ThreadLocal ThreadLocal引发的内存泄露: 线程池的好处 线程池构造参数 阿里巴巴开发者手册不建议开发者使用Executors创建线程池 并发 synchronized synchronized是jdk提供的jvm层面的同步机制。 它解决的是多线程之间访问共享资源的同步问题,它保证了 在被它修饰的方法或代码块同一时间只有一个线程执行。 java6之前的synchronized属于重量锁,性能较差, 它的原理是基于操作系统的Mutex Lock互斥量实现的。 因为java线程是映射到操作系统的线程之上的, 所以暂停或唤醒线程都需要Java程序从用户态转换为内核态,这段转换时间消耗较长。 java6之后jvm团队对synchronized做出了非常大的优化。 synchronized底层原理 先看我编写的一段测试代码: 使用 javap -c -v -l 指令反编译 class文件后的 字节码指令 如下 可以清楚的看到,在进入synchronized的时候，底层字节码编译出来的指令为 monitorenter,在执行完同步代码块后又有一个monitorexit指令. 想了解synchronized究竟是如何实现的,可以直接进入openjdk:src/share/vm/runtime 目录, 这个目录存放的是hotspot虚拟机在运行时所需的代码。 可以直接锁定其中的 objectMonitor.cpp源文件和objectMonitor.hpp头文件. 看到这2个文件，相信各位同学应该就知道，这个就是synchronized锁对象的monitor，它也是 一个对象,不过它是一个c++对象(见:objectMonitor.hpp头文件): 其实真正的锁应该是这个monitor,synchronized锁的那个对象起到的只是关联monitor的作用。 只不过我们身在java层面，无法感知到monitor的作用，所以才称synchronized的锁对象为锁。 以下是monitorenter指令执行过程(见 InterpreterRuntime.cpp): PS:本来想真正弄清楚fast_enter(偏向锁的实现),slow_enter(轻量级锁实现)和inflate(膨胀锁实现) 的,无奈暂时看不太懂cpp源码，但是有的地方是可以根据语义来推断的。 这里做一个总结吧,这个总结可能不太准确，但大致是这样的: 每次执行monitorenter指令的时候,是将当前synchronized锁对象 关联的monitor的_recursions加1, 执行monitorexit指令的时候,将当前object对象关联的monitor的_recursions减1, 当_recursions为0的时候，就说明线程不再持有锁对象。 如果熟悉AQS原理的同学就知道在AQS内部， 有一个被volatile修饰state变量， 这个state变量就是AQS的核心， state变量的作用类比到此处就是monitor计数器的作用。 synchronized 使用方法 修饰静态方法: 修饰静态方法是给类加锁,会作用于所有对象,因为静态方法属于类, 而不属于对象,不管有多少个对象,static方法都是共享的。 修饰实例方法: 修饰实例方法是给对象加锁,会作用于当前类的实例对象。 修饰代码块: 修饰代码块,根据代码块给定的对象加锁,线程想要进入代码块,只能获取指定的对象的锁。 Synchronized和ReentrantLock的区别 Synchronized是基于JVM层面的同步机制;而ReentrantLock是基于Java API层面提供的同步机制。 Synchronized和Reentrantlock都属于可重入锁。 ReentrantLock提供了比Synchronized更高级的功能: 公平锁 更方便的线程间的通信(Condition) 等待可中断(在线程等待获取锁的时候可以被中断) 乐观锁 乐观锁对共享的数据很乐观，认为不会发生线程安全的问题，从而不给数据加锁。 乐观锁适用于读多写少的环境。常见的例子就是mysql的更新使用version控制。 CAS属于乐观锁。 悲观锁 悲观锁对共享的数据很悲观，认为无论什么时候都有可能发生线程安全的问题， 所以在每次读写数据的时候都会加锁。 Synchronized属于悲观锁。 独占锁 锁一次只能被一个线程占有使用。 Synchronized和ReetrantLock都是独占锁。 共享锁 锁可以被多个线程持有。 对于ReentrantReadWriteLock而言,它的读锁是共享锁,写锁是独占锁。 公平锁 公平锁指根据线程在队列中的优先级获取锁,比如线程优先加入阻塞队列,那么线程就优先获取锁。 非公平锁 非公平锁指在获取锁的时候,每个线程都会去争抢,并且都有机会获取到锁,无关线程的优先级。 可重入锁(递归锁) 一个线程获取到锁后,如果继续遇到被相同锁修饰的资源,那么可以继续获取该锁。 Synchronized和Reentrantlock都是可重入锁。 偏向锁 在线程获取偏向锁的时候, jvm会判断锁对象MarkWord里偏向线程的ID是否为当前线程ID。 如果是,则说明当前锁对象处于偏向状态。 如果不是,则jvm尝试CAS把对象的MarkWord的偏向线程ID设置为当前线程ID, 如果设置成功,那么对象偏向当前线程，并将当对象的锁标志位改为01。 如果设置失败，则说明多线程竞争，将撤销偏向锁，升级为轻量级锁。 偏向锁适用于单线程无锁竞争环境(单线程环境)。 hotspot偏向锁实现(faster_enter): 轻量级锁 在线程获取对象锁时，jvm首先会判断对象是否为无锁状态(无锁状态标志位为01)。 如果对象是无锁状态，那么将在线程的栈帧中开辟一块空间用于存储对象的MarkWord， 然后将对象的MarkWord复制到栈帧空间去，并使用CAS更新对象的MarkWord为指向 线程栈帧的指针。 如果更新成功，那么当前线程获取锁成功，并修改对象的MarkWord标志位 为 00 。 如果更新失败，那么jvm会判断对象的MarkWord是否已经指向线程的栈帧。 如果已经指向，那么线程直接执行同步代码。否则，说明多个线程竞争，将inflate为重量级锁。 轻量级锁适用于多线程无锁竞争环境(多线程轮流执行,并不会发生冲突)。 hotspot轻量级锁实现(slow_enter): 自旋锁 在争夺锁的过程中，线程不会停止获取锁，而是通过CAS不断的判断线程是否符合获取锁的条件。 AQS获取锁的核心就是CAS。 自适应自旋锁 自旋锁意味着线程会不断的消耗cpu资源，短时间还行，长时间就意味着而资源的浪费。 所以自适应自旋锁会有一个自旋的生命周期,过了这个生命周期,线程将不再自旋。 网上有文章说这个生命周期依据前一个线程的自旋时间来决定，但是我暂且没有找到相关资料，不敢妄自揣测。 锁消除 锁消除属于Java编译器对程序的一种优化机制。 锁消除是指当JVM的JIT编译器检测出一些已经加锁的代码不可能出现共享的数据存在竞争的问题， 会消除这样的锁。锁消除的依据来源于逃逸分析算法。 如果判断到一段代码，在堆上的数据不会逃逸出去被其他线程访问到， 那么就把它们当做栈上的数据，为线程私有的，自然无需同步加锁。 //每次线程进入此方法，创建的都是不同的StringBuffer临时对象, //也就是说 StringBuffer 临时对象不会逃出方法t,作用于外部, //所以根本不存在线程之间的竞争，那么JIT在编译时就会消除append方法的锁 public String t(String s1, String s2,String s3) { return new StringBuffer().append(s1).append(s2) .append(s3).toString(); } 锁粗化 当虚拟机检测出一系列连续的操作都对同一个连续加锁， 那么它会把加锁的返回扩大至整个操作的序列的外部，保证只加锁一次。 public String t() { StringBuffer stringBuffer = new StringBuffer(); for (int i = 0 ; i 死锁 死锁是指多个进程在执行过程中,循环等待彼此占有的资源而导致程序的无限期的阻塞的情况。 产生死锁的条件: 互斥条件: 一个资源在一段时间内只能被一个进程所持有。 不可抢占条件: 进程所持有的资源只能由进程自己主动释放,其他资源的申请者不能向进程持有者抢夺资源。 占有且申请条件: 进程已经持有一个资源后,又申请其他资源,但是其他资源已被其他线程所占有。 循环等待条件: 在条件3之上,进程1有进程2需要申请的资源,进程2有进程1需要申请的资源。那么这2个线程 不停等待彼此持有的资源,又不能释放已拥有的资源,陷入循环等待。 死锁: 如何避免死锁? 只要打破死锁产生的4个条件之一就行,但是真正能够被打破的条件只有第3和第4个条件。 因为第1和第2个条件都是锁的必要条件。 所以有如下解决死锁的方案: 可以打破第3个条件: 实现资源的有序分配。 可以打破第4个条件: 设置等待超时时间。 volatile volatile是JVM提供的轻量级的线程同步机制。它可以保证内存的可见性，禁止指令重排序。 但是volatile，并不能保证数据的原子性，所以它不合适作为线程同步的工具。 volatile保证内存的可见性 可见性是指一个线程的对于共享数据的修改对其他线程是可见的。 jvm的内存模型是: 线程总是从主内存读取变量到工作内存，然后在工作内存中进行修改， 在修改完后再把数据同步到主内存中。 如果多个线程同时读取了一个变量到各自的内存中，其中一个线程对变量进行了修改，并同步回了主内存， 但其它线程仍然使用的是原来的旧值，这就造成了数据的不一致。 解决这个问题的办法就是给变量加上volatile关键字修饰。 volatile使得被它修饰的变量在被线程修改后，那么线程就需要把修改后的变量重新同步到主内存， 且其他线程每次使用这个变量，都需要从主内存读取。 volatile禁止指令重排序 指令重排序是编译器和cpu为了程序的高效运行的一种优化手段, 指令重排序只能保证程序执行的结果是正确的，但是无法保证程序指令运行的顺序是否与代码的顺序一致, volatile就禁止了这种重排序。 比如: 1. int a = 1; 2. int b = 3; 3. int c = a + b; 上面的代码在编译后,指令执行的顺序可能有: 1,2,3和2,1,3 这样程序实际执行的顺序可能与代码的顺序不符,但并不会影响程序最终的结果。 volatile如何禁止指令重排序的? volatile通过提供内存屏障来防止指令重排序。 java内存模型会在每个volatile写操作前后都会插入store指令，将工作内存中的变量同步回主内存。 在每个volatile读操作前后都会插入load指令，从主内存中读取变量。 volatile不保证原子性 比如: i++ 如果是多线程环境下，一个线程读取到i的值到工作内存，然后对i做出自增操作， 然后写回主内存，其它内存才知道i的值被修改了，这个过程本身就不是原子的。 所以不能拿volatile来带替synchronized,如果是多线程环境，仍然需要使用synchronized保证线程同步。 CAS CAS: Compare And Swap 比较成功并交换。 CAS体现的是一种乐观锁的机制。 CAS涉及到3个元素: 指定的内存地址,期盼值和目标值。 它将指定内存地址的值与期盼值相比较，如果比较成功就将内存地址的值修改为目标值。 CAS在JAVA中的底层实现(Atomic原子类实现) CAS在Java中的实现是 juc的atomic包下的Atomicxx原子类。 而这些Atomic原子类的核心是: 类 Unsafe类是个final类，它的核心方法都是native的， 因为Java无法像C/C++一样使用指针来操作内存, Unsafe类就解决了这个问题。 拿incrementAndGet方法来说， Unsafe首先调用getAndAddInt方法, 它会根据当前Atomic的value在内存中地址获取到当前对象的值, 然后再重复一遍此操作，把之前获得的值与第二遍获得的值进行比较， 如果成功，就把内存地址的值更新为新值，否则就do while循环. 并且有个重要的细节就是,Atomic原子类内部的value值都是由volatile修饰的, 这就使得Atomic的值是对其他线程可见的。 CAS的缺点 循环时间开销大: 我在看源码的时候，发现Atomic的CAS操作并没有进行CAS失败的退出处理， 只是单纯的循环比较并交换，这就让我很担心它的性能问题， 如果长时间不成功，那会是很可怕的一件事请，至少cpu的负荷会很大。 只能保证一个共享变量的原子操作: Atomic原子类只能保证一个变量的原子操作， 如果是多数据的话，还是考虑用互斥锁来实现数据的同步吧 ABA问题: ABA问题是指如果一个线程进行CAS操作并成功了，却不代表这个过程就是没有问题的。 假设2个线程读取了同一份数据，线程1修改了这个值并把它改回了原值，并同步到主内存中， 另一个线程准备进行CAS操作,当它发现原值和期盼的值是一样的，那么CAS仍然成功。 解决ABA问题 在juc的atomic包中提供了 AtomicStampedReference 类, 这个类较普通的原子类新增了一个stamp字段，它的作用相当于version。 每次修改这个引用的值，也都会修改stamp的值， 当发现stamp的值与期盼的stamp不一样，也会修改失败. 这就类似于以version实现乐观锁一样。 ThreadLocal ThreadLocal为每个线程都提供了一份相同的变量的副本， 每个线程都可以修改这个副本，但不用担心与其他线程发生数据冲突， 实现了线程之间的数据隔离。 ThreadLocal的原理还得从Thread线程类说起， 每个Thread类内部都有一个ThreadLocalMap，当使用ThreadLocal的get和remove操作的时候， 就是使用每个线程的ThreadLocalMap的get和remove。 ThreadLocal引发的内存泄露: 在ThreadLocalMap中，key是使用弱引用的ThreadLocal存储的。 弱引用是只要垃圾回收器开始回收，无论内存是否充足，都会回收掉弱引用对象，如此一来， 当ThreadLocal被回收掉,那么ThreadLocalMap将可能出现Null Key 的 value。但是也不必太过担心， 因为设计者已经想到了这点，所以ThreadLocal会自动处理key 为 null的 value。 线程池的好处 http连接池，数据库连接池，线程池等都是利用了池化技术。 如果一个资源需要多次使用并且很昂贵，那么使用new创建的对象或资源，可能会带来较大的消耗。 池化技术的好处在于 方便资源的管理，无需显示的使用new创建。 降低了资源的消耗，在池子里的资源可以重复利用 提供了任务的响应速度，任务可以很快的被分配资源进行处理。 线程池构造参数 new ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize: 线程池的核心线程数(常驻线程数),也就是线程池的最小线程数,这部分线程不会被回收. maximumPoolSize: 线程池最大线程数,线程池中允许同时执行的最大线程数量 keepAliveTime: 当线程池中的线程数量超过corePoolSize，但此时没有任务执行， 那么空闲的线程会保持keepAliveTime才会被回收，corePoolSize的线程不会被回收。 unit: KeepAliveTime的时间单位 workQueue: 当线程池中的线程达到了corePoolSize的线程数量， 并仍然有新任务，那么新任务就会被放入workQueue。 threadFactory: 创建工作线程的工厂,也就是如何创建线程的,一般采用默认的 handler: 拒绝策略，当线程池中的工作线程达到了最大数量， 并且阻塞队列也已经满了，那么拒绝策略会决定如何处理新的任务。ThreadPoolExecutor 提供了四种策略: AbortPolicy(是线程池的默认拒绝策略): 如果使用此拒绝策略，那么将对新的任务抛出RejectedExecutionException异常，来拒绝任务。 DiscardPolicy: 如果使用此策略，那么会拒绝执行新的任务，但不会抛出异常。 DiscardOldestPolicy: 如果使用此策略，那么不会拒绝新的任务，但会抛弃阻塞队列中等待最久的那个线程。 CallerRunsPolicy: 如果使用此策略，不会拒绝新的任务，但会让调用者执行线程。 也就是说哪个线程发出的任务，哪个线程执行。 阿里巴巴开发者手册不建议开发者使用Executors创建线程池 newFixedThreadPool和newSingleThreadPoolExecutor都是创建固定线程的线程池, 尽管它们的线程数是固定的，但是它们的阻塞队列的长度却是Integer.MAX_VALUE的,所以， 队列的任务很可能过多，导致OOM。 newCacheThreadPool和newScheduledThreadPool创建出来的线程池的线程数量却是Integer.MAX_VALUE的， 如果任务数量过多,也很可能发生OOM。 "},"gitbook_doc/jdk_jvm_juc-learning/AQS.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/AQS.html","title":"AQS","keywords":"","body":" AQS(AbstractQueuedSynchronizer) AQS概述 AQS的两种共享资源的访问方式 lock,tryLock和lockInterruptibly区别 CountDownLatch Semaphore CycliBarrier ReentrantReadWriteLock如何区分读写锁的? AQS(AbstractQueuedSynchronizer) AQS是Doug Lea大师为JDK编写的一套基于API层面的抽象队列同步器. AbstractQueuedSynchronizer,抽象队列同步器. Lock,CountDownLatch等等这些并发工具都是基于AQS来实现的。 由此可以看出Doug Lea大师的功力已经臻至化境 AQS概述 AQS的核心思想是如果被请求的资源空闲，那么就将当前请求资源的线程设置为有效的工作线程; 如果请求的资源被其他线程所占有， 那么就使用CLH线程阻塞队列来提供阻塞线程并唤线程分配资源的机制。 在CLH队列中，每个请求资源的线程都会被封装成队列中的一个节点。 在AQS内部有一个int类型的state表示线程同步状态， 当线程lock获取到锁后，该state计数就加1,unlock就减1， 这就是为什么解锁次数要对应加锁次数的原因。 AQS主要实现技术为:CLH队列(Craig,Landin and Hagersten)， 自旋CAS，park(阻塞线程)以及unparkSuccessor(唤醒阻塞队列中的后继线程)。 AQS的两种共享资源的访问方式 AQS定义了两种共享资源方式. 独占式(Exclusive): 同一时间只有一个线程可以访问共享资源,也就是独占锁。 如:Synchronized,ReentrantLock。 对于独占式锁的实现,在AQS中对应tryAcquire获取锁和tryRelease释放锁。 共享式(Share): 同一时间允许多个线程同时访问共享资源,也就是共享锁。 CountDownLatch,Semaphore,ReentrantReadWriteLock的ReadLock都是共享锁。 对于共享式锁的实现,在AQS中对应tryAcquireShare获取锁和tryReleaseShare释放锁。 lock,tryLock和lockInterruptibly区别 PS: AQS中的锁计数指的是 state 变量。 lock: 如果线程获取到了锁或线程已经拥有了锁就更改锁计数， 否则线程就加入阻塞队列并一直CAS自旋获取。 tryLock: 线程尝试获取锁，如果线程获取到了锁或线程已经拥有了锁就更改锁计数，否则返回false。 lockInterruptibly: 如果线程在获取锁之前被设置了中断状态，那么当线程获取锁时就会响应中断状态， 抛出InterruptedException异常。如果获取不到就加入阻塞队列并自旋获取，并且阻塞自旋期间还会响应中断， 也就是说在阻塞自旋期间可能抛出InterruptedException异常。 所以lockInterruptibly优先响应中断，而不是优先获取锁。 如果线程获取到了锁或线程已经拥有了锁才更改锁计数。 CountDownLatch CountDownLatch允许count个线程阻塞在一个地方，直至所有线程的任务都执行完毕。 CountDownLatch是共享锁的一种实现,它默认构造AQS的state为count。 当线程使用countDown方法时,其实使用了tryReleaseShared方法以CAS的操作来减少state, 直至state为0就代表所有的线程都调用了countDown方法。 当调用await方法的时候，如果state不为0， 就代表仍然有线程没有调用countDown方法，那么就把已经调用过countDown的线程都放入阻塞队列Park, 并自旋CAS判断state == 0，直至最后一个线程调用了countDown，使得state == 0， 于是阻塞的线程便判断成功，全部往下执行。 Semaphore Semaphore允许一次性最多(不是同时)permits个线程执行任务。 Semaphore与CountDownLatch一样，也是共享锁的一种实现。 它默认构造AQS的state为permits。 当执行任务的线程数量超出permits,那么多余的线程将会被放入阻塞队列Park,并自旋判断state是否大于0。 只有当state大于0的时候，阻塞的线程才有机会继续执行,此时先前执行任务的线程继续执行release方法， release方法使得state的变量会加1，那么自旋的线程便会判断成功。 如此，每次只有不超过permits个的线程能自旋成功，便限制了执行任务线程的数量。 所以这也是我为什么说它可能不是permits个线程同时执行， 因为只要state>0,线程就有机会执行. CycliBarrier CycliBarrier的功能与CountDownLatch相似，但是CountDownLatch的实现是基于AQS的， 而CycliBarrier是基于ReentrantLock(ReentrantLock也属于AQS同步器)和Condition的。 CountDownLatch虽然可以令多个线程阻塞在同一代码处，但只能await一次就不能使用了。 而CycliBarrier有Generation代的概念，一个代，就代表CycliBarrier的一个循环， 这也是CycliBarrier支持重复await的原因。 ReentrantReadWriteLock如何区分读写锁的? Sync既有写锁，又有读锁，因此一个state不够用， 所以使用state的高16为表示读锁，低位16表示写锁. ReentrantReadWriteLock部分源码: static final int SHARED_SHIFT = 16; static final int SHARED_UNIT = (1 >> SHARED_SHIFT; } /** Returns the number of exclusive holds represented in count. */ static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; } 剩下的就读源码吧。 其实吧，在我读了几遍源码后,才发现jdk的源码不算特别不难阅读。 但是像我在读SpringBoot的源码时，我就只能分析个大概。 主要是Jdk的源码之间并没有什么耦合性，你看一个jdk的类，不像Spring的源码那样绕来绕去， 各种设计模式搞得你头晕。 所以我建议阅读源码可以从jdk的源码开始，前提是你需要一定的基础才能看得懂。 比如我这个版本(11)就发现AQS的部分源码与之前版本的源码不同。 这个版本的AQS使用了: VarHandle 这个类来设置Node类内部的属性， 而之前都是直接使用构造方法来构造Node的。 并且AQS使用的是LockSupport来阻塞线程的，LockSupport仍然使用的是Unsafe类来进行操作的, 这些都属于java与c/c++交互的类,所以你如果没有基础，会诧异,jdk还有这种东西呀 ^-^... "},"gitbook_doc/jdk_jvm_juc-learning/Java集合.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/Java集合.html","title":"Java集合","keywords":"","body":" java集合 线程不安全的集合 HashMap的特点 HashMap的长度(容量)为什么要设计成2的幂？ HashTable的特点 TreeMap ArrayList的特点 Vector的特点 LinkedList的特点 Set ConcurrentModificationException异常 线程安全的集合 线程安全的 List CopyOnWriteArrayList 线程安全的Set 线程安全的Map ConcurrentHashMap ConcurrentSkipListMap java集合 线程不安全的集合 HashMap的特点 HashMap在Jdk8之前使用拉链法实现,jdk8之后使用拉链法+红黑树实现。 HashMap是线程不安全的,并允许null key 和 null value。** HashMap在我当前的jdk版本(11)的默认容量为0,在第一次添加元素的时候才初始化容量为 16, 之后才扩容为原来的2倍。 HashMap的扩容是根据 threshold决定的 : threshold = loadfactory * capacity。 当 size 大于 threshold 时,扩容。 当每个桶的元素数量达到默认的阈值TREEIFY_THRESHOLD(8)时,那么这个桶的链表将会转为红黑树。 当红黑树节点的数量低于默认的阈值UNTREEIFY_THRSHOLD(6)时，那么这个桶的红黑树将转为链表 HashMap的长度(容量)为什么要设计成2的幂？ 这就不得不佩服大师们的设计。 想想看，一个对象的hashcode是很大的，当HashMap的容量仅为16,32时， 如何根据hashcode来确定key在数组中的下标。 一个好的办法就是取余: hashcode % length。 这样就能确保，key的下标是永远不会超过数组的长度的。 但是想想，除了取余有没有更好的办法， 当然有: hash % length == hash & (length - 1) 为什么上面这个性能超高的等式成立，当然是有条件的， 只有当length为2的幂的时候这样的等式才成立, 这就明白了为什么使用2的幂来定义HashMap的长度。 HashTable的特点 HashTable底层使用拉链法实现。 HashTable就像Vector一样,也是jdk1就存在的很古老的一个类，它是线程安全的， 实现线程安全的手段是使用synchronized。 HashTable的默认容量为16，每次扩容为原来的2倍+1。 HashTable不允许null key 和 null value。 TreeMap TreeMap使用红黑树实现,不允许null key,允许自然排序Comparable和比较器Comparator排序。 ArrayList的特点 ArrayList底层使用Object数组实现。 ArrayList的容量默认为0,只有在第一次执行add操作时才会初始化容量为10。 由于ArrayList采用数组实现,它的容量是固定的,所以当添加新元素的时候,如果超出了数组的容量, 那么此时add操作的时间复杂度将会是O(n-1)。 ArrayList实现了RandomAccess接口，该接口没有具体的规范，只是一个标记， 这代表ArrayList支持快速的随机访问。 ArrayList在内存空间利用率上肯定是不如LinkedList的， 因为数组是一片固定的连续的内存空间，一旦分配就无法改变， 所以难免会有空间不足或空间使用率很低的情况。 Vector的特点 ArrayList是线程不安全的，Vector是线程安全的， 但Vector实现线程安全的手段是synchronized。这就好比HashMap与HashTable的区别。 Vector默认容量为10。 Vector是当它的扩容增量大于0时，会扩容为原来的容量+扩容增量，否则扩容为原来的2倍。 LinkedList的特点 LinkedList底层使用双向链表实现。 LinkedList的add操作只需要改变尾节点的引用就行了。 但是如果需要在指定位置进行add操作的话，那么时间复杂度也是比较高的,为O(n)， 因为需要从头节点或尾节点遍历到需要操作的节点。 LinkedList的空间利用率虽然很高，但是它的每个Node可以说也是占用了较大空间的， 因为每个Node需要保存它的前继和后继节点。 ps: 双向链表与双向循环链表的区别: 双向链表:每个Node都保存了前后2个节点的引用，双向链表的first节点的前一个节点为null, last节点的后一个节点为null。 双向循环链表: 每个Node都保存了前后2个节点的引用， 双向循环链表的first节点的前一个节点指向last节点， last节点的最后一个节点指向first节点。 Set 为啥不单独说HashSet，我目前看到的JDK所有的Set,都是使用Map实现的, 除了CopyOnWriteArraySet(底层是CopyOnWriteArrayList)。 TreeSet --> TreeMap LinkedHashSet --> LinkedHashMap HashSet --> HashMap ConcurrentSkipListSet --> ConcurrentSkipListMap Set是如何保证元素不会重复,这个得看各自Map的实现了。 拿HashMap来讲，它就是先判断key的hashcode是否相等，然后才使用equals判断2个对象是否相等。 ConcurrentModificationException异常 ConcurrentModificationException可以从名字看出是并发修改的异常。 但我要说的是这个异并不是在修改的时候会抛出的，而是在调用迭代器遍历集合的时候才会抛出。 而集合类的大部分toString方法，都是使用迭代器遍历的。所以如果多线程修改集合后， 接着就遍历集合，那么很有可能会抛出ConcurrentModificationException。 在ArrayList，HashMap等非线程安全的集合内部都有一个modCount变量， 这个变量是在集合被修改时(删除，新增)，都会被修改。 如果是多线程对同一个集合做出修改操作，就可能会造成modCount与实际的操作次数不符， 那么最终在调用集合的迭代方法时，modCount与预期expectedModeCount比较， expectedModCount是在迭代器初始化时使用modCount赋值的， 如果发现modCount与expectedModeCount不一致，就说明在使用迭代器遍历集合期间， 有其他线程对集合进行了修改,所以就会抛出ConcurrentModificationException异常。 线程安全的集合 线程安全的 List 使用集合工具类Collections的 synchronizedList把普通的List转为线程安全的List.(不推荐) 使用Vector.(不推荐) 使用CopyOnWriteArrayList,推荐使用此种方法，因为以上2种全部都是单纯的Synchronized加锁. CopyOnWriteArrayList CopyOnWriteArrayList是线程安全的ArrayList，可以被称为写时复制的ArrayList。 CopyOnWriteArrayList底层仍然使用数组实现， 但是它的修改操作(增删改)采用synchronized关键字保证并发的安全性， 然后在进行修改的时候复制原来的数组到一个新副本，对新副本进行修改，修改完后再设置原数组。 这样就不会让写操作影响读操作了。 但是CopyOnWriteArrayList不容忽视的缺点就是修改操作比较消耗内存空间，所以它适用于读多写少的环境。 线程安全的Set 使用集合工具类的Collections的synchronizedSet把普通的set转为线程安全的set(不推荐) 使用CopyOnWriteArraySet,此set适用于读多写少的情况，它的底层采用CopyOnWriteArrayList实现. 使用ConcurrentSkipListSet，底层采用ConcurrentSkipListMap实现 线程安全的Map 使用集合工具类Collections的synchronizedMap把普通map转为线程安全的map(不推荐) HashTable(不推荐) 使用ConcurrentHashMap(常用) ConcurrentSkipListMap(跳表map,推荐) ConcurrentHashMap ConcurrentHashMap使用数组+链表/红黑树实现,其扩容机制与HashMap一样。 但是ConcurrentHashMap控制并发的方法改为了CAS+synchronized, synchronized锁的只是链表的首节点或红黑树的首节点。 PS:我只看了常用的put,get,remove等核心方法的源码. 整个ConcurrentHashMap的实现用\"复杂\"来形容一点也不为过, 你只要想到它内部有52个内部类就知道有多复杂了,但如果不考虑并发CAS这部分， ConcurrentHashMap和普通的HashMap的差别是不大的。 ConcurrentSkipListMap ConcurrentSkipListMap是基于跳表这种数据结构实现的。 跳表比较特殊，它由多个层次的链表组成，每层链表又有多个索引节点连接， 每层链表的元素也都是有序的。处于上层索引的链表都是下层链表的子集。 跳表与普通链表相比查找元素的效率更高。 "},"gitbook_doc/jdk_jvm_juc-learning/IO.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/IO.html","title":"IO","keywords":"","body":" Java IO 操作系统的用户态与内核态 操作系统的内核 用户态切换到内核态的几种方式 阻塞和非阻塞 同步与异步 Linux IO模型 阻塞IO 非阻塞IO(网络IO模型) 多路复用IO(网络IO模型) 信号驱动IO(网络IO模型) 异步IO Java IO IO图源: 简书 (如有侵权,请联系俺,俺会立刻删除) 操作系统的用户态与内核态 unix与linux的体系架构：分为用户态与内核态. 个人理解:用户态与内核态是操作系统对执行权限进行分级的不同的运行模式。 操作系统的内核 操作系统的内核是操作系统的核心部分。 它负责管理系统的进程，设备(硬件)驱动程序，文件，内存，网络等部分。 内核态(核心态,特权态): 内核态是操作系统内核运行的模式。 内核态控制计算机的硬件资源,并为上层应用程序提供执行环境。 用户态: 用户态是应用程序的活动空间,也是应用程序运行的模式。 应用程序的执行必须依托于内核态,因此用户态的态的操作权限比内核态是要低的， 如磁盘，cpu等，访问操作都是受限的。 系统调用: 系统调用是内核为上层应用程序提供能够访问到内核态的资源的接口。 用户态切换到内核态的几种方式 系统调用: 系统调用是用户态主动要求切换到内核态的一种方式， 用户应用程序通过操作系统调用内核为上层应用程序开放的接口来执行程序。 异常: 当cpu在执行用户态的应用程序时，发生了某些不可知的异常。 于是当前用户态的应用进程切换到处理此异常的内核的程序中去。 外围设备的中断: 当外围设备完成用户请求后，会向cpu发出相应的中断信号， 这时cpu会暂停执行下一条即将要执行的指令，转而去执行与中断信号对应的应用程序， 如果先前执行的指令是用户态下的程序，那么这个转换过程也是用户态到内核台的转换。 比如硬盘读写完成，系统内核会从硬盘的读写状态切换到硬盘读写的中断处理程序中。 阻塞和非阻塞 阻塞: 一个线程调用一个方法计算 1 - 100 的和，如果该方法没有返回， 那么调用的线程就一直等待该方法返回，不继续往下执行。 非阻塞: 一个线程调用一个方法计算 1 - 100的和，如果该方法没有返回， 调用者线程也无需一直等待该方法返回，可以执行其他任务，但是线程仍然需要不断检查方法是否返回。 结论: 阻塞与非阻塞针对调用者的立场而言。 同步与异步 同步: 一个线程调用一个方法计算 1 - 100 的和，如果方法没有计算完，就不返回。 异步: 一个线程调用一个方法计算 1 - 100 的和，该方法立刻返回，但是由于方法没有返回结果， 所以就需要被调用的这个方法来通知调用线程 1 - 100的结果， 或者线程在调用方法的时候指定一个回调函数来告诉被调用的方法执行完后就执行回调函数。 结论:同步和异步是针对被调用者的立场而言的。 Linux IO模型 Linux下共有5种IO模型: 阻塞IO 非阻塞IO 多路复用IO 信号驱动IO 异步IO 阻塞IO 阻塞IO是很常见的一种IO模型。 在这种模型中，用户态的应用程序会执行一个操作系统的调用， 检查内核的数据是否准备好。如果内核的数据已经准备好， 就把数据复制到用户应用进程。如果内核没有准备好数据， 那么用户应用进程(线程)就阻塞，直到内核准备好数据并把数据从 内核复制到用户应用进程， 最后应用程序再处理数据。 阻塞IO是同步阻塞的。 阻塞IO的同步体现在: 内核只有准备好数据并把数据复制到用户应用进程才会返回。 阻塞IO的阻塞体现在:用户应用进程等待内核准备数据和把数据从用户态拷贝到内核态的这2段时间。 当然,如果是本地磁盘IO,内核准备数据的时间可能会很短。 但网络IO就不一样了，因为服务端不知道客户端何时发送数据， 内核就仍需要等待socket数据，时间就可能会很长。 阻塞IO的优点是对于数据是能够保证无延时的，因为应用程序进程会一直阻塞直到IO完成。 但应用程序的阻塞就意味着应用程序进程无法执行其他任务， 这会大大降低程序性能。一个不太可行的办法是为每个客户端socket都分配一个线程， 这样就会提升server处理请求的能力。不过操作系统的线程资源是有限的， 如果请求过多，可能造成线程资源耗尽，系统卡死等后果。 非阻塞IO(网络IO模型) 在非阻塞IO模型中，用户态的应用程序也会执行一个操作系统的调用， 检查内核的数据是否准备完成。如果内核没有准备好数据, 内核会立刻返回结果,用户应用进程不用一直阻塞等待内核准备数据， 而是可以执行其他任务,但仍需要不断的向内核发起系统调用，检测数据是否准备好， 这个过程就叫轮询。 轮询直到内核准备好数据，然后内核把数据拷贝到用户应用进程， 再进行数据处理。 非阻塞IO的非阻塞体现在: 用户应用进程不用阻塞在对内核的系统调用上 非阻塞IO的优点在于用户应用进程在轮询阶段可以执行其它任务。 但这也是它的缺点，轮询就代表着用户应用进程不是时刻都会发起系统调用。 可能数据准备好了，而用户应用进程可能等待其它任务执行完毕才会发起系统调用， 这就意味着数据可能会被延时获取。 多路复用IO(网络IO模型) 在多路复用IO模型中,用户应用进程会调用操作系统的select/poll/epoll函数, 它会使内核同步的轮询指定的socket， (在NIO,socket就是注册到Selector上的SocketChannel,可以允许多个) 直至监听的socket有数据可读或可写，select/poll/epoll函数才会返回, 用户应用进程也会阻塞的等待select/poll/epoll函数返回。 当select/poll/epoll函数返回后，即某个socket有事件发生了，用户应用进程就会 发起系统调用，处理事件，将socket数据复制到用户进程内，然后进行数据处理。 多路复用IO模型是同步阻塞的 多路复用IO模型的同步体现在: select函数只有监听到某个socket有事件才会返回。 多路复用IO模型的阻塞体现在: 用户应用进程会阻塞在对select函数上的调用上。 多路复用IO的优点在于内核可以处理多个socket， 相当于一个用户进程(线程)就可以处理多个socket连接。 这样不仅降低了系统的开销，并且对于需要高并发的应用是非常有利的。 而非阻塞IO和阻塞IO的一个用户应用进程只能处理一个socket， 要想处理多socket，只能新开进程或线程，但这样很消耗系统资源。 PS: 在多路复用IO模型中, socket一般应该为非阻塞的， 这就是Java中NIO被称为非阻塞IO的原因。 但实际上NIO属于多路复用IO，它是同步阻塞的IO。 具体原因见 知乎讨论 PS: select/poll/epoll函数是多路复用IO模型的基础，所以如果想 深入了解多路复用IO模型，就需要了解这3个函数以及它们的优缺点。 信号驱动IO(网络IO模型) 在信号驱动IO模型中，用户应用进程发起sigaction系统调用,内核收到并立即返回。 用户应用进程可以继续执行其他任务，不会阻塞。当内核准备好数据后向用户应用进程 发送SIGIO信号，应用进程收到信号后，发起系统调用， 将数据从内核拷贝到用户进程， 然后进行数据处理。 个人感觉在内核收到信号就立刻返回这一点很像异步IO的方式了，不过 与异步IO仍有很大差别。 异步IO 在异步IO模型中，用户进程发起aio_read系统调用，无论内核的数据是否准备好， 都会立即返回。用户应用进程不会阻塞,可以继续执行其他任务。当内核准备好数据, 会直接把数据复制到用户应用进程。最后内核会通知用户应用进程IO完成。 异步IO的异步体现在:内核不用等待数据准备好就立刻返回， 所以内核肯定需要在IO完成后通知用户应用进程。 弄清楚了阻塞与非阻塞，同步与异步和上面5种IO模型，相信再看 Java中的IO模型，也只是换汤不换药。 BIO : 阻塞IO NIO : 多路复用IO AIO : 异步IO 本来打算写Java中的IO模型的，发现上面几乎讲完了(剩API使用吧)，没啥要写的了， 所以暂时就这样吧。如果各位同学有好的建议，欢迎pr或issue。 PS: 我此处写的IO模型大部分是借鉴于网上的资料，如有错误，请各位同学指出。 "},"gitbook_doc/jdk_jvm_juc-learning/JVM.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/JVM.html","title":"JVM","keywords":"","body":" JVM JVM运行时内存分区 程序计数器 程序计数器的特点 Java虚拟机栈 栈帧 局部变量表 操作数栈 动态连接 方法出口 本地方法栈 堆 方法区 JavaVirtualMachineError StackOverflowError OutOfMemoryError JVM JVM部分参考了《深入理解Java虚拟机》(周志明) 个人认为《深入理解Java虚拟机》上的部分内容已经过时 有些知识请各位同学明鉴 JVM运行时内存分区 以HotSpot为例: JDK8之前: 线程私有的部分有:程序计数器(PC寄存器),JAVA虚拟机栈,本地方法栈(native)。 线程共享部分有: GC堆,永久代(是方法区的一种实现)。 JDK8之后: -线程私有的部分不变, 线程共享部分的永久代改为了元空间(MetaSpace) (永久代和元空间都是方法区的实现),字符串常量池也移动到了heap空间 程序计数器 程序计数器是一块较小的内存空间，它的作用是作为当前线程执行的字节码的行号计数器。 当字节码解释器工作时，通过改变行号计数器的值来选取下一条要执行的字节码指令。 分支，循环，跳转，异常处理，线程恢复等功能都需要依赖程序计数器完成。 程序计数器是属于线程私有的部分。 当cpu在多个线程之间切换执行时，需要记录下当前线程执行的字节码的位置， 以便下次切换回当前线程时，能够继续执行字节码指令， 所以每个线程都需要有自己的程序计数器。 程序计数器的特点 如果当前线程执行的是java方法，那么程序计数器记录的是字节码指令的地址。 如果当前线程执行的native方法，那么程序计数器记录的值为空(undefined)。 程序计数器这部分内存区域是JVM中唯一不会出现OOM错误的区域 程序计数器的生命周期与线程相同,即程序计数器随着线程创建而创建， 随着线程的销毁而销毁。 使用 javap -c 反编译class文件后的代码如下, 红框里的就是字节码的偏移地址: Java虚拟机栈 Java虚拟机栈与程序计数器一样，都是线程私有的部分，生命周期也跟线程一样。 Java虚拟机栈描述的是Java方法运行时的内存模型，它由一个一个的栈帧组成。 栈帧 栈帧是用于支持Java方法运行时的数据结构。 栈帧包含了局部变量表，操作数栈，动态连接，方法出口等信息。 每个方法执行时，都会在java虚拟机栈中创建一个栈帧。 对方法的调用和返回，就对应着栈帧的入栈和出栈的过程。 Java虚拟机栈: 局部变量表 局部变量表用于存储方法参数和方法内定义的局部变量。 局部变量表存放了各种已知的数据类型的变量。 一个局部变量的类型可以是基本数据类型 (int,short,float,double,boolean,long,byte,char)或引用类型(reference)。 在Java代码被编译成class字节码后，方法Code属性的locals就确定了方法的局部变量表的大小。 局部变量表以slot为最小单位，一个slot代表4个字节，也就是32位长度的大小。 操作数栈 操作数栈是一个后进先出(LIFO)的数据结构。 它存储的是方法在进行数据运算时的元素。 和局部变量表一样，操作数栈的每个元素的类型也可以是基本数据类型和引用类型。 操作数栈的深度不会超过 Code属性的stack值。 使用javap -c 反编译class文件后可以得到的字节码指令如下: 动态连接 了解动态连接首先需要了解符号引用和直接引用 符号引用: 符号引用存于Class文件常量池。分为类的全限定名，方法名和描述符，字段名和描述符。 直接引用: 指向目标的指针，可以简单理解为目标的内存地址(如指向类的字段的内存地址)。 Class文件常量池如下(javap -c 反编译class文件后的字节码): 在虚拟机栈中，每个栈帧都包含了一个该栈帧所属方法的符号引用， 持有这个符号引用的目的是为了支持方法调用过程中的动态连接。 这些符号引用有的一部分会在JVM类解析阶段就会转为直接引用，这部分转换成为静态解析。 还有一部分会在运行时转为直接引用，这部分称为动态连接。 方法出口 当方法执行时，有2种方式可以退出该方法。 正常退出: 当方法执行时，执行到return指令，该方法就会正常退出。 一般来说，方法正常退出时，调用线程的程序计数器的值可以作为方法返回的地址， 栈帧中可能会保存这个计数器的值。 异常退出: 在方法执行过程中遇到了异常，并且方法内部没有处理这个异常，就会导致方法退出。 方法异常退出时，返回地址需要通过异常处理器表来确定的，栈帧中不会保存这部分值。 无论何种退出方式，在方法退出后，都需要回到方法被调用的位置，程序才能继续执行。 本地方法栈 本地方法栈与虚拟机栈的作用是相似的， 不过虚拟机栈是为执行Java方法提供服务的， 本地方法栈视为执行native方法提供服务的。 在本地方法执行的时候，也会在本地方法栈中创建栈帧， 用于存放该本地方法的局部变量表，操作数栈，动态连接和方法返回地址等信息。 堆 堆是JVM中内存占用最大的一块区域，它是所有线程共享的一块区域。 堆的作用是为对象分配内存并存储和回收它们。 堆是垃圾回收的主要区域，所以堆区也被成为GC堆。 堆区可以划分为 新生代(Young Generation),老年代(Old Generation) 和 永久代(Permanent Generation),但永久代已被元空间代替, 元空间存储的是类的元信息，几乎不可能发生GC。 新生代再细分可以分为: Eden空间，From Survivor空间和To Survivor空间。 缺省状态下新生代占堆区的 1/3,老年代占堆区的2/3， eden空间占新生代的80%,2个Survivor空间栈新生代的20%, FromSurvivor和ToSurvivor的空间占比为1:1。 (通过-XX:NewRatio参数可以调整新生代和老年代的空间占比) (通过-XX:SurvivorRatio参数可以调整eden和survivor的空间占比) 发生在新生代的GC叫做Young GC或Minor GC, 发生在老年代的GC叫做Old GC或Major GC 堆: PS: FromSurvivor和ToSurvivor这两块内存空间并不是固定的， 在进行GC的时候，这两块内存会轮流替换使用。这部分内容参考GC部分。 PS: 有的文章说 Full GC与Major GC一样是属于对老年代的GC， 也有的文章说 Full GC 是对整个堆区的GC，所以这点需要各位同学自行分辨Full GC语义。 见: 知乎讨论 方法区 方法区在JVM规范里也是各个线程共享的一部分区域， 它用于存储已被jvm加载的类的元信息，运行时常量池等数据。 HotSpot虚拟机对于方法区的实现在jdk8之前为永久代，在jdk8之后， HotSpot移除了永久代，新增了元空间。 元空间使用的是本地内存，所以元空间仅受本地物理内存的限制。 元空间存储着已被加载的类的方法描述，字段描述，运行时常量池等信息。 字符串常量池在jdk7已经从永久代转移到了堆内存之中。 方法区在逻辑上是属于堆区的。在jdk8之前，堆区在GC时会回收永久代。 但jdk8之后的元空间归属于物理内存，存储的都是常量，几乎不会发生GC。 无论是永久代还是元空间，都有可能发生OOM。 JavaVirtualMachineError StackOverflowError 当前线程执行或请求的栈的大小超过了Java 虚拟机栈的最大空间(比如递归嵌套调用太深),就可能出现StackOverflowError错误 OutOfMemoryError 发生OOM的情况: java heap space 当需要为对象分配内存时，堆空间占用已经达到最大值， 无法继续为对象分配内存，可能会出现OOM: java heap space错误。 GC overhead limit exceed 垃圾回收器花费了很长时间GC,但是GC回收的内存非常少, 就可能抛出OOM:GC overhead limit exceed 错误。 但是这点在我的机器上测试不出来,可能与jdk版本或gc收集器或Xmx分配内存的大小有关, 一直抛出的是java heap space Direct buffer memory 当程序分配了超额的本地物理内存(native memory/ direct buffer)， minor gc(young gc)并不会回收这部分内存， 只有 full gc才会回收直接内存，如果不发生full gc， 但直接内存却被使用完了，那么可能会发生 OOM: Direct buffer memory。 unable to create new native thread 操作系统的线程资源是有限的， 如果程序创建的线程资源太多(无需超过平台限制的线程资源上限)， 就可能发生 OOM: unable to create new native thread 错误。 Metaspace 当加载到元空间中的类的信息太多，就有可能导致 OOM : Metaspace。 PS: 使用cglib的库，可以动态生成class， 所以可以使用cglib测试此错误(Metaspace) "},"gitbook_doc/jdk_jvm_juc-learning/简单了解类文件结构.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/简单了解类文件结构.html","title":"简单了解类文件结构","keywords":"","body":"简单了解类文件结构 Class文件结构如下: 使用vim -b filename 以二进制模式编辑class文件， 然后输入 :%!xxd 即可查看十六进制的Class文件,如下: 当然，最直观的方法是对 class 文件使用 javap -c命令进行详细查看。 "},"gitbook_doc/jdk_jvm_juc-learning/类的生命周期.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/类的生命周期.html","title":"类的生命周期(类加载)","keywords":"","body":" 类的生命周期 类加载过程 加载 连接 初始化 使用 类的卸载 Java中类加载器有多少个 类加载器的命名空间 双亲委派机制 为什么需要双亲委派机制? 双亲委派机制的实现原理? 类的生命周期 当java源代码文件被javac编译成class文件后，并不能直接运行， 而是需要经过加载，连接和初始化这几个阶段后才能使用。 在使用完类或JVM被销毁后，JVM会将类卸载掉。 类加载过程 类加载过程需要经过3个阶段: 加载 连接 初始化 其中连接又可分为3个阶段: 验证 ， 准备 ， 解析。 加载 在加载阶段，类加载器将类的class文件的二进制数据读取到内存， 并保存到方法区，并在堆区生成该类的Class对象。 通常有多种方式可以获取类的二进制数据: 通过javac编译器编译java源文件，读取在本地磁盘上生成的class文件。 从Jar，ZIP等归档文件中读取class文件。 通过网络读取类的字节流。 通过动态生成字节码的技术(如使用动态代理，cglib)来生成class。 PS:数组由数组元素的类型的类加载器在java程序运行时加载，这是ClassLoader类的部分注释: 见: 测试 连接 1.验证 验证阶段是为了确保类的字节流符合虚拟机规范，并且不会对虚拟机造成恶意损害。 JVM会对字节流进行如下验证: 文件格式验证:会验证class文件是否符合虚拟机规范，如是否以0×CAFEBABE开头， 主次版本号是否在虚拟机规定范围类，常量池中的类型是否有JVM不支持的类型。 元数据验证: 会对类的元信息进行语义分析，确保符合Java语法规范。 字节码验证: 通过分析数据流和控制流，确保类的方法体的程序语义是合法的， 符合逻辑的。 符号引用验证: 确保常量池中的符号引用能在解析阶段正常解析。 2.准备: 准备阶段会为类的静态变量初始化零值，如(0,0L,null,false). 3.解析: 解析阶段会将常量池中的符号引用转为直接引用。 符号引用包括类的全限定名，方法名和描述符，字段名和描述符。直接引用是指向目标的指针，可以简单理解为目标的内存地址。 初始化 初始化阶段是类加载过程的最后一个阶段。 在这个阶段,只有主动使用类才会初始化类，总共有8种情况会涉及到主动使用类。 当jvm执行new指令时会初始化类。即当程序创建一个类的实例对象。 当jvm执行getstatic指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量归属于运行时常量池)。 当jvm执行putstatic指令时会初始化类。即程序给类的静态变量赋值。 当jvm执行invokestatic指令时会初始化类。即程序调用类的静态方法。 当使用反射主动调用这个类时,也会初始化类,如Class.forname(\"...\"),newInstance()等等。 当初始化一个子类的时候，会先初始化这个子类的所有父类，然后才会初始化这个子类。 当一个类是启动类时，即这个类拥有main方法，那么jvm会首先初始化这个类。 MethodHandle和VarHandle可以看作是轻量级的反射调用机制，而要想使用这2个调用， 就必须先使用findStatic/findStaticVarHandle来初始化要调用的类。 PS:见:测试 使用 在类被初始化完成后，就可以使用类了。 类的卸载 类被卸载(Class对象被GC掉)需要满足3个条件: 该类的实例对象都已被GC，也就是说堆中不存在该类的实例对象。 该类没有在其它任何地方被使用。 加载该类的类加载器实例已被GC。 在JVM的生命周期中，被JVM自带的类加载器所加载的类是不会被卸载的。 而被我们自定义的类加载器所加载的类是可能会被卸载的。 其实只要想通一点就好了，jdk自带的BootstrapClassLoader， PlatformClassLoader和AppClassLoader负责加载jdk提供的类， 它们(类加载器)的实例肯定不会被回收，其中BootstrapClassLoader在java中更是不能被获取到。 而我们自定义的类加载器的实例是可以被GC掉的， 所以被我们自定义类加载器加载的类是可以被GC掉的。 PS:使用-XX:+TraceClassUnloading 或 -Xlog:class+unload=info可以打印类卸载的信息。 Java中类加载器有多少个 BootstrapClassLoader(用于加载Java基础核心类库。由c/c++编写，Java获取不到)。 PlatformClassLoader (jdk9之后才有此类加载器，jdk8之前是扩展加载器ExtensionClassLoader 。PlatformClassLoader加载平台相关的模块，ExtensionClassLoader加载jdk扩展的模块)。 AppClassLoader。(应用程序类加载器，负责加载我们程序的classpath下的jar和类)。 自定义类加载器。 类加载器的命名空间 每个类加载器实例都有自己的命名空间，命名空间由该加载器及其所有父加载器加载的所有的类组成。 在同一个命名空间中(一个类加载器实例)，不会出现全限定名(包括包名)相同的2个类(不会加载2个相同名称的类)。 在不同的命名空间中(多个类加载器实例)，可能会出现全限定名(包括包名)相同的2个类(可能加载2个相同名称的类)。 PS:见:测试 双亲委派机制 为什么需要双亲委派机制? 双亲委派机制是为了防止类被重复加载，避免核心API遭到恶意破坏。 如Object类，它由BootstrapClassLoader在JVM启动时加载。 如果没有双亲委派机制，那么Object类就可以被重写，其带来的后果将无法想象。 双亲委派机制的实现原理? 每个类都有其对应的类加载器。 双亲委派机制是指在加载一个类的时候，JVM会判断这个类是否已经被其类加载器加载过了。 如果已经加载过了，那么直接返回这个类。 如果没有加载，就使用这个类对应的加载器的父类加载器判断， 一层一层的往上判断，最终会由BootstrapClassLoader判断。 如果BootstrapClassLoader判断都没有加载这个类, 那么就由BootstrapClassLoader尝试加载。 如果BootstrapClassLoader加载失败了， 就由BootstrapClassLoader的子类加载器们加载。 在jdk9之后，由于模块化的到来，双亲委派机制也变化了一点: 如果类没有被加载，那么会根据类名找到这个类的模块。 如果找到了这个类的模块， 就由这个类的模块加载，否则仍然使用父类加载器加载。 可以看出:在加载一个类时，是由下自上判断类是否被加载的。如果类没有被加载， 就由上自下尝试加载类。 "},"gitbook_doc/jdk_jvm_juc-learning/JVM常量池.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/JVM常量池.html","title":"JVM常量池","keywords":"","body":" JVM常量池 Class常量池(静态常量池) 运行时常量池 字符串常量池(全局常量池) 包装类型缓存池 JVM常量池 Jvm常量池分为: Class常量池(静态常量池) 运行时常量池 字符串常量池(全局常量池) 包装类型缓存池 Class常量池(静态常量池) 当Java源文件被编译后，就会生成Class字节码文件。 Class常量池就存在于Class文件中(Class文件的Constant Pool中)。 Class文件常量池主要存放两大常量:字面量和符号引用。 字面量: 字面量分为文本字符串(如: \"abc\",1等)和用final修饰的成员变量(实例变量和静态变量) 符号引用: 符号引用包括三种：类的全限定名，方法名和描述符，字段名和描述符。 运行时常量池 运行是常量池是在类加载阶段，将class二进制数据加载到内存， 并将数据保存到方法区,其中class文件中的常量池将保存到 运行时常量池(数据都在方法区，常量池肯定也在方法区)。 也就是说一个Class文件常量池对应一个运行时常量池。 字符串常量池(全局常量池) 字符串常量池在jdk7之前都是存于永久代(永久代)之中,jdk7以后存于 堆区之中。 包装类型缓存池 包装类缓存池并不是所有的包装类都有，并且缓存池缓存的是一定范围内的数据。 拥有包装类型缓存池的类有:Integer,Byte,Character,Long,Short， 而Float，Double，Boolean都不具有缓存池。 包装类的缓存池缓存的范围基本都为: -128 - 127之间， Character的缓存范围为 0 - 127。 "},"gitbook_doc/jdk_jvm_juc-learning/GC.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/GC.html","title":"GC","keywords":"","body":" GC 判断对象存活的方法 引用计数法缺点 什么是GC Root ? 垃圾回收算法 复制算法(Copying) 标记-清除算法(Mark-Sweep) 标记-整理算法(Mark-Compact) 分代收集算法 内存分配与垃圾回收策略 一次GC的过程 动态年龄阈值 垃圾回收器 Serial串行收集器 Serial Old 串行收集器(老年代版本) Parallel Scavenge 并行多线程收集器 Parallel Old 并行收集器(老年代版本) ParNew 多线程收集器 CMS 并发标记清除收集器 CMS收集器回收过程 G1 收集器 G1回收器的特点 G1收集器回收过程 GC 判断对象存活的方法 在垃圾回收器对堆内存回收前，需要判断对象是否存活。 引用计数算法: 给每个对象添加一个引用计数器,每当对象被引用, 对象的引用计数器就加1,当引用失效时,引用计数器就减1。 直到引用计数器为0,就代表对象不再被引用。 可达性算法: 通过GC ROOT的对象节点往下搜索,节点走过的路径被称为引用链。 如果一个对象不处于任何引用链,那么此对象是不可达的。 引用计数法缺点 引用计数的主要缺陷是很难解决循环引用的问题: 也就是当2个对象互相引用的时候,除了彼此, 没有其他地方引用这2个对象,那么他们的引用计数都为1,就无法被回收。 什么是GC Root ? 上面说通过GC Root对象搜索引用链,那么GC Root对象是什么对象, 或者说什么样的对象是GC Root对象。 可以作为GC Root对象的有: 虚拟机栈和本地方法栈区(native)中的引用对象(common object) 方法区中类的静态属性引用的对象(static) 方法区中的常量引用的对象(final) 垃圾回收算法 常见的垃圾回收算法主要有以下4种: 复制算法 标记-清除算法 标记-整理算法 分代收集算法 复制算法(Copying) 将堆内存分为2块大小相等的内存空间， 每次只使用其中的一块内存，另一块则空闲。 当其中一块内存使用完后， 就将仍然存活的对象复制到另一块空闲内存空间，再清理已使用的内存。 复制算法的优点是不会产生连续的内存碎片，速度也很高效。 但是缺点更明显:每次只使用内存的一半，就代表可使用的内存减少了1/2，代价很高昂。 复制算法一般用于新生代。 因为新生代的GC非常频繁，每次GC的对象较多，存活的对象较少。 所以采用复制算法效率更高，复制时只需要复制少量存活的对象。 标记-清除算法(Mark-Sweep) 标记-清除算法分为2个步骤：标记和清除。 首先标记出所有可达(存活)的对象，在标记完成后， 统一回收所有未被标记(不可达)的对象。 标记-清除算法的缺点主要有2个: 标记和清除2个阶段的耗时都比较长，可以总结为效率较低。 对象在内存中的分布可能是不连续的，分散的，标记-清除后可能造成不连续的内存碎片。 当内存碎片过多后，后续想要分配较大的对象时，无法找到足够大的内存碎片， 可能又需要触发GC。 标记-清除算法一般用于老年代。 因为老年代中的对象存活率较高，几乎很少被回收， 所以标记-清除和标记-整理算法GC的时间不会太长， GC的对象相比新生代更少。 标记-整理算法(Mark-Compact) 标记-整理算法是对标记-清除算法的一种改进。 标记-整理算法与标记-清除算法的在标记阶段是相同的， 都是首先标记出所有可达(存活)的对象。 但标记之后并不直接清理未被标记(不可达)的对象， 而是使被标记(存活)的对象向内存一端移动，然后清理掉这一端外的内存。 标记-整理算法的优点是: 几乎不会如标记-清除算法那样产生不连续的内存碎片。 但，所谓慢工出细活,标记-整理的效率是比标记-清除要低的。 标记-整理算法和标记-清除算法一样，一般用于老年代。 分代收集算法 分代收集算法并不是指某一种具体的垃圾收集算法， 而是将复制，标记-清除，标记-整理等算法合理运用到堆区的不同空间。 比如新生代使用复制算法，老年代使用标记清除或标记整理算法。 现代的几乎所有的JVM都使用分代收集，毕竟每种算法都有优缺点， 结合它们的特点，对不同的环境采用不同的算法是非常明智的选择。 内存分配与垃圾回收策略 对象优先在eden区域被分配 大对象将直接进入老年代 (大对象是指需要大量连续的内存空间的对象，如长字符串，大数组等。) 长期存活的对象将进入老年代 一次GC的过程 对象优先在eden区被分配，当eden区内存不足时， JVM发起Minor GC。Minor GC的范围包括eden和From Survivor: 首先JVM会根据可达性算法标记出所有存活的对象。 如果存活的对象中，有的对象的年龄已经达到晋升阈值 (阈值是动态计算的，可以通过-XX:MaxTenuringThreshold设置最大年龄阈值)， 那么将已经达到阈值的对象复制到老年代中。 如果To Survivor空间不足以存放剩余存活对象， 则直接将存活的对象提前复制到老年代。 如果老年代也没有足够的空间存放存活的对象， 那么将触发Full GC(GC整个堆，包括新生代和老年代)。 如果To Survivor可以存放存活的对象， 那么将对象复制到To Survivor空间，并清理eden和From Survivor。 此时From Survivor为空， 那么From Survivor就成为了下一次的To Survivor， 此时To Survivor存放着存活的对象，就成为了下一次的From Survivor。 这样From Survivor与To Survivor就是不断交替复制的使用。 老年代的空间比新生代的空间要大， 所以老年代的Major GC要比Minor GC耗时更长。 根据垃圾回收器的不同，老年代的GC算法也不同。 动态年龄阈值 JVM并不要求对象年龄一定要达到 MaxTenuringThreshold 才会 晋升到老年代，晋升的年龄阈值是动态计算的。￼￼￼￼￼ 如果在Survivor中，某个相同年龄阶段的所有对象大小的总和 大于Survivor区域的一半，则大于等于这个年龄的所有对象 可以直接进入老年代，无需等到MaxTenuringThreshold。 垃圾回收器 如果说垃圾回收算法是JVM对GC算法的方法论，那么垃圾回收器就是对GC算法的实现。 垃圾回收器主要分为以下几种收集器: Serial串行收集器 Serial收集器为单线程环境设计,并只使用一个线程进行垃圾回收。 在回收时，会暂停用户线程,并不适用于并发环境。 Serial收集器在单线程环境中是很高效的,它没有多线程切换的消耗。 Serial收集器采用复制算法 Serial Old 串行收集器(老年代版本) 它是 Serial收集器的老年代使用的GC收集器，同样是一个单线程的垃圾收集器。 Serial Old收集器采用的是标记-整理算法。 /** 开启串行收集器使用 -XX:+UseSerialGC , * 这样默认新生代使用 Serial 收集器, * 老年代使用 Serial Old 收集器. * * 设置VM参数: * * -XX:+Xlogs:gc* 打印gc信息 * -XX:+PrintCommandLineFlags 打印java版本信息 * -XX:+UseSerialGC 使用串行GC */ //如果程序正常运行,日志会显示 : // 新生代的信息为: def new generation..... // 老年代的信息为: tenured generation..... Parallel Scavenge 并行多线程收集器 Parallel Scavenge是并行收集器，它使用多个垃圾回收线程一起工作, 但是仍然会暂停用户线程。 Parallel Scavenge与其它垃圾回收器不同的是它更关注于达到可控制的吞吐量。 吞吐量是CPU运行用户应用程序代码的时间与CPU总消耗的时间的比值: 吞吐量 = 应用程序代码运行时间 / (应用程序代码运行时间 + GC时间) Parallel Scavenge收集器采用复制算法 Parallel Old 并行收集器(老年代版本) 它是 Parallel Scavenge 的老年代版本,同样是一个并行多线程的收集器。 Parallel Old收集器采用标记-整理算法。 /** * * 设置 Parallel Scavenge 收集器的参数: * * -XX:+UseParallelGC * * ParallelGC老年代默认使用的 Parallel Old GC 回收器 * * 并行收集器打印的新生代的信息为: * PSYoungGen .... * * 老年代的信息为: * ParOldGen .... * */ ParNew 多线程收集器 它可以看做是多线程版的Serial收集器。 除了多线程外，ParNew收集器与Serial收集器几乎没啥区别。 PS:目前只有Serial和ParNew能作为CMS收集器的新生代收集器。 ParNew收集器采用复制算法 /** * * 设置ParNewGC回收器的参数为: * -XX:+UseConcMarkSweepGC * */ CMS 并发标记清除收集器 Concurrent Mark Sweep,并发标记-清除垃圾回收器。 它是一款老年代的收集器，是以达到最短回收停顿时间目标的收集器。 见名知意,CMS收集器使用的是标记-清除算法。 CMS在垃圾回收过程中，用户线程可以同时工作，无需暂停。 因为CMS收集器采用的是标记-清除算法，所以回收时可能会产生不连续的内存碎片。 CMS收集器回收过程 初始标记(Stop The World，此阶段会暂停用户线程): 只标记与GC ROOT直接关联的对象。 并发标记: 对第一个阶段已经标记的对象进行Tracing，标记所有可达的对象。 重新标记(Stop The World,此阶段会暂停用户线程): 在第二个阶段，由于用户程序的运行， 可能有些对象之间的引用关系受到了影响，所以需要对这部分对象进行重新标记调整。 并发清除: 清除所有未被标记的对象。 /** * * 设置 CMS 收集器参数: * -XX:+UseConcMarkSweepGC * * 使用ConcMarkSweepGC收集器后,它的新生代使用的是: * ParNew收集器. * * 当ConcMarkSweepGC收集器出现异常时,会将CMS替换成Serial Old收集器 * * CMS回收分为4个阶段: * * 初始标记: (Stop the world 暂停用户线程) * 标记与GC Root直接可达的对象. * * 并发标记: * 从第一步标记的可达的对象开始,并发的标记所有可达的对象 * * 重新标记: (Stop the world 暂停用户线程) * 在第二部的并发标记阶段,由于程序运行导致对象间引用的关系发生变化, * 就需要重新标记 * * 并发清除: * 这个阶段不暂停用户线程,并且并发的去清除未被标记的对象 * */ G1 收集器 G1收集器可以说是目前最前沿的一款收集器，它是一款面向服务端的收集器。 G1收集器无需配合其他收集器就可以管理整个堆内存。 jdk9开始，G1成为jdk默认使用的垃圾回收器 G1回收器的特点 并行和并发: G1能够充分利用多核cpu的优势，使垃圾回收与用户线程同时运行。 可预测的停顿: 降低GC停顿时间是CMS与G1收集器的共同目标。但是除了降低GC停顿时间， G1收集器还可以建立可预测的停顿时间模型。(...太np了 =_=) 空间整合: 个人认为这是G1收集器不同于其他收集器的最大亮点了。 在其他收集器中，堆区基本都分为新生代和老年代。 而在G1收集器中虽然仍然保留了新生代和老年代的概念，但已经不再是物理上的分隔了。 在G1收集器的堆内存模型中，内存被分割成了一块一块大小相等的Region， 在这些Region中，Region的类型也不同，有eden，survivor，old，humongous之分。 当有大对象时，对象会被分配到Humongous Region之中。 G1收集器回收过程 G1收集器与CMS收集器的回收过程相似 初始标记(Stop The World,此阶段会暂停用户线程): 只标记与GC ROOT直接关联的对象。 并发标记: 对第一个阶段标记的对象Tracing，标记所有可达的对象。 最终标记(Stop The World,此阶段会暂停用户线程): 在并发标记阶段，由于用户线程执行， 可能导致被标记对象之间的引用关系发生影响，需要对这些对象进行重新标记调整。 筛选回收: 不同于CMS的并发清除，G1收集器首先会对所有Region的回收价值和回收成本进行排序, 然后再进行回收。这样可以在有限的时间内获得最大的回收率。 /** * * 因为我的机器的jdk版本是11,所以无需指定垃圾回收器 * 指定G1回收器的参数是: -XX:+UseG1GC * * 1:初始标记:(Stop the world 暂停用户线程) * 标记所有与GC Root直接可达的对象 * * 2:并发标记 * 从第一个阶段标记的对象开始,trace标记 * * 4:最终标记:(Stop the world 暂停用户线程) * 在第二步并发标记的阶段,由于程序执行, * 导致被标记对象之间的引用关系发生变化,所以需要重新调整标记 * * 5:筛选回收: * 和CMS的并发回收不一样, * G1收集器首先会对所有Region的回收价值和回收成本进行排序, * 然后再进行回收。 * 这样可以保证在有限的时间内获得最大的回收率. * */ "},"gitbook_doc/jdk_jvm_juc-learning/JVM调优相关内容.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/JVM调优相关内容.html","title":"JVM调优相关内容","keywords":"","body":" JVM调优相关 JVM常见参数 堆栈相关 GC相关 其他 Java常用调优命令和工具 JVM调优相关 JVM常见参数 堆栈相关 -Xss 调整线程栈大小。 -Xms 设置堆内存初始化大小。 -Xmx / -XX:MaxHeapSize=? 设置堆内存最大值。 -Xmn / -XX:NewSize=? 设置新生代大小。 -XX:NewRatio=? 设置老年代与新生代的空间占比。 如: -XX:NewRatio=2,那么老年代:新生代=2:1。 -XX:SurvivorRatio=? 设置eden与survivor的空间占比。 如: -XX:SurvivorRatio=2,那么eden:from survivor:to survivor=2:1:1 -XX:MetaspaceSize=? / -XX:PerGenSize=? -XX:MetaspaceSize=9m 设置元空间的初始化大小为9m,此参数只在jdk8以后的版本有效。 -XX:PerGenSize=9m 设置永久代的初始化大小为9m，此参数只在jdk8以前的版本有效。 -XX:MaxMetaspaceSize=? / -XX:MaxPerGenSize=? -XX:MaxMetaspaceSize=50m 设置元空间最大值为50m,此参数只在jdk8以后的版本有效。 -XX:MaxPerGenSize=50m 设置永久代的最大值为50m,此参数只在jdk8以前的版本有效。 -XX:+HeapDumpOnOutOfMemoryError 此参数使程序发生OOM时，dump错误堆栈信息。 -XX:HeapDumpPath=? -XX:HeapDumpPath=/home/log 此参数指定发生OOM时，dump错误堆栈信息存放的日志文件或目录。 此参数只在 -XX:+HeapDumpOnOutOfMemoryError 开启时生效。 GC相关 -XX:+PrintGCDetails / -Xlog:gc* 打印GC的日志信息。 -Xlog:gc* 在我使用的版本(jdk11)是更受推荐的。 -XX:+TraceClassUnloading / -Xlog:class+unload=info 打印类卸载的日志信息。 -Xlog:class+unload=info 在我使用的版本(jdk11)是更受推荐的。 -XX:+UseSerialGC 使用Serial串行回收器。 -XX:+UseParallelGC 使用Parallel并行回收器。 -XX:ParallelGCThreads=? 设置并行收集的线程数,如-XX:ParallelGCThreads=5。 -XX:+UseConcMarkSweepGC 使用CMS收集器，它默认的新生代搜集器为ParNew。 可以与参数: -XX:+UseSerialGC 一起使用，就替换掉了ParNew， 使用Serial作为CMS的新生代收集器。 -XX:+UseG1GC 使用G1收集器。 -XX:MaxTenuringThreshold=? 设置新生代对象晋升到老年代的最大年龄阈值。 其他 -server / -client -server:以服务端模式运行应用程序，server模式适用于服务端应用程序。 JVM在此模式下，会对服务端运行效率做很大优化。 -client:以客户端模式运行应用程序，client模式适用于客户端桌面程序(GUI)。 JVM在此模式下，会对客户端运行做很大优化。 Java常用调优命令和工具 jps(个人认为非常重要) jps 命令类似于 linux的 ps 命令，不过ps命令是用于查看系统进程的， 而jps用于查看当前系统运行的java进程。 jps -q 只输出java进程id jps -l 输出java进程main函数的详细路径 jps -v 输出java进程时指定的jvm参数 jps -m 输出java进程执行时main函数的参数 jstat jstat用于查看java进程的运行状态. jstat -class pid 用于查看java进程类的情况 jstat -compiler pid 用于查看java进程编译的情况 jstat -gc pid 用于查看java进程gc的情况 jinfo jinfo 查看正在运行的java进程的jvm参数 jinfo -flag MetaspaceSize pid 查看java进程的jvm的元空间大小 jinfo -flag MaxHeapSize pid 查看java进程的jvm的最大堆的大小 ... jmap jmap 既可以dump java程序的快照，也可以查看对象的统计信息。 jmap -heap pid 查看java进程堆的信息 jmap -histo pid 查看java进程对象的信息 jmap -dump:file=filename pid 生成java进程jvm的堆快照到指定文件 jstack jstack用于分析java线程栈信息 jstack pid jconsole jconsole 是jdk提供的对java程序进行分析的GUI界面工具。 "},"gitbook_doc/jdk_jvm_juc-learning/Jdk新特性.html":{"url":"gitbook_doc/jdk_jvm_juc-learning/Jdk新特性.html","title":"Jdk新特性","keywords":"","body":" Jdk新特性 Jdk8新特性 Jdk9新特性 Jdk新特性 Jdk8新特性 Lambda / 方法引用 接口新增default方法 Stream API Optional API 新的时间API(java.time强烈推荐使用) 内置Base64工具 Jdk9新特性 集合的工厂方法 接口新增private方法 响应式流(Doug Lea大师编写的，个人认为很重要，也是Webflux的基础吧) JShell 交互式编程环境 "},"gitbook_doc/rdbms-learning/About.html":{"url":"gitbook_doc/rdbms-learning/About.html","title":"关系型数据库部分","keywords":"","body":"关于本部分 rdbms-learning部分是对rdbms-learning 模块更细分的讲解。 关系型数据库常见知识点一览: XMind下载: Java知识梳理之关系型数据库 - XMind "},"gitbook_doc/rdbms-learning/RDBMS.html":{"url":"gitbook_doc/rdbms-learning/RDBMS.html","title":"RDBMS","keywords":"","body":" RDBMS(Relational Database Manager System) 什么是RDBMS? 什么是关系型数据库? 关系型数据库(SQL)与非关系型数据库(NoSQL)的区别 RDBMS(Relational Database Manager System) 什么是RDBMS? 关系数据库管理系统。 关系数据库关系系统是管理关系型数据库的软件系统。 什么是关系型数据库? 关系型数据库是指采用了关系模型来组织数据的数据库。 关系型数据库以行和列的形式来存储数据，以便于用户理解。 关系型数据库一系列的行和列的集合被称为数据表，而数据库则由一组表构成。 关系型数据库(SQL)与非关系型数据库(NoSQL)的区别 个人认为关系型数据库与非关系型数据库主要有以下区别: 存储结构 关系型数据库按照结构话的方式存储数据，需要先定义好数据库表的字段，再存储数据。 这样做的好处就是可靠性比较高，但是如果后期应用需要功能，需要扩展表的话，会有些受限。 非关系型数据库存储的结构则不像关系型数据库那样固定，相对来说较为灵活， 可以根据数据调整数据库的结构。 存储方式 关系型数据库大多都使用行和列这样的表格关系存储数据。 非关系型数据库存储数据的方式是不固定的，有的采用K-V及键值对存储， 有的采用文档存储，还有的图数据库使用图结构存储。 SQL标准 关系型数据库采用结构化的语言SQL来对数据库进行操作，并且SQL已成为大多数数据库的标准规范。 非关系型数据库则各自为战，一直没有一个统一的标准，每种厂商提供的数据库规范都不一样。 读写性能 关系型数据库强调数据的一致性，所以在遇到高并发读写操作时，会显得力不从心。 非关系型数据库强调BASE理论: Basically Available(基本可用), Soft-state(软状态), Eventual Consistency(最终一致性)， 它允许一定程度的数据不一致，但保证数据的最终一致性。 因此，面对高并发读写操作时，表现的会比关系型数据库好的多， 这也是redis,memcache这类高性能的NoSQL数据库被用于缓存的主要原因。 "},"gitbook_doc/rdbms-learning/RDBMS常见知识点.html":{"url":"gitbook_doc/rdbms-learning/RDBMS常见知识点.html","title":"RDBMS常见知识点","keywords":"","body":" RDBMS常见知识点 键是什么? 超键 / 候选键 / 主键 / 外键？ 联合主键和复合主键 DDL,DML,DCL,DQL,TCL DROP , TRUNCATE , DELETE区别 数据库设计范式(Normal Form)? 视图是什么? 视图与表有什么不同? 视图的优点 视图的缺点 存储过程是什么? 存储过程的优点 存储过程的缺点 触发器是什么? 临时表 连接 RDBMS常见知识点 键是什么? 键是描述数据表中某些特殊的属性列。 假设有一个学生表和一个班级表: 学生表有: 学号，身份证号，性别等属性 班级表有: 班级id，班级名等属性. 超键 / 候选键 / 主键 / 外键？ 超键: 超键是能唯一标识数据表中的记录的属性集的集合。 超键可以是一个属性，也可以是属性组合。 如学生表中的学号可以作为学生的唯一标识， 身份证号也可以作为学生的唯一标识,那么与这2个属性任意搭配的集合， 都可以作为学生表的超键: [[学号]，[身份证号],[学号,身份证号]，[学号，性别]，[身份证号，性别]...]等等。 候选键: 候选键是能唯一标识数据表中的记录的属性的集合。 可以把候选键看作是最小粒度的超键，即没有冗余的超键。 学生表中的候选键为:[[学号]，[身份证号]]。 但是不能有[学号，身份证号]，因为学号和身份证好同时存在就不是最小粒度了。 主键: 主键是能唯一标识数据表中的记录的属性列。 看起来主键和候选键区别不大。 但是候选键可以是一个集合,同时包括[学号],[身份证号]， 而主键是从候选键里选出一个属性出来，要么是[学号]，要么是[身份证号]。(不考虑联合主键哈) 外键: 外键是约束一个数据表和另一个数据表表的关系的属性列。 如何确定学生在哪个班级呢?或者说如何确定某个班级有哪些学生呢? 一个班级可以有多个学生.这就属于一对多关系。 可以在学生表中加一个班级id的外键列，与班级表的班级id关联， 这样就可以确定学生与班级的关系了。 联合主键和复合主键 网上有文章说联合主键和复合主键有区别，但我个人认为没区别。 在我看来联合主键和复合主键都是以多个属性列共同组合的主键， 它们以组合的形式保证数据的唯一性。 有的同学说联合主键是多个主键组合成的主键， 而我想反驳:一个表只有一个主键呀，哪来的那么多主键。 我估摸着有同学大概是想说唯一属性的列组成的主键吧，那还不是属于组合主键。。 当然，也可能是我功力不足，认识不到吧。 DDL,DML,DCL,DQL,TCL DDL(Data Define Language:数据定义语言):DDL的功能是用于定义数据库中的模式(Schema)， 模式包含了表，视图，存储过程等集合。 这里准确来说应该是定义数据库的三级模式:外模式，模式(逻辑模式，概念模式)和内模式。 DDL的关键字有: CREATE , ALTER , DROP等。 DML(Data Manipulation Language:数据操纵语言):DML的功能是用于操作数据库中的数据。 DML的关键字有: SELECT , DELETE , UPDATE , INSERT等。 DCL(Data Control Language:数据控制语言): DCL的功能是用于设置数据库的用户权限。 DCL的关键字有: GRANT,REVOKE等。 TCL(Transaction Control Language:事务控制语言): TCL的功能是用于管理事务。 TCL的关键字有: BEGIN , COMMIT , ROLLBACK等。 DQL(Data Query Language:数据查询语言): 数据查询语言，个人认为它应该是属于DML的。 DQL的主要关键字就是SELECT了。 DROP , TRUNCATE , DELETE区别 DROP: 删除表(包括表的所有索引和数据)或数据库。DROP属于DDL，操作不可回滚。 TRUNCATE: 删除表中的所有数据，如果有字段是自增的，那么该字段将重新从0开始。 TRUNCATE属于DDL，操作不可回滚。 DELETE: 删除表中指定的数据，如果没有指定条件，将删除所有数据。DELETE属于DML，操作可回滚。 数据库设计范式(Normal Form)? 第一范式: 所有字段都是不可分解的原子属性。 假设在一张用户表中有一个字段为地址。 但地址其实就不是一个原子属性， 因为地址可以分成: 国家 + 省份 + 城市 + 区域 + 街道等属性， 所以需要以最小粒度为单位设置表的属性。比如年龄，它仅仅代表年龄，并不能再分割。 第二范式: 第二范式在第一范式的基础上，所有属性必须依赖于主键，不能依赖部分主键。 一个表必须所有的非主键属性都必须依赖于主键，而且不能只依赖部分主键， 假设有一张学生教师表，字段为: 学号，学生姓名 ，教师编号，教师姓名。 学号(PK) 学生姓名 教师编号(PK) 教师姓名　 1 　guang19 1 qsjz 其中学号与教师编号为联合主键，学生姓名依赖于学号，而并不依赖于教师编号， 所以学生表不符合第二范式。 正确的做法是将学生教师表拆分为2张表:学生表和教师表， 并添加一张中间表来建立学生与老师的关系(一对一或一对多)。 学生表的字段为:学号，学生姓名。 教师表的字段为:教师编号，教师姓名。 学生表: 学号(PK) 学生姓名 1 　guang19 教师表: 教师编号(PK) 教师姓名 1 　qsjz 中间表: 学号(PK) 教师编号 1 1 第三范式: 第三范式在第二范式的基础上，属性不能间接依赖于主键，必须直接依赖于主键。 假设有一张学生表的字段为: 学号，学生姓名，班级编号，班级名称。 学号(PK) 学生姓名 班级编号 班级名称　 1 　guang19 1 qsjz5 其中学号为主键，但是班级名称依赖于班级编号，班级编号再依赖于学号。 这样班级名称与学号之间并不是直接性依赖，而是传递性依赖。 可以将学生表拆分为:学生表和班级表，其中: 学生表的字段为: 学号，学生姓名，班级编号。 班级表的字段为:班级编号 ， 班级名称。 学生表: 学号(PK) 学生姓名 班级编号 1 　guang19 1 班级表: 班级编号(PK) 班级名称 1 　qsjz5 学生表的班级编号与班级表的班级编号就属于一种外键关系了， 2张表中也不再有传递依赖性的依赖关系了。 视图是什么? 视图是一种展示数据表特定结果的虚拟表。 它主要用来做查询结果集的展示。 视图与表有什么不同? 数据表是存在物理文件中的，而于视图是虚拟存在的内存表。 它实际上是一条编译好的Select SQL语句，没有任何数据。 对视图的增删改查等操作实际上是对视图的基表的操作。 视图的优点 视图的优点主要在于可以定制用户数据，让用户关注于其自定义数据本身，而不用理会无关的数据。 视图的缺点 视图的主要缺点在于修改限制。 虽然视图主要是用来做结果集的查询展示的， 但是仍然可以对视图做出修改的操作(实际上是对基表做出修改)。 如果一个视图由多张基表的结果集组成，那么修改操作会变得很麻烦。 存储过程是什么? 当用户使用DML SQL语句操作数据库时，数据库需要编译SQL后再执行。 而存储过程则是用户为了完成特定的任务， 而预先在数据库中定义好并经过数据库编译后的一组SQL， 用户通过指定存储过程的名字和参数来调用存储过程。 存储过程类似于编程语言中的方法函数。 存储过程的优点 存储过程的优点主要在于它允许我们像编写函数一样定义SQL语句，非常的灵活。 并且存储过程是直接经过预编译直接存储在内存之中的，执行速度是很快的。 存储过程的缺点 存储过程的缺点主要在于耗费数据库的资源，如果存储过程过多，那么占用的内存也是越多的。 有的文章说存储过程的可移植性差，但应用程序的技术选型不应该是预先敲定的吗? 触发器是什么? 触发器是在指定表上，当满足指定条件时会执行的SQL语句的集合。 可以把触发器看做是特殊的存储过程，不过存储过程需要手动调用， 而触发器则是满足指定条件就会被触发。 触发器的触发事件有: UPDATE,DELETE,INSERT 触发时间有:Before,After 触发器缺点同存储过程一样。 临时表 临时表与普通数据表是相似的，不过临时表只在当前的连接之中有效， 当连接断开时，临时表就被销毁了。 因此，临时表可以保存一些临时的数据。 使用SHOW TABLES命令是无法查看临时表的。 连接 连接分为:内连接，外连接和交叉连接。 内连接:内连接只返回表的匹配的数据。 外连接:外连接分为:左外连接，右外连接和全外连接。 左外连接:左外连接会返回左表所有的行，即使右表中不匹配的行。 右外连接:右外连接返回右表所有的行，即使左表中没有匹配的行。 全外连接:全外连接返回所有表的所有行，即使表的数据不匹配。 交叉连接:交叉连接又称为笛卡尔积，它不同于其他连接，交叉连接无需指定条件。 它将一张表的每一行与另一张表的所有行全部匹配一遍，效率非常低，而且使用交叉连接的情况较少。 "},"gitbook_doc/rdbms-learning/索引.html":{"url":"gitbook_doc/rdbms-learning/索引.html","title":"索引","keywords":"","body":" 索引 什么是索引? 索引的优点 索引的缺点 B树和B 树区别 Hash索引 和 B 树索引 优劣 索引类型 主键索引(Primary Key) 二级索引(辅助索引) 聚集索引与非聚集索引 聚集索引 聚集索引的优点 聚集索引的缺点 非聚集索引 非聚集索引的优点 非聚集索引的缺点 非聚集索引一定回表查询吗(覆盖索引)? 覆盖索引 索引创建原则 单列索引 联合索引(多列索引) 最左前缀原则 索引创建注意点 最左前缀原则 选择合适的字段 不合适的字段 尽可能的考虑建立联合索引而不是单列索引 考虑在字符串类型的字段上使用前缀索引代替普通索引 使用索引一定能提高查询性能吗? 索引 什么是索引? 索引是一种用于快速查询和检索数据的数据结构。 见的索引结构有: B树， B+树和Hash。 索引的作用就相当于目录的作用。 打个比方: 我们在查字典的时候，如果没有目录， 那我们就只能一页一页的去找我们需要查的那个字，速度很慢。 如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。 索引的优点 索引最大的优点就是数据的检索效率高，这也是为什么要创建和使用索引的原因。 毕竟大部分系统的读请求总是大于写请求的。 索引的缺点 创建索引和维护索引需要耗费许多时间 : 当对表中的数据进行增删改的时候，如果数据有索引， 那么索引也需要动态的修改，会降低SQL执行效率。 占用物理存储空间 : 索引需要使用物理文件存储，也会耗费一定空间。 B树和B+树区别 B树的所有节点既存放 键(key) 也存放 数据(data); 而B+树只有叶子节点存放 key 和 data，其他内节点只存放key。 B树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B树的检索的过程相当于对范围内的每个节点的关键字做二分查找， 可能还没有到达叶子节点，检索就结束了。 而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程， 且叶子节点的顺序检索很明显。 Hash索引 和 B+树索引 优劣 Hash索引定位快 Hash索引指的就是Hash表，最大的优点就是能够在很短的时间内， 根据Hash函数定位到数据所在的位置，这是B+树所不能比的。 Hash冲突 知道HashMap或HashTable的同学，相信都知道它们最大的缺点就是Hash冲突了。 不过对于数据库来说这还不算最大的缺点。 Hash索引不支持顺序和范围查询(Hash索引不支持顺序和范围查询是它最大的缺点。) 试想一种情况: SELECT * FROM tb1 WHERE id B+树是有序的，在这种范围查询中，优势非常大， 直接遍历比500小的叶子节点就够了。 而Hash索引是根据hash算法来定位的，可能还要把 1 - 499的数据， 每个都进行一次hash计算来定位，就算不这样做，也需要全表扫描吧。 索引类型 主键索引(Primary Key) 数据表的主键列使用的就是主键索引。 一张数据表有只能有一个主键，并且主键不能为null，不能重复。 在mysql的InnoDB的表中，当没有显示的指定表的主键时， InnoDB会自动先检查表中是否有唯一索引的字段。 如果有，则选择改字段为默认的主键，否则InnoDB将会自动创建一个6Byte的自增主键。 二级索引(辅助索引) 二级索引又称为辅助索引，是因为二级索引的叶子节点存储着主键。 也就是说，通过二级索引，可以定位主键的位置。 唯一索引，普通索引，前缀索引等索引属于二级索引。 PS:不懂的同学可以暂存疑，慢慢往下看，后面会有答案的，也可以自行搜索。 唯一索引(Unique Key): 唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据， 但是允许数据为NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的通常都是为了该属性列的数据的唯一性，而不是为了查询效率。 普通索引(Index):普通索引的唯一作用就是为了快速查询数据。 一张表允许创建多个普通索引，并允许数据重复和NULL。 前缀索引(Prefix):前缀索引只适用于字符串类型的数据。 前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小因为只取前几个字符。 全文索引(Full Text):全文索引主要是为了检索大文本数据中的关键字的信息， 是目前搜索引擎数据库使用的一种技术。 Mysql5.6之前只有MYISAM引擎支持全文索引，5.6之后InnoDB也支持了全文索引。 二级索引: 聚集索引与非聚集索引 聚集索引 聚集索引即索引结构和数据一起存放的索引。 主键索引属于聚集索引。 在Mysql中，InnoDB引擎的表的.ibd文件就包含了该表的索引和数据， 对于InnoDB引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引， 叶子节点存储索引和索引对应的数据。 聚集索引的优点 聚集索引的查询速度非常的快，因为整个B+树本身就是一颗多叉平衡树， 叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 聚集索引的缺点 依赖于有序的数据 因为B+树是多路平衡树，如果索引的数据不是有序的， 那么就需要在插入时排序，如果数据是整型还好， 否则类似于字符串或UUID这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。 非聚集索引 非聚集索引即索引结构和数据分开存放的索引。 二级索引属于非聚集索引。 MYISAM引擎的表的.MYI文件包含了表的索引， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向.MYD文件的数据。 非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键。 非聚集索引的优点 更新代价比聚集索引要小 非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的 非聚集索引的缺点 跟聚集索引一样，非聚集索引也依赖于有序的数据 可能会二次查询(回表) 这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 这是Mysql的表的文件截图: 聚集索引和非聚集索引: 非聚集索引一定回表查询吗(覆盖索引)? 非聚集索引不一定回表查询。 试想一种情况，用户准备使用SQL查询用户名，而用户名字段正好建立了索引。 SELECT name FROM table WHERE username='guang19'; 那么这个索引的key本身就是name，查到对应的name直接返回就行了，无需回表查询。 即使是MYISAM也是这样，虽然MYISAM的主键索引确实需要回表，因为它的主键索引的叶子节点存放的是指针。 但是如果SQL查的就是主键呢? SELECT id FROM table WHERE id=1; 主键索引本身的key就是主键，查到返回就行了。 这种情况就称之为覆盖索引了。 覆盖索引 覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。 如主键索引，如果一条SQL需要查询主键，那么正好根据主键索引就可以查到主键。 再如普通索引，如果一条SQL需要查询name，name字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。 覆盖索引: 索引创建原则 单列索引 单列索引即由一列属性组成的索引。 联合索引(多列索引) 联合索引即由多列属性组成索引。 最左前缀原则 假设创建的联合索引由三个字段组成: ALTER TABLE table ADD INDEX index_name (num,name,age) 那么当查询的条件有为: num / (num AND name) / (num AND name AND age)时，索引才生效。 所以在创建联合索引时，尽量把查询最频繁的那个字段作为索引的最左(第一个)字段。 查询的时候也尽量以这个字段为第一条件。 但可能由于版本原因(我的mysql版本为8.0.x),我创建的联合索引， 相当于在联合索引的每个字段上都创建了相同的索引: 无论是否符合最左前缀原则，每个字段的索引都生效: 索引创建注意点 最左前缀原则 虽然我目前的Mysql版本较高，好像不遵守最左前缀原则，索引也会生效。 但是我们仍应遵守最左前缀原则，以免版本更迭带来的麻烦。 选择合适的字段 不为NULL的字段: 索引字段的数据应该尽量不为NULL，因为对于数据为NULL的字段，数据库较难优化。 如果字段频繁被查询，但又避免不了为NULL，建议使用0,1,true,false 这样语义较为清晰的短值或短字符作为替代。 被频繁查询的字段: 我们创建索引的字段应该是查询操作非常频繁的字段。 被作为条件查询的字段: 被作为WHERE条件查询的字段，应该被考虑建立索引。 被经常频繁用于连接的字段: 经常用于连接的字段可能是一些外键列，外键列并不是一定要建立外键， 只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。 不合适的字段 被频繁更新的字段应该慎重建立索引: 虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。 不被经常查询的字段没有必要建立索引 尽可能的考虑建立联合索引而不是单列索引 因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗B+树。 如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后， 索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。 如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间， 且修改数据的操作效率也会提升。 考虑在字符串类型的字段上使用前缀索引代替普通索引 前缀索引仅限于字符串类型，较普通索引会占用更小的空间， 所以可以考虑使用前缀索引带替普通索引。 使用索引一定能提高查询性能吗? 大多数情况下，索引查询都是比全表扫描要快的。 但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。 "},"gitbook_doc/rdbms-learning/Mysql.html":{"url":"gitbook_doc/rdbms-learning/Mysql.html","title":"Mysql","keywords":"","body":"Mysql Mysql是什么? Mysql是一个关系型数据库管理系统，由瑞典Mysql公司开发，现属于Oracle旗下产品。 Mysql是最流行的关系型数据库之一，与它同类型的数据库还有SQL Server，Oracle，DB2等。 Mysql官方文档 Mysql架构 Mysql总体架构可分为三层:应用层,服务层，存储引擎层: 应用层: 应用层是Mysql体系最上面的一层，接受客户端的连接请求。 应用层包含:连接处理，用户认证，安全管理等内容。 连接处理: 当客户端向Mysql服务端发送一个请求后，Mysql 服务会从线程池中分配一个线程来对客户端连接进行处理。 用户认证: 当客户端请求连接后，服务端会根据用户名，密码等信息判断用户身份。 安全管理(权限): 当客户端连接到Mysql服务端后，Mysql服务会验证用户的权限，以便限制用户的操作。 服务层: 服务层用于处理客户端的操作，是Mysql的核心模块，主要包括:SQL解析器，优化器和缓存等。 SQL解析器: sql解析器用于解析SQL语句，如果SQL有错误，则会提示相应的错误信息，如果没有错，则执行SQL优化。 如果SQL是查询语句，那么首先会去缓存里查询，如果查询成功，就直接返回结果， 不进行接下来的SQL优化。 优化器: 优化器用于优化SQL语句，使得SQL的执行更加高效率。 缓存: 缓存SQL查询的结果，提高SQL查询的效率。 存储引擎层: 存储引擎是Mysql数据持久化的核心。 Mysql是数据库肯定要存储数据，存储数据就要与磁盘文件交互了。 并且Mysql是关系型数据库，核心由表和索引组成，存储引擎还要负责表与索引的创建与持久化。 "},"gitbook_doc/rdbms-learning/Mysql存储引擎.html":{"url":"gitbook_doc/rdbms-learning/Mysql存储引擎.html","title":"Mysql存储引擎","keywords":"","body":" Mysql存储引擎 InnoDB MyISAM MRG_MyISAM MEMORY BLACKHOLE CSV ARCHIVE FEDERATED PERFORMANCE_SCHEMA Mysql存储引擎 使用: SHOW ENGINES 命令可以查看Mysql所有的存储引擎。 InnoDB InnoDB是Mysql最常用的存储引擎之一。 InnoDB主要特点如下: 采用聚集索引: InnoDB采用聚集索引(B+树)，即数据和索引存放在一个文件(.ibd)中。 自适应Hash: 网上有的资料说InnoDB引擎支持Hash，也有的说不支持。 Hash索引的查询(定位)效率是很高的，只是范围和有序查询是它的硬伤，抛开这点， Hash索引的优势还是很大的。InnoDB会自适应优化，如果判断建立Hash索引确实能够提高效率， 那么InnoDB将自己建立相关索引。 参考: 58沈剑前辈的文章 支持事务: 在Mysql的所有引擎中，只有InnoDB支持事务，这也是它被广泛采用的原因之一。 既支持行锁也支持表锁 支持缓存: InnoDB支持缓存，既能缓存数据，也能缓存索引。 支持外键 支持全文索引: Mysql 5.6开始，InnoDB也支持全文索引。 MyISAM MyISAM也是Mysql最常用的引擎之一。 MyISAM主要特点如下: 采用非聚集索引: MyISAM引擎采用的是非聚集索引(B+树)，即索引和数据分开存放， 索引的叶子节点存放指向数据的指针。.MYD文件存放数据, .MYI文件存放索引。 不支持事务: MyISAM引擎不支持事务，可以说这是它最大的缺点了。 只支持表锁: 相比InnoDB，MyISAM只支持表锁，所以在并发方面，MyISAM可能没有InnoDB那么出色 不支持外键 支持全文索引 保存表的行数: MyISAM保存表的行数，而InnoDB不保存， 所以使用 SELECT COUNT(*)查询，MyISAM比InnoDB要快。 MRG_MyISAM MRG_MyISAM引擎也称为MERGE引擎。 它实际上是一系列相同的MyISAM表的集合，创建MERGE表时，必须指定成员表。 对MERGE表的操作，就是对成员表的操作，对成员表的操作，也会反馈到MERGE表中。 假如对MERGE进行INSERT，其实是INSERT到MERGE表的成员表上， 对成员表进行INSERT，结果也会体现到MERGE表上。 MERGE引擎要求merge的表必须都是MyISAM引擎， 且这些表必须拥有相同数据类型的属性列，相同顺序的索引， 但是也允许每个表对应列和索引的名称不同。 MEMORY MEMORY内存引擎。 MEMORY主要特点如下: 不支持持久化机制: MEMORY表的数据是存放在内存中的，且MEMORY不支持持久化机制。 也就是说一旦MYSQL服务器发生宕机等故障，那么数据是很可能丢失的。 所以MEMORY适用于临时数据表。 只支持行锁，不支持表锁 默认采用Hash索引，但支持B树索引: HASH索引执行条件SQL非常快，但如果是范围查询，则需要全表扫描。 BLACKHOLE BLACKHOLE 黑洞引擎。 它的主要特点如下: 不存储数据: 如它的名字一样:黑洞。 写入的数据都会被吞噬掉，只进不出， 不会存储数据，只有一个.sdi(.frm)文件，但是它会记录binlog。 分担主库压力: BLACKHOLE不存储数据就没有用了吗?当然不是。 在普通的主从架构下，slave节点直接连接master节点进行binlog同步压力是比较大的， 可以让BLACKHOLE引擎的数据库节点与master进行搭配， 再让其他slave节点与BLAKHOLE节点进行同步，这样就降低了master的压力。 CSV CSV文件存储引擎。 CSV主要特点如下: CSV引擎的表不支持主键和其他普通索引 所有字段必须为NOT NULL: CSV引擎的表要求所有字段必须非空。 逗号分隔列数据: CSV引擎如它的名字一样，以.csv文件存储数据，且列数据之间以逗号分割。 关于CSV文件还可以参考:CSV文件 ARCHIVE ARCHIVE归档引擎，主要解决了冷数据存储问题。 ARCHIVE主要有以下特点: 占用空间小: 同样的数据，ARCHIVE引擎表占用的空间要比InnoDB小80%左右。 不支持删除和修改: ARCHIVE引擎的表不允许UPDATE和DELETE操作。 支持行锁 不支持索引: ARCHIVE引擎的表支持主键和自增，但是不支持普通索引。 FEDERATED FEDERATED是一种特殊的存储引擎，在我的版本中(8.0.x)默认是不开启的。 FEDERATED引擎使得我们可以访问远程Mysql服务器中数据库的数据。 FEDERATED类型的表由两部分组成: 远程表: 远程表的引擎可以是Mysql支持的任何类型，如:InnoDB,MyISAM等。 本地存放的.frm文件，.frm文件是对表的定义，包含了指向远程表的字符串。 FEDERATED引擎的本地表并不存放数据，当对本地表进行操作的时候，实际上是操作远程表。 PERFORMANCE_SCHEMA PERFORMANCE_SCHEMA系统存储引擎，它是Mysql的一个特性, 主要用来收集Mysql数据库在运行时的性能， 具体参考:Mysql:PERFORMANCE_SCHEMA文档 "},"gitbook_doc/rdbms-learning/事务.html":{"url":"gitbook_doc/rdbms-learning/事务.html","title":"事务","keywords":"","body":" 事务 什么是事务? 事务的四大特性(ACID) 事务的隔离级别 事务隔离级别引发的问题 快照读 事务 事务并不是Mysql独有的，只是因为某些知识点以Mysql为示例， 所以便把它放在了Mysql之后。 什么是事务? 事务是一组原子性的操作序列，操作执行成功的结果使数据库从一种状态变成另一种状态， 且状态是持久的。 事务的四大特性(ACID) 原子性(Atomicity): 原子性指事务是一组不可分割的操作，要么全部成功， 要么全部失败，不会出现一个操作成功，一个操作失败的情况。 一致性(Consistency): 一致性指事务对数据库操作前后，数据的完整性没有被破坏。 如用户A给用户B转账，无论转账是否成功，A和B的财产总和是不变的。 隔离性(Isolation): 隔离性指事务与事务之间是相互独立的，互不干扰的， 一个事务的失败，不会影响另一个事务。 持久性(Durability): 持久性指事务对数据库的操作产生的影响应该是持久的，不会因为外部原因而发生改变。 事务的隔离级别 读未提交(READ UNCOMMITTED): 一个事务读取另一个事务未提交的数据。 如果事务的隔离级别处于读未提交，那么可能产生脏读，换读和不可重复读等现象。 读已提交(READ COMMITTED): 一个事务读取另一个事务已提交的数据，可以避免脏读， 但是又可能会出现不可重复读和幻读。 可重复读(REPEATABLE READ): 一个事务没有结束时，它对表中的同一条记录读取的结果都是相同的， 也就避免了不可重复读，但还有可能发生幻读问题。 串行化(SERIALIZABLE): 串行化是最高的事务隔离级别，完全满足ACID四个特性。 同一时间，数据库只能执行一个事务，事务之间完全互不干扰，这样就防止了脏读，幻读和不可重复读等问题。 PS:但是串行化相当于串行模式，效率是很低的，所以请慎用。 事务的隔离级别 能否解决:脏读 能否解决:不可重复读 能否解决:幻读 RU × × × RC √ × × RR √ √ × S √ √ √ 事务隔离级别引发的问题 脏读: 脏读在事务隔离级别为读未提交的时候会出现。脏读指读取到了一个事务还没有提交的数据。 假设某张表的一个字段为money，有一条记录money的值为100。 一个事务A对数据做了修改: money=120，但没有提交。 此时，另一个事务B读取到了A修改但没有提交的数据 money=120，然后事务A回滚了， 使得money仍然为原值100，那么事务B读到的money=120就是脏数据。 使用2个mysql客户端窗口模拟多线程事务导致的脏读: 设置事务隔离级别为读已提交可以避免脏读发生。 SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED; 读已提交: 可以看到，虽然读已提交解决了脏读，但是又出现了不可重复读问题。 不可重复读: 不可重复读在事务隔离级别为读已提交时会出现。 不可重复读指一个事务还没有结束时，多次读取同一条数据，可能读取的结果不一样。 假设某张表的一个字段为money，有一条记录money值为100。 一个事务A读取了这条记录为100，此时， 另一个事务B对这条记录做出了修改money=120,并提交了。 当A再次读取money的时候，money为120 。 设置事务隔离级别为可重复读可以避免不可重复读的问题发生。 SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ; 可重复读: 虽然可重复读避免了不可重复读问题，但幻读问题也随之而来。 在说幻读之前,得先讲讲MVCC(Multi-Versioned Concurrency Control)机制。 简单理解:这个机制保证了在某个时间，多个事务读取的是数据库的一个快照版本。 关于MVCC机制可以看这篇文章:MVCC 再来说幻读: 幻读: 了解了MVCC机制之后，再看幻读会觉得豁然开朗。 幻读在隔离级别为可重复读的时候会出现。 可重复读虽然避免了不可重复读的问题，但是它也使得当前事务无法感知其他事务的操作。 假设事务A查询了一张表为空表，此时，另一个事务B插入了一条记录并提交了， 当事务A也要插入记录的时候，却发生了主键冲突的错误，可当事务A再次查询的时候，仍然是空表呀。 幻读: 快照读 解决幻读之前先看看快照读： 快照读就是幻读。 个人理解幻读(快照读)是MVCC机制出现的一种问题。 先来看看另一种情况: 当前读 为什么上面处于可重复读级别的第一个事务在第一次读取之后，感知不到第二个事务的修改操作。 因为在事务一开启后，事务会选择第一次SELECT(事务开启后的第一次SELECT)的结果作为快照， 此后的读取，都是读取的这个快照版本，即使其他事务更新了数据， 当前事务也认为这个快照是最新版本，所以读取的仍然是快照版本，数据当然一致。 这就揭露了，可重复读实际上是快照读。 那为什么会发生上面当前读的情况? 因为第一个事务开启后，并没有立刻SELECT，也就是在事务一内并不存在快照版本， 那么事务一就会选择记录的最新版本作为结果。 最新的版本是什么时候? 是第二个事务修改数据并提交后，记录的版本也随之修改了，所以第一个事务能够感知到第二个事务的修改操作。 关于 ，还是和MVCC机制有关，这部分内容比较复杂，所以建议各位同学仔细阅读。 避免幻读的有2种方式:串行化和加锁。 看看加锁是如何解决幻读的: "},"gitbook_doc/rdbms-learning/数据库锁.html":{"url":"gitbook_doc/rdbms-learning/数据库锁.html","title":"数据库锁","keywords":"","body":" 数据库锁 数据库锁机制是什么 乐观锁和悲观锁 共享锁和独占锁(排他锁) 行锁，表锁，页锁 行锁基于索引 数据库锁 数据库锁机制是什么 在编程语言中，有线程同步机制保证多线程对共享资源进行访问时的安全问题。 在数据库中，也有事务锁同步机制，保证事务的一致性。 乐观锁和悲观锁 锁从宏观上分为乐观锁和悲观锁。 乐观锁: 乐观锁一般是用户实现的一种锁机制。乐观锁机制对与共享数据很乐观， 认为任何时候都不会发生线程安全或事务一致性问题，所以不会给数据加锁。乐观锁适用于读多写少的应用。 悲观锁: 数据库锁基本都属于悲观锁。悲观锁认为在任何环境下，数据都有可能发生共享一致性问题， 所以每次读写数据的时候都会加锁。 共享锁和独占锁(排他锁) 按锁的操作可划分为共享锁和独占锁。 共享锁: 共享锁允许多个事务同时访问同一份共享数据。 读锁就属于共享锁，多个事务可以同时对一份数据进行读操作。 独占锁: 独占锁保证了在任何时候，只能有一个事务获取锁，其他事务只能等待获取锁的事务释放锁。 写锁属于独占锁,一份数据同时只能被一个事务增删改。 行锁，表锁，页锁 锁按粒度来划分，还可以分成行锁，表锁，页锁。 行锁: 行锁是最小粒度的一种锁，只针对当前事务操作的行加锁，即在当前事务范围内， 其他事务无法对当前事务操作的行进行修改，事务产生冲突的概率很小。 行锁的加锁粒度最小，并发性高，但它的开销大，加锁慢，而且可能会出现死锁。 表锁:表锁是粒度最大的一种锁，它对整张表加锁，即当在当前事务范围内， 其他事务无法对表做出修改，所以事务产生冲突的概率较大。 表锁的粒度最大，并发性低，但它的实现较为简单，加锁很快，不会发生死锁。 页锁: 页锁是锁定粒度介于行锁和表锁中间的一种锁,并发性一般，可能会出现死锁。 行锁基于索引 在InnoDB中，行锁是基于索引实现的。 如果当前事务的操作没有基于索引，那么InnoDB将使用表锁。 这就意味着如果你使用一个SQL操作一条记录，但是这个条SQL的条件列并没有建立索引， 那么这条SQL即使操作一条记录，使用的也是表锁。 行锁升级为表锁的一种情况: "},"gitbook_doc/rdbms-learning/Mysql日志.html":{"url":"gitbook_doc/rdbms-learning/Mysql日志.html","title":"Mysql日志","keywords":"","body":" Mysql Log日志 binlog redolog undolog Mysql Log日志 Mysql中有几种重要的日志文件，Mysql需要依赖这些日志文件完成非常重要的功能 binlog 二进制日志可以说是Mysql最重要的日志，它记录了所有的DDL和DML(SELECT和SHOW不会记录)语句。 binlog的作用主要在于恢复记录和复制记录。 redolog 重做日志，它记录了事务的操作。 它的作用是确保事务的持久性，防止因为外部原因，数据没来得及写入磁盘而丢失。 在Mysql启动时，会根据redolog重新执行事务操作，从而达到事务持久性。 redolog在事务开启后就产生了，在事务的执行过程中，就被写入了redolog。 redolog日志大小是固定的，当事务执行完后，数据落盘后，redolog就会被覆盖掉。 undolog 回滚日志,它记录了事务开始前数据的一个版本状态，如果事务在记录到redolog时， 就出现了意外，就可以将数据回滚到事务之前的这个状态。 "},"gitbook_doc/rdbms-learning/Mysql优化.html":{"url":"gitbook_doc/rdbms-learning/Mysql优化.html","title":"Mysql优化","keywords":"","body":" Mysql优化 Explain执行计划 开启慢查询日志 为什么要求字段尽量设置为NOT NULL? 为什么主键尽量设置成有序和整型? Mysql优化 Explain执行计划 Explain是Mysql的优化神器，它可以对一条Query SQL进行分析， 并输出SQL的详细信息，以便于优化SQL。 下面是Explain解析一条SELECT的例子: EXPLAIN输出的属性如下: id: id是SELECT查询的序列号，表示一条SELECT或SELECT中子查询的执行顺序。主要有2种情况: 如果id相同，可以被认为是同一分组，执行顺序，从上到下。 如果id不同，id值越大，那么越先执行。 select_type: select_type是为了区分简单查询，复杂查询，子查询等查询类型。 select_type主要有如下值: SIMPLE: SIMPLE代表简单查询，SELECT中不包含子查询或联合查询等复杂查询。 SUBQUERY: SUBQUERY表示子查询部分。 PRIMARY: PRIMARY表示最外层查询，如果一个SELECT中包含子查询， 那么最外层的查询就是PRIMARY。 DERIVED: DERIVED代表查询的结果被放入临时表中。 如FROM 语句后跟着一个 SELECT ，那么SELECT的结果就可能被放入临时表中。 UNION: UNION代表联合查询，也就是UNION后的SELECT。 UNION RESULT: UNION RESULT代表联合查询的结果。 table: table表示查询的表。 partitions: partition代表查询匹配的分区，对于非分区表为NULL。 type: 查询类型，是衡量SQL的一个重要的指标。 一般来说，至少要达到range标准，最好达到ref。 它有如下值： SYSTEM: SYSTEM代表表只有一条记录，他是CONST类型的一个特例。 CONST: CONST表示表只最多只有一个匹配行，只用读一次， 因此优化器可以视查询结果为一个常量。 EQ_REF: EQ_REF代表唯一性索引扫描。比如以 unique key索引或主键作为条件， 这2种索引都是唯一的，表中只有一条记录与之匹配。 REF: REF代表非唯一索引匹配，返回匹配条件的所有行。 比如WHERE条件的列有索引，经过匹配后，发现有多条符合条件的记录。 RANGE: RANGE表示范围扫描。如使用>, INDEX: INDEX代表全表扫描，不过它与ALL的区别在于， INDEX是在索引列上进行全表扫描，一般要比ALL快。 ALL: ALL代表全表扫描，效率最低。 possible_keys: poosible keys代表查询涉及到的字段如果有索引会被列出来， 但不一定使用。 key: key代表查询实际使用到的索引，如果为NULL，则没有使用索引。 key_len: key_len表示使用索引的实际长度。 ref: ref表示与索引比较的列或这常量。 假设 WHERE以主键作为条件 id = 10,那么ref显示的就是const， 因为主键为10，就是一个常量。 rows: rows代表查询优化器估算查询结果集要扫描的行数， 也就是执行SELECT预计需要扫描的行数。 filtered: filtered代表SELECT执行时过滤掉的记录与rows的百分比。 filtered 显示的百分比 与 rows 的乘积就是查询时过滤掉的行数。 EXTRA: 显示SQL执行时的附加信息 开启慢查询日志 慢查询用于记录查询超过某个临界值的SQL。 使用: SHOW VARIABLES LIKE 'SLOW_QUERY_LOG'; 查看慢查询是否开启，如果显示OFF，那么执行: set GLOBAL SLOW_QUERY_LOG = on 开启慢查询日志。 使用: SHOW VARIABLES LIKE 'LONG_QUERY_TIME'; 查看慢查询临界值,单位: 秒。 使用: SET LONG_QUERY_TIME=2 设置慢查询临界值。 开启慢查询后，会在mysql的数据目录下产生xxx-slow.log慢查询日志文件， 一旦某条SQL超过了临界值，就会被记录到慢查询日志文件中。 为什么要求字段尽量设置为NOT NULL? 因为Mysql难以优化可以为空的字段，一旦字段被建立了索引， 那么就需要额外的空间来存储此当前行记录是否为NULL的标识。 为什么主键尽量设置成有序和整型? 这个问题其实在索引章节就说过了，索引的结构是B+树，B+树最大的优点就是顺序查找， 有序的主键当然有利于查找，像UUID等这种长字符串，连排序都难以解决。 "},"gitbook_doc/rdbms-learning/Mysql数据类型.html":{"url":"gitbook_doc/rdbms-learning/Mysql数据类型.html","title":"Mysql数据类型","keywords":"","body":" Mysql数据类型 UTF8和UTF8MB4 CHAR 和 VARCHAR TIMESTAMP 和 DATETIME 如何在TIMESTAMP和DATETIME之中选择? Mysql数据类型 UTF8和UTF8MB4 在mysql中，UTF8编码最多能存放3个字节的数据，也就是说几乎可以存放所有的中文汉字了。 但是如果遇到像emoji这种特殊的字符，那UTF8就不够用了。 在mysql5.5.3版本后，mysql加入了一种新的字符: UTF8MB4,他是UTF8的超集， 最多可以支持4个字节的数据，所以解决了UTF8兼容性的问题。 CHAR 和 VARCHAR CHAR是固定长度的字符串,VARCHAR是可变的字符串。 mysql5.0版本以上，CHAR(M)和VARCHAR(M)的长度M不再指字节长度， 而单纯的就是指长度。 如CHAR(1)和VARCHAR(1), 既可以存放1个中文字符，也可以存放1一个英文字符，只不过它们底层的字节长度不同。 一个中文字符约等于3个字节，所以CHAR(1)如果存放一个中文字符，那么mysql底层的字节长度将为3。 (VARCHAR的实际最大长度还得看表的字符编码,UTF8最大只支持3个字节，UTF8MB4支持4个字节) 它们的主要区别如下: 长度上限不同: CHAR长度的上限为255个字节(约85个汉字), VARCHAR长度的上限为65535个字节(约21845个汉字)(mysql 5.0 以上)，和text相同。 占用空间不同: 使用CHAR 作为类型的话，无论该字段字符的长度是否小于指定长度，都会占用指定长度的空间。 而VARCHAR则是根据字符的长度来决定占用的空间，这就是可变长字符串的好处。 是否删除字符串末尾的空字符串: 如果字符串末尾有空格字符，CHAR则会删除其末尾的空格， 而VARCHAR不会删除字符串末尾的空格。 效率问题: 由于VARCHAR是可变长的，如果对字符串进行更改的时候， 那么也会修改其相应的空间，这在效率上就没有CHAR那么高效了。 TIMESTAMP 和 DATETIME TIMESTAMP和DATETIME都是用于表示时间的类型。 它们主要有如下区别: 占用空间不同: TIMESTAMP占用4个字节；DATETIME占用8个字节,因此TIMESTAMP更加节省空间。 时间范围不同: TIMESTAMP表示 1970 - 2038年；DATETIME表示: 1000 - 9999 年。 是否受时区影响: TIMESTAMP的时间会受当前Mysql的时区影响； 而DATETIME则不受影响，存进去什么时间，拿出来就什么时间。 默认值不同: TIMESTAMP字段的值如果为NULL，那么将会自动更新到当前时间； DATETIME存进去NULL，就默认为NULL。 如何在TIMESTAMP和DATETIME之中选择? 如果你想让一个时间字段表示的范围更大，且不受系统时区影响，那么建议选择DATETIME。 其他情况考虑TIMESTAMP吧。 "},"gitbook_doc/nosql-learning/About.html":{"url":"gitbook_doc/nosql-learning/About.html","title":"非关系型数据库部分","keywords":"","body":"关于本部分 nosql-learning部分是对nosql-learning 模块更细分的讲解。 非关系型数据库常见知识点一览: XMind下载: Java知识梳理之非关系型数据库 - XMind "},"gitbook_doc/nosql-learning/NoSQL.html":{"url":"gitbook_doc/nosql-learning/NoSQL.html","title":"NoSQL","keywords":"","body":" NoSQL(Not-only SQL) 什么是NoSQL数据库? 为什么要有NoSQL数据库? 非关系型数据库与关系型数据库的区别 有哪些类型的NoSQL数据库? NoSQL(Not-only SQL) 什么是NoSQL数据库? NoSQL数据库泛指非关系型数据库，与关系型数据库不同，非关系型数据库并没有一种固定的存储数据的结构， 相对来说比较灵活。 为什么要有NoSQL数据库? 非关系型数据库与关系型数据库是一种相辅相成的关系，起到了互补的作用。 关系型数据库的数据看上去很直观且支持事务，保证了数据的一致性。 非关系型数据库读写速度块，在高并发的压力下仍有不俗的表现且数据结构丰富， 更多的是对关系型数据库的一种补充。 非关系型数据库与关系型数据库的区别 存储结构 关系型数据库按照结构化的方式存储数据，需要先定义好数据库表的字段， 再存储数据。这样做的好处就是可靠性比较高，但是如果后期应用扩展功能， 需要扩展表的话，会有些受限。 非关系型数据库存储的结构则不像关系型数据库那样固定，相对来说较为灵活， 可以根据数据调整数据库的结构。 存储方式 关系型数据库大多采用行和列这样的表格关系存储数据。 非关系型数据库存储数据的方式则不固定，有的采用K-V键值对存储， 有的采用文档存储，还有的图数据库使用图结构存储。 SQL标准 关系型数据库采用结构化的语言SQL来对数据库进行操作，并且SQL已成为大多数数据库的标准规范。 非关系型数据库则各自为战，一直没有一个统一的标准，每种厂商提供的数据库规范都不一样。 读写速度 关系型数据库强调数据的一致性，所以在遇到高并发读写操作时，会显得力不从心。 非关系型数据库强调BASE理论: Basically Available(基本可用),Soft-state(软状态),Eventual Consistency(最终一致性)。 它允许一定程度的数据不一致，但保证数据的最终一致性。 因此，面对高并发读写操作时，表现的会比关系型数据库好的多， 这也是redis,memcached这类高性能的NoSQL数据库被用于缓存的主要原因。 有哪些类型的NoSQL数据库? K-V键值对: K-V键值对类型的NoSQL数据库类似于Hash表，将数据存储在内存中， 操作速度非常的快，因此常被用于缓存数据库。K-V键值对类型的NoSQL数据库主要有:Memcached,Redis等。 文档: 文档类型的NoSQL数据库结构则不固定，无需像关系型数据库一样预先定义字段，它存储数据的方式类似于JSON， 可以清晰的描述数据之间的复杂关系。文档类型的NoSQL数据库主要有:MongoDB,CouchDB等。 列式存储: 列式存储的NoSQL数据库以列簇形式存储数据，将同一列的数据存储在一起， 这样可以分割为多列，查询速度是很快的，但是列式存储的数据库功能也会收到限制。 列式NoSQL数据库主要有:HBase等; 图结构: 图数据库主要用于构建节点的关系图谱，以图算法和图结构进行计算和存储。 图数据库主要有:Neo4j等。 "},"gitbook_doc/nosql-learning/Redis.html":{"url":"gitbook_doc/nosql-learning/Redis.html","title":"Redis","keywords":"","body":"Redis 推荐一个学习Redis的网站: RedisBook 什么是Redis? Redis是一个使用ANSI C语言编写，遵守BSD协议规范的开源的K-V类型的NoSQL数据库服务器。 Redis是当前最流行的K-V类型的NoSQL数据库之一，在通往系统架构的方向，它是我们不得不学习的知识。 Redis官网 "},"gitbook_doc/nosql-learning/Redis常见知识点.html":{"url":"gitbook_doc/nosql-learning/Redis常见知识点.html","title":"Redis常见知识点","keywords":"","body":" Redis常见知识点 Redis优缺点 Redis为什么这么快? Redis应用场景 为什么不用Map或Guava做缓存? Redis和Memcached异同 Redis IO模型 Redis 6 之前 Redis 6 之后 Redis常见知识点 Redis优缺点 Redis的优点: 性能高: 用c语言编写的应用我就没见过慢的~_~。 丰富的数据结构: 总体上来说Redis是以K-V形式存储数据，但是细分来说， 它支持STRING，HASH，LIST，SET，SORTED_SET，HyperLogLog等多种数据结构。 支持Lua脚本: Redis使用Lua脚本解释器来执行脚本，所以它支持Lua脚本。 支持事务: Redis是为数不多的支持事务的NoSQL数据库之一。 支持数据持久化: Redis支持rdb和aof两种数据持久化方式。 支持发布者/订阅者功能 支持主从模式: Redis支持Sentinel哨兵模式搭建高可用集群配置。 Redis的缺点: 受限于物理内存: Redis属于内存数据库，它在内存中存储数据的大小是受物理内存限制的， 所以它不适合存储海量数据。 Redis为什么这么快? 内存操作: Redis绝大部分操作都是基于内存的，想不快都难。 优秀的数据结构: Redis虽然支持的数据结构众多，但是它的每种数据结构都是专门设计和优化过的。 多路复用IO: Redis整体采用多路复用IO模型，核心操作使用单线程处理。 Redis应用场景 缓存: 缓存可能是Redis用的最多的场景了。由于Redis的高性能， 高并发场景下作为缓存服务数据库，再适合不过了。 并且Redis支持的key自动过期功能，更是可以定制热点数据的过期时间。 多功能业务场景: Redis支持多种丰富的数据结构，不仅可以存储简单的K-V数据，还可以使用Hash存储用户，商品等信息， List存储有序的数据，Set还有交集，并集，差集等功能。 分布式锁: Redis的操作具有原子性的，可以利用这点来完成分布式锁。 为什么不用Map或Guava做缓存? 因为无论是Map还是Guava，都属于本地缓存，数据都存在一个JVM进程内的。 如果是单机模式，这样做尚可。但如果是分布式或者Java应用有多个实例，那就不能保证每个JVM进程内的缓存是一致的， 所以需要使用Redis这种第三方数据库作为缓存容器。 Redis和Memcached异同 都属于内存数据库 持久化支持: Redis支持RDB和AOF两种持久化机制； Memcached只在内存中存储数据，不支持持久化机制。 数据结构: Redis从整体上来说是以K-V类型的为存储结构， 但它细分可以支持String，Hash，List，Set，Sorted Set等数据类型； Memcached只支持K-V类型的存储结构。 IO模型: Redis是以多路复用IO为模型的设计； Memached是以非阻塞IO为模型的设计。 事件库: Redis采用自制的AeEven事件库处理Socket事件; Memcached采用的是LibEvent事件库。 使用场景: 不考虑性能，Redis更适用于需要复杂数据结构，需要持久化的应用， 如果你的应用以后需要扩展，那么也可以选择Redis； Memcached则适用于高并发和只需要K-V数据结构的应用。 Redis IO模型 Redis IO模型按Redis的版本可以分为Redis 6之前和Redis 6之后。 Redis 6 之前 Redis是基于多路复用IO模型处理Socket请求的，关于多路复用的知识，我在 Linux五种IO模型中 已经说过了: 多路复用IO模型依赖于操作系统的select/poll/epoll函数， epoll函数使得内核不断轮询客户端socket， 用户进程(线程)也需要阻塞在对epoll函数的调用上，当Socket有事件时， 用户线程便发起系统调用，处理Socket事件。 多路复用IO模型简单理解就是一个线程处理多个Socket连接。 所以可以把Redis看成是单线程模型，但并不是说Redis只有一个线程， 而是说它执行核心操作的线程只有一个，它还有其他辅助线程完成其它功能。 Redis这样设计就避免了多线程切换的开销和简化了Redis的设计。 Redis IO模型: Redis 6 之后 Redis 6 之前一个线程处理所有的Socket和核心操作， 这样做的好处就是单线程无需考虑像多线程切换带来的困扰， 简化了Redis的模型，但随之而来的也有性能上的瓶颈。 虽然Redis确实够快，但它的数据是在内存中操作的，会受到内存的限制。 且一个线程处理所有的Socket会带来网络IO的限制，并不能发挥多核CPU的优势。 那有什么办法既能够发挥多核cpu的优势，又不会复杂化Redis的架构呢？ Redis 6 之前的瓶颈主要在于内存和网络IO。 关于内存这块，只得靠Redis自身的优化和机器条件了。 但是网络IO这块就可以通过新增多线程来处理大量Socket连接来优化了。 Redis 6 正是通过新增监听线程来解决网络IO的瓶颈，线程监听到Socket事件后， 再交由main线程处理。 所以整体来说，Redis 6 在处理Socket事件上由单线程优化成了多线程，但核心操作还是由单线程执行。 Redis 6 IO模型： "},"gitbook_doc/nosql-learning/Redis数据结构.html":{"url":"gitbook_doc/nosql-learning/Redis数据结构.html","title":"Redis数据结构","keywords":"","body":"Redis数据结构 关于Redis数据结构这块，还是推荐学习: RedisBook Redis有着非常丰富的数据结构，这些数据结构可以满足非常多的应用场景， 如果对这些数据结构有一个比较清晰的认知，使用Redis也会更加得心应手。 Redis主要支持以下数据结构: String(字符串) List(双端链表) Hash(Hash字典) Set(无序集合) Sorted Set(有序集合) 数据结构 描述　 　实现 String 可以存储字符串，整型和浮点型等类型的数据。适合于简单的K-V数据场景。 Redis并没有使用字符数组来实现这一数据类型，而是自己定义了简单动态字符串(SDS: Simple Dynamic String)类型来实现这一数据结构。 List 既可以存储操作有序的数据，还可以当做栈来使用，它适合存储列表性质的数据。 List在Redis中使用的是双端链表和压缩列表实现的，这就解释了它为什么能在头尾操作元素。 C语言并没有双端链表的实现，所以Redis自定义了这一数据结构。 Hash Hash字典，也是关联数组，数组的每个元素都是key到value的映射，它适合存储对象这样的结构化数据。 Hash在Redis中是使用Hash字典和压缩列表实现的。 Set Set无序集合，它适合存储需要去重的元素，且有并集，交集，差集等功能在多个Set之间进行比较计算。 整数集合是Set的底层实现之一，当集合只有整型元素且元素数量不多的时候，Redis就会使用整数集合来实现Set。当新添加元素的时候，整数集合会根据新元素的类型自动扩容，并将所有元素的类型都转为与新元素一样的类型，在这个过程中，还需要保持原来的顺序不变，最后才添加新元素。 Sorted Set Sorted Set有序集合，可以看做加强版的Set。Sorted Set 与 Set不同的是，Sorted Set可以根据元素的score分数进行排序。它适合存储需要排序的不重复的元素。 Sorted Set在Redis中使用的是跳表实现的，跳表是一种有序且查询速度很快的数据结构。跳表每个节点都维持指向其他节点的指针，从而达到快速访问的目的。 "},"gitbook_doc/nosql-learning/Redis事务.html":{"url":"gitbook_doc/nosql-learning/Redis事务.html","title":"Redis事务","keywords":"","body":"Redis事务 Redis的事务主要依赖于WATCH ,UNWATCH,MULTI , EXEC, DISCARD等命令。 其中 MULTI , EXEC , DISCARD 分别对应关系型数据库的 BEGIN,COMMIT,ROLLBACK操作。 Redis事务执行过程 客户端使用MULTI命令开启事务，此时用户就可以开始发出要执行的命令。 如果命令为WATCH/MULTI/EXEC/DISCARD这四个中的任意一个， 那么会被直接执行，因为它们属于事务操作。 当执行DISCARD的时候，会清空事务队列并退出事务。 如果是普通命令，就将命令加入事务队列，然后当EXEC命令执行时， 事务中的队列将会被一一执行，最后执行的结果也是一个数组。 参考: Redis事务的设计与实现 Redis事务队列 在开启事务后，用户命令并不会被立刻执行，而是被添加到事务队列中， 这个队列其实是一个数组，每个数组元素由3部分组成: 要执行的命令(cmd) 命令的参数(argv) 参数的数量(argc) 命令被添加到队列中的结构大致如下: 命令被执行后，也会生成一个结果数组，Redis就将这个结果数组返回: Redis事务错误 Redis事务有两个错误时机。 EXEC执行命令之前出现错误: 在EXEC命令之前的错误，也就是开启事务后，用户发出了错误的命令， 参数数量不对或其他原因，服务端会累积这些错误。 当EXEC命令执行时，将拒绝执行事务，并返回错误原因，清空事务队列。 EXEC执行命令时出现错误: EXEC执行命令时出现错误，也就是用户发出的命令没有错， 但是在执行命令的时候出现了错误(可能是参数类型不对)，这时候仍然返回结果数组, 也就是说错误的命令并不影响其他命令的执行。 "},"gitbook_doc/nosql-learning/Redis缓存淘汰策略.html":{"url":"gitbook_doc/nosql-learning/Redis缓存淘汰策略.html","title":"Redis缓存淘汰策略","keywords":"","body":" Redis缓存淘汰策略(key回收) noeviction volatile allkeys Redis缓存淘汰策略(key回收) 当Redis使用的内存超出物理内存限制时， Redis的内存会和Swap(虚拟内存)频繁切换，造成Redis性能的急剧下降。 为了不让Redis内存占用超过物理内存占用，可以给Redis配置一个 maxmemory 的值， 当Redis占用内存超过了这个maxamemory的值， 那么Redis将启用缓存淘汰策略来删除内存中的key， 缓存淘汰策略可以通过 maxmemory-policy 设置。 缓存淘汰策略主要分为3类: noeviction volatile allkeys noeviction noeviction策略是Redis默认的淘汰策略。 它可以继续接受请求并执行，但是不会执行写请求， 这样做可以保证内存中的数据不会被删除，但是却不能继续完成写请求。 volatile volatile只针对 设置了过期时间的key做淘汰。 volatile有三种算法实现: volatile-lru:根据lru算法淘汰设置了过期时间的key，lru算法优先删除最近最少使用的key。 volatile-ttl:根据key的过期时间淘汰设置了过期的key，过期时间越小的key优先被删除。 volatile-random:随机淘汰设置了过期时间的key。 allkeys allkeys对所有key无差别淘汰 allkeys有两种算法实现: allkeys-lru: 根据lru算法淘汰所有的key，最近最少使用的key优先被删除。 allkeys-random:随机淘汰所有的key。 "},"gitbook_doc/nosql-learning/Redis持久化策略.html":{"url":"gitbook_doc/nosql-learning/Redis持久化策略.html","title":"Redis持久化策略","keywords":"","body":" Redis持久化 RDB(Redis Data Base) RDB优缺点 AOF(Append Only File) AOF优缺点 如何选择持久化策略? Redis持久化 Redis有2种持久化策略: RDB和AOF。 RDB(Redis Data Base) RDB是Redis默认的持久化策略，这种策略是把内存的数据以二进制形式的副本保存在磁盘上。 RDB持久化触发条件 SAVE命令: 当客户端执行SAVE命令时，会阻塞Redis主线程进行数据持久化，直到持久化完成。Redis在阻塞期间不能处理客户端的请求。 BGSAVE命令: 当客户端执行BGSAVE命令时，Redis会fork一个子进程进行数据持久化，因此并不会阻塞Redis服务。 FLUSHALL命令: 当客户端执行FLUSHALL命令时，会清空Redis所有数据库的数据，并且也会触发数据同步。 save配置: Redis会按照配置文件中的save配置的条件进行数据同步，一旦满足条件，就会执行BGSAVE命令，即fork一个子进程进行同步。 shutdown: 当Redis服务关闭时，也会将数据同步到磁盘，以便下次启动时恢复。 RDB优缺点 RDB的优点: 文件体积小,恢复大数据较快 最大化Redis性能: Redis会fork出子进程进行数据同步，并不影响Redis的性能。 RDB的缺点: 数据安全性较低: 如果不显示的执行SAVE命令，那么Redis隔一段时间才会同步数据，可能会造成一定程度的数据丢失。 AOF(Append Only File) AOF默认情况下是关闭的，当配置选项 appendonly 设置为yes后才会进行AOF的持久化。 appendfsync指定了AOF的同步策略，它有三个可选值。 no: no代表Redis不亲自持久化，而是通过系统调用write函数每隔一段时间将数据写入文件。 这种情况下如果服务器发生故障，可能会有数据还没来得及同步就丢失了。 always: always表示Redis每次执行写操作都会将数据同步到文件中。 这种策略虽然保证了数据的安全性，但是对Redis的性能会有影响。 everysec: everysec是AOF默认的持久化策略，这种策略下， 系统每一秒都会将数据写入文件，兼顾了性能和数据安全性。 AOF优缺点 AOF优点: 数据安全性较高,秒级丢失 AOF缺点: 文件体积大,恢复大数据较慢 如何选择持久化策略? 两种持久化方式各有优缺点，可以选择混合的方式进行备份。 混合持久化后，文件的内容大部分都是RDB格式的，恢复起来较快。 以AOF的方式同步也能保证数据的安全性。 "},"gitbook_doc/computer-network/About.html":{"url":"gitbook_doc/computer-network/About.html","title":"计算机网络部分","keywords":"","body":"关于本部分 computer-network部分是对computer-network 模块更细分的讲解。 计算机网络常见知识点一览: XMind下载: Java知识梳理之计算机网络 - XMind "},"gitbook_doc/computer-network/OSI七层模型.html":{"url":"gitbook_doc/computer-network/OSI七层模型.html","title":"OSI七层模型","keywords":"","body":"OSI OSI(Open System Interconnect开放式系统互联)。 它是ISO(国际标准化组织)提出的网络互联模型。 OSI模型定义了网络互联的7层框架: 应用层，表示层，会话层，传输层，网络层，数据链路层，物理层。 OSI七层模型 OSI网络互联模型为什么要分层? 分层可以把开放系统中信息交换的问题分解到具体的层级之中， 而各层可以对各自的功能独自做出修改和扩展，体现了解耦的思想。 物理层: 物理层的作用是利用光纤，电缆，双绞线等传输介质来传输比特流(光，电等信号)。 需要ISP(Internet Service Provider)互联网提供商的支持。 链路层: 链路层的作用是当网络层数据传输前，将数据封装成帧。 一个帧由一个数据字段和若干首部字段组成，网络层的数据报就存于数据字段中。 当帧中的数据作为bit传输时，接收方可能会判断错误，如0判断成1。 这种错误是由于在数据发送过程中外部因素如电磁噪声干扰所致， 许多链路层协议就提供了一种纠错机制，通过让发送节点在帧中包括差错bit，让接受节点进行差错检查。 网络层: 网络层主要负责数据的数据链路的寻址和路由选择。网络层的协议主要有:IP,ICMP等。 传输层: 传输层提供端口到端口的可靠的数据传输服务。传输层的协议主要有TCP和UDP。 会话层: 会话层的作用是负责建立，管理和终止主机之间的通信连接。 表示层: 表示层主要的作用是负责数据格式的转换。将应用层的数据转换为网络传输的格式， 或者将来自下一层的数据转为应用层协议能够处理的格式。 除此之外，数据的压缩解压，加密解密也都由表示层完成。 应用层: 应用层为应用程序提供SPI(Service Provider Interface)应用程序接口。 应用层协议是为应用程序提供服务保证的协议。 "},"gitbook_doc/computer-network/TCP_IP.html":{"url":"gitbook_doc/computer-network/TCP_IP.html","title":"TCP/IP","keywords":"","body":" TCP/IP TCP/IP协议族 HTTP(HyperText Transfer Protocol)(应用层协议) HTTPS(HyperText Transfer Protocol Secure) (应用层协议) SMTP(Simple Mail Transfer Protocol) (应用层协议) POP3(Post Office Protocol 3) IMAP(Internet Mail Access Protocol) DNS(Domain Name System) (应用层协议) FTP(File Transfer Protocol)(应用层协议) SFTP(Secure File Transfer Protocol) (应用层协议) Telnet / SSH(Secure Shell) (应用层协议) TCP协议(Transmission Control Protocol) TCP为什么可靠性较高? UDP协议(User Datagram Protocol) TCP与UDP主要区别 TCP如何保证可靠性传输? 为什么需要三次握手? TCP三次握手的过程 为什么需要四次挥手? TCP四次挥手的过程 TCP粘包和半包问题 解决TCP消息无边界的办法主要有以下几种: TCP/IP TCP / IP 不仅仅是指TCP和IP这两种协议，而是一系列网络协议的总和， 而这些协议中最核心的2个协议就是TCP和IP，所以被称为TCP/IP网络协议族。 TCP/IP协议族是互联网的基础通信架构。 TCP/IP协议族 HTTP(HyperText Transfer Protocol)(应用层协议) HTTP超文本传输协议。 是用于Web浏览器和Web服务器之间传递数据的协议。 HTTP协议以明文的方式发送内容，不提供任何方式的数据加密， 因此HTTP是一种不太安全的协议。 HTTPS(HyperText Transfer Protocol Secure) (应用层协议) HTTPS协议在HTTP协议的基础上加入了SSL协议， SSL依靠证书来验证服务器的身份， 所以HTTPS协议叫HTTP协议来说是安全的。 SSL协议作用于传输层协议和各种应用层协议之间。 SMTP(Simple Mail Transfer Protocol) (应用层协议) SMTP简单邮件传输协议。 它是用于从源地址到目标地址传输邮件的协议(发送邮件) POP3(Post Office Protocol 3) POP邮局协议的第3个版本。 POP3协议允许电子邮件客户端下载服务器上的邮件， 但是在客户端上的操作，并不会反馈到服务器上。 也就是说客户端的操作对服务端没有影响。(接受并处理邮件) IMAP(Internet Mail Access Protocol) IMAP交互式邮件存取协议。 它和POP3协议类似 ，但是IMAP对客户端的操作会反馈到服务端, 也就是说客户端邮件的状态与服务端邮件的状态是一致的。(接受并处理邮件) DNS(Domain Name System) (应用层协议) DNS域名系统。 DNS服务器可以看做是一个域名与IP地址相互映射的分布式数据库。 我们使用浏览器访问google的时候需要输入:google.com, 浏览器会帮我们到DNS服务器查询google.com对应的IP地址， 从而能够访问google的服务器。 FTP(File Transfer Protocol)(应用层协议) FTP文件传输协议。 FTP协议用于从一台主机将文件传输到另一台主机上。 但FTP协议在文件传输过程中，并没有为文件提供加密措施， 所以FTP协议是不安全的。 SFTP(Secure File Transfer Protocol) (应用层协议) SFTP安全文件传输协议。 SFTP实际可以看做是SSH的一部分。 当使用SFTP登录到目标主机后，可以使用SFTP指定的命令进行数据传输， 并且传输的数据是加密过的。 Telnet / SSH(Secure Shell) (应用层协议) Telnet和SSH都可以作为远程登录的协议。 但Telnet使用的是明文来传输数据，并且没有提供数据加密措施， 是不安全的协议。 而SSH协议则提供了对数据的压缩和加密，比Telnet要安全的多。 所以现在几乎大部分场景都使用的是SSH作为安全数据传输和远程登录的协议， 并且SSH提供了对SFTP的支持。 TCP协议(Transmission Control Protocol) TCP传输控制协议。 TCP协议是一种面向连接的，可靠的，基于字节流的传输协议。 TCP协议适用于对数据准确性和可靠性要求较高的应用，如文件传输等。 TCP为什么可靠性较高? TCP会采用校验和，确认应答与序列号， 拥塞控制，流量控制，超时重传， 连接管理(三次握手，四次回收)等机制保证传输的可靠性。 TCP报文格式: UDP协议(User Datagram Protocol) UDP用户数据报协议。 与TCP协议不同，UDP协议并不保证数据传输的可靠性， 无论目标主机是否可通信，UDP都会发送数据。 UDP适用于传输效率要求较高，允许一定数据丢失的应用，如语音，视频等。 PS:UDP报文格式 TCP与UDP主要区别 TCP基于连接，数据传输前需要做好可靠性准备工作(三次握手);而UDP是无连接的，只要有数据就可发送了。 TCP使用流量控制和拥塞控制等措施使传输更加可靠；而UDP则是不可靠的传输。 TCP是面向流的数据模式(无边界)；而UDP是面向报文的数据模式(有边界)。 TCP仅支持单播，点对点的数据传输；而UDP不仅支持单播，还支持组播，广播。 TCP首部开销较大(最大60字节，最小20字节);UDP首部开销较小(8字节)。 TCP如何保证可靠性传输? 校验和(16位) 在数据传输过程中，将发送的数据段分成若干个16位的整数。 将这些整数加起来，并且前面的进位不能丢弃，补在后面，最后取反， 得到校验和。 发送方在发送数据之前计算校验和，并将校验和填充到TCP报文中， 而接收方收到数据后，对数据以同样的方式进行计算，求出校验和， 与发送方的进行比对。如果比较失败，接收方将丢弃数据包。 确认应答ACK和序列号(32位) 在TCP传输过程中，每次接收方收到数据后，都会对发送方进行应答， 也就是响应ACK报文，这个报文中有对应的确认序列号。 超时重传 在TCP传输时，由于确认应答和序号机制，当发送方发送完数据后， 会等待接收方的ACK报文，并解析判断ACK报文(一般来说ACK为seq+1)， 如果发送方一直没有等到接收方的ACK报文，那么将重新发送一遍数据。 连接管理 连接管理是TCP数据传输前和连接断开时的工作， 包括三次握手与四次挥手的过程。 流量控制(滑动窗口) TCP连接发送端和接收端都有一个缓冲区，如果发送端的发送数据过快， 导致接收端来不及处理数据，缓冲区就被填充满了，那么接下来的数据， 接收方就会丢弃数据，导致丢包等连锁反应产生。 TCP根据接收端的处理能力，来决定发送端的发送速度，这个机制就是流量控制。 TCP的报文中，有一个16位的窗口字段， 窗口大小就是接收端计收数据缓冲区的剩余大小，这个数字越大， 代表接收端缓冲区的剩余空间越大。 接收端在发送ACK确认报文时，会将自己当前的窗口大小填入， 这样发送方就会根据ACK报文里的窗口大小的值改变自己的发送速度。 如果接收方窗口大小的值为0，那么发送方将停止发送数据， 并定期的向接收端发送窗口探测数据，让接收端把窗口大小告诉发送端。 拥塞控制(拥塞窗口) 滑动窗口是接收端的使用的窗口大小，用来告诉发送端接收端的缓存大小， 从而可以控制发送端的发送速度。 而发送端发送的速度则是使用发送端的窗口来实现的。 发送端的窗口就是拥塞窗口了，发送端的拥塞窗口不代表缓存， 而是指发送端每次最多可以发送的数据包数。 当TCP连接建立时，拥塞窗口被初始化为1，每次发送数据后， 收到一个ACK，拥塞窗口就增加一个报文段， 发送端取拥塞窗口与滑动窗口的最小值作为发送上限，从而实现拥塞控制。 如果网络比较拥堵，那么一次性发送大量数据将，可能产生大量的丢包， 继而发生一系列的连锁反应，如超时重传等。 拥塞控制就避免了一次性发送过多的数据，而导致的问题。 为什么需要三次握手? TCP是面向连接的，三次握手是客户端与服务端进行数据传输前的准备工作。 这样做是为了建立可靠的传输信道，尽可能的保证数据的安全。 TCP三次握手的过程 三次握手是指建立一个TCP连接时需要客户端和服务端总共需要发送3个数据包确认连接的建立。 TCP三次握手的过程: 1.第一次握手 客户端发送一个数据包发送给服务端。 该数据包的标志位SYN=1，表示客户端请求建立连接， 随机产生的序列号seq=J。 客户端进入SYN_SENT状态，等待服务端确认。 2.第二次握手 服务端收到客户端的数据包后，由标志位SYN=1判断客户端需要建立连接。 于是响应一个确认数据包给客户端。 该确认数据包的标志位SYN和标志位ACK都为1，确认序列号ack=J+1, 随机产生的序列号seq=K。服务端进入SYN_RCVD状态。 3.第三次握手 客户端收到服务端的确认数据包后，检查确认序列号ack是否为J+1, 标志位ACK是否为1。 如果正确则将发送最后一个数据包给服务端。 该数据包的标志位ACK为1,确认序列号ack=K+1。 服务端收到后检查确认序列号ack是否为K+1,标志位ACK是否为1。 如果正确，则客户端和服务端都进入ESTABLISHED状态。 三次握手后，客户端和服务端就可以传输数据了。 为什么需要四次挥手? 四次挥手是客户端与服务端关闭连接时的结尾工作。 TCP是全双工的，即:客户端可以通过这条TCP连接向服务端发送数据(上传)， 服务端也可以通过这条TCP连接向客户端发送数据(下载)。 因此，客户端和服务端都需要单独的关闭连接。 客户端关闭连接是关客户端到服务端的通信传输， 而服务端关闭连接是关闭服务端到客户端的通信传输， 所以需要四次挥手来保证2端的关闭。 TCP四次挥手的过程 四次挥手是指断开连接时，客户端与服务端总共需要发送4个数据包确认连接的断开。 客户端或服务端任意一方都可以发送断开连接的请求。 TCP四次挥手的过程: 1.第一次挥手(假设客户端请求断开) 客户端发送一个数据包给服务端，用于关闭Client到Server的数据传输。 数据包的标志位FIN=1，随机产生的序号seq=M，客户端进入FIN_WAIT_1状态。 2.第二次挥手 服务端收到客户端的断开请求后，将发送一个数据包响应给客户端。 该数据包的标志位ACK=1，确认序列号ack=M+1。 客户端收到后进入FIN_WAIT_2状态，服务端进入CLOSE_WAIT状态。 3.第三次挥手 服务端发送一个数据包给客户端，用于关闭服务端到客户端的数据传输。 数据包的标志位FIN=1，随机产生的序列号seq=N。 服务端进入LAST_ACK状态。 4.第四次挥手 客户端收到服务端的断开请求后，就可以关闭连接了。 于是发送最后一个数据包结束与服务端的连接，并进入TIME_WAIT状态。 最后一个数据包的标志位ACK=1，确认序列号ack=N+1。 服务端收到最后一个了数据包后，就关闭了连接，状态就为CLOSED， 如果服务端没有收到ACK,客户端可以重传。客户端等了一会儿， 最终没有收到响应，就代表服务端已经关闭连接了，客户端也就会关闭连接。 上面是客户端或服务端中的一段主动关闭，另一段被动关闭， 实际还可能还会出现同时发起关闭的情况: TCP粘包和半包问题 在TCP传输数据时，客户端发送数据，实际上是把数据写入到了TCP的缓冲区中， 粘包和半包也就可能在此时产生。 假设客户端给服务端发送两条数据: \"ABC\"和\"DEF\"， 服务端这边的接受可能会有多种情况: 可能是一次性收到了这两条消息:\"ABCDEF\", 也有可能分批收到了消息:\"ABC\",\"DEF\"或\"AB\",\"CD\",\"EF\"。 服务端一次性收到了所有数据包，这种情况就是粘包。 服务端分批收到数据包，这种情况就是半包。 如果客户端发送的包的大小比TCP的缓冲区要小， 并且TCP的缓冲区可以存放多个包，客户端一次性就可能向服务端发送多个包， 这时服务端从TCP缓冲区中就可能读取多个包，这种现象就叫粘包。 如果客户端发送的包的大小比TCP缓冲区要大， 那么这个数据包就可能被分为多个包，就需要多次发送， 而服务端第一次从缓冲区里获取的数据只是整个数据包的一部分，这时候就产生了半包。 粘包的主要原因是: 发送端发送的数据大小 半包的主要原因是: 发送端发送的数据大小 > Socket缓冲区大小， 服务端读取数据不够及时，只读取到了数据的一部分。 总结起来就是:多次发送可能共用一个传输，一个发送可能多占用多个传输。 其实归根到底，究其根本原因是: TCP是面向字节流的协议，消息之间没有边界。 而UDP虽然也可以一次性传输多个包或者多次传输一个包 但UDP的每个消息都是有边界的，因此不会有粘包和半包问题。 解决TCP消息无边界的办法主要有以下几种: 固定长度:这种方式是为消息设定一个固定长度。虽然实现简单，但缺点很大，如果消息的大小本身就比较小， 那么这样做就很浪费空间了。 分隔符:这种方式是为消息边界添加分隔符。这样做实现也是比较简单，也不再浪费空间， 不过当内容本身也有分割符时，那就需要转义了，就可能需要对整个内容进行扫描，效率上就比较低。 添加数据的长度字段:这种方式是为报文添加一个Length字段，存储消息的长度。 在Http协议的报文中，有一个字段为Content-Length，专门存储数据的长度,这种方式是比较好的。 "},"gitbook_doc/computer-network/HTTP.html":{"url":"gitbook_doc/computer-network/HTTP.html","title":"HTTP","keywords":"","body":" HTTP HTTP协议的特点 Cookie和Session的区别 没有Cookie是否依然能实现Session? 重定向和转发的区别 GET和POST区别 常见HTTP状态码 301与302的区别 HTTP请求方法 URI,URL,URN HTTP HTTP协议的特点 适用于客户端与服务端的通信架构: 如果一个应用使用了HTTP协议，那么肯定要有一端作为客户端， 另一段作为服务端，请求又客户端发出，服务端处理并返回请求的结果。 无状态: 无状态是指HTTP协议不对请求和响应之间的通信状态进行保存， 对于发送过的请求或响应的结果都不做持久化处理。 但无状态就意味着每个请求都是独立的，后续的请求如果需要用到前面使用过的信息/数据则需要重传， 这可能导致后续连接的数据较大。 于是Cookie和Session就应运而生,Cookie和Session可以保存用户的状态信息或数据。 无连接: 无连接是指每次TCP连接只处理一个请求，服务端处理完客户端的请求后， 立刻断开连接。采用这种方式，可以节省传输时间。 但是这样做的缺点也很明显，每个TCP连接只处理一个请求， 这样做不仅浪费资源，而且每次请求都需要建立连接，这就使得请求的效率也很低。 从HTTP/1.1开始支持Keep-Alive功能， Keep-Alive使得客户端与服务端的连接持续有效， 当客户端对服务端有多个请求时，都会使用这一条连接。 当超过Keep-Alive规定的时间，或者出现其他意外的情况时， 客户端与服务端的连接才会被断开。 Cookie和Session的区别 Cookie是在客户端保存用户信息的一种机制，用于记录用户的一些状态信息。 每一次客户端向服务端发出请求，都会携带Cookie信息。 Session是在服务端保存用户信息的一种机制。 一个Session对应一个客户端，当客户端第一次请求服务端时， 客户端就会被分配一个唯一SessionId，该SessionId依赖于Cookie，被存储在客户端。 因为SessionId采用Cookie保存，所以每次客户端请求服务端， 也都会携带该SessionId，这样，服务端就能根据SessionId识别客户端身份。 没有Cookie是否依然能实现Session? 个人认为是可以的。 Session将SessionId保存在客户端的Cookie中， 而Cookie不过是客户端保存请求状态的一种机制而已， 使用其他技术当然也可以实现这种机制， 如LocalStorage/SessionStorage也可以存储。 重定向和转发的区别 转发是服务端行为,客户端是无法感知转发的。重定向则是客户端行为。 转发属于一次请求，而重定向是客户端需要发送第二次请求。 GET和POST区别 GET和POST都是HTTP请求的一种方式，而HTTP协议是基于TCP协议的， 所以GET和POST都是基于TCP协议的。。-_- GET请求的语义是从服务器获取资源，无论获取多少次资源， 数据可能不同，但是并不会对服务器资源造成任何影响。 所以我认为GET请求是无副作用的，是幂等的，是可缓存的。 POST请求的语义是在服务器上创建资源，是会产生副作用的。 相同的2次POST请求会创建两份资源，因此POST请求是非幂等的，是不可缓存的。 其他方面，个人认为没啥不同。 只是对于不同的浏览器，GET请求和POST请求在这些浏览器上的表现也不同。 如GET请求和POST请求的URL长度不同,但是具体的长度，恐怕还得视浏览器而定吧。 常见HTTP状态码 HTTP状态码: 1** : 指示信息。服务端收到请求，继续执行操作。 2** : 成功。操作被成功接受并处理。 3** : 重定向。需要进一步的操作来完成请求。 4** : 客户端错误。由于客户端请求的错误，服务端无法处理请求。 5** : 服务端错误。服务端在处理请求的过程中发生了错误。 301与302的区别 301和302都代表客户端请求的资源发生了转移。 不同之处在于: 301: 客户端请求的资源已被永久移动到了新的位置，客户端会自动重定向新URL。 客户端以后的请求应该都使用新的URL。 302: 客户端请求的资源被临时移动到了新的位置，客户端可以继续使用原URL。 HTTP请求方法 GET POST PUT DELETE HEAD PATCH OPTION TRACE CONNECT URI,URL,URN URI ( uniform resource identifer):统一资源标识符 URI是一个互联网资源的唯一标识，但它并不代表资源在互联网上的位置， 它对于资源的作用相当于身份证号码对于我们的作用，起一个唯一标识的作用。 URL (uniform resource locator) : 统一资源定位符 URL是URI的子集，URL标识了资源在互联网上的位置， 一个URL只能访问到一个资源， 所以URL有着和URI相同的作用:都可以作为资源的唯一标识符，但URL也有URI没有的作用:对资源的定位。 URN(uniform resource name):统一资源名称 URN也是URI的子集，URN是对资源的命名，不能像URL一样对资源定位。 "},"gitbook_doc/spring-learning/About.html":{"url":"gitbook_doc/spring-learning/About.html","title":"Spring框架部分","keywords":"","body":"关于本部分 spring-learning部分是对spring-learning , SpringMVC 以及 SpringBoot 模块更细分的讲解。 Spring框架常见知识点一览: XMind下载: Java知识梳理之Spring - XMind "},"gitbook_doc/spring-learning/SpringFramework常见知识点.html":{"url":"gitbook_doc/spring-learning/SpringFramework常见知识点.html","title":"SpringFramework常见知识点","keywords":"","body":" Spring常见知识点 什么是Spring Framework? Spring的优缺点 Spring的优点: Spring的缺点: Spring 主要提供了哪些模块? Spring主要使用了哪些设计模式? Spring IOC容器的配置方式有哪些？ BeanFactory和ApplicationContext的区别是什么? 什么是IOC容器和DI依赖注入? Spring依赖注入的方式有几种? 一个bean的定义包含了什么?(BeanDefinition) bean的作用域有哪些? Spring 的扩展点主要有哪些? Spring如何解决循环依赖? 事务的传播行为是什么?有哪些? 什么是AOP? AOP的组成元素和概念有哪些? AOP实现方式有哪些? AspectJ AOP 和 Spring AOP的区别? cglib动态代理和jdk动态代理的区别? Spring常见知识点 什么是Spring Framework? Spring是一个轻量级的，开源的Java应用程序开发框架。它提供的IOC和AOP等核心功能，能够使开发者很方便的开发出松耦合的应用。 Spring的优缺点 Spring的优点: 方便解耦，简化开发 对象统一交由容器管理，实现了资源的可配置和易管理。 并且不再需要显示的编写管理对象的代码，降低了应用的代码量。 AOP支持 Spring 提供 AOP模块，能够很方便的编写出AOP程序. 声明式事务 只需要通过配置或注解就可以完成对事务的支持，而不需要手动的编写事务代码 第三方框架无缝集成 Spring可以很方便的将第三方框架继承到系统中，很灵活。 ... Spring的缺点: 复杂 Spring发展到现在，确认有些复杂了，但是对于它解决的问题来说，复杂已经不算什么了。 效率 Spring内部依赖反射，而反射会带来一定的效率损耗。 Spring 主要提供了哪些模块? core模块提供IOC和DI等核心功能 aop模块提供面向切面编程的实现 web模块提供对web应用的支持 dao模块提供数据库方面的支持 test模块提供测试方面的支持 Spring主要使用了哪些设计模式? Spring使用的设计模式有很多，此处只列举几个常见的 工厂模式 BeanFactory 就是简单工厂的实现，用来创建和获取Bean 单例模式 Spring容器的Bean默认是单例的 代理模式 aop使用的就是代理模式 模板方法模式 jdbcTemplate等就使用模板方法模式 观察者模式 当有事件触发时，该事件的监听者(观察者)就会做出相应的动作。 ... Spring IOC容器的配置方式有哪些？ xml (不再推荐使用) 注解(推荐使用) Java API(和注解一起使用) BeanFactory和ApplicationContext的区别是什么? BeanFactory是最底层，最顶级的IOC容器接口，它提供了对bean的基本操作，属于低级容器。 而ApplicationContext是BeanFactory的应用扩展接口， 提供了比BeanFactory更多高级的功能和扩展接口，属于高级容器。 什么是IOC容器和DI依赖注入? IOC(Inversion Of Control): 控制反转. DI(Dependencies Inject): 依赖注入. Spring IOC容器是Spring框架的核心功能， 它负责管理用户定义好的bean以及bean的生命周期，包括(创建，初始化,使用和销毁)， 而依赖注入是处理bean与bean之间的依赖关系。 控制反转是指原本由用户来管理对象，现在交由容器管理， 不再需要我们手动去处理对象之间的依赖关系了。 Spring依赖注入的方式有几种? setter方法注入: 通过构造器或工厂方法(静态工厂方法或实例bean工厂方法)构造bean所需要的依赖后， 使用setter方法设置bean的依赖。 构造器注入: 构造器的每个参数都可以代表对其他bean的依赖。 一个bean的定义包含了什么?(BeanDefinition) BeanDefinition 是对Bean的定义，它定义了Bean的元数据， 如Bean的Scope，Class，beanName，bean的实例化方式等等。 bean的作用域有哪些? singleton(单例bean): singleton作用域表示在容器中，一个bean只存在一个实例。 每次获取这个bean，都是获取它唯一的实例。 prototype(原型bean): prototype作用域表示如果有一个bean是prototype scope, 那么每次获取该作用域的bean时，容器都会新创建该bean的实例。 request(请求域): 作用于Web应用。request作用域表示如果一个bean是request scope， 那每次HTTP请求，容器都会创建一个该bean的实例。 session(会话域): 作用于Web应用。session作用域表示如果一个bean是session scope， 那么容器为每个session创建一个该bean的实例，当session销毁时，该session内的bean也就销毁了。 application(web应用作用域): 作用于web应用。 application作用域表示如果一个bean是 application scope的， 那么容器会为整个Web应用上下文创建一个该bean的实例，这个实例属于ServletContext级别的。 不同于singleton，singleton是Spring的每个ApplicationContext唯一， 而application是每个ServletContext唯一，对于Web应用来说， ServletContext也只有一个，所以application可以理解为web应用唯一。 websocket(websocket作用域): 应用于web应用。 websocket作用域表示如果一个bean是websocket scope的， 那么该bean作用域整个WebSocket作用域内，也是唯一的。 Spring 的扩展点主要有哪些? 这里列举的并不是很全，因为Spring的扩展点实在是太多了， 但究其根本，还是在bean实例化/初始化前后的扩展。 如果容器中有BeanFactoryPostProcessor,那么执行它的postProcessBeanFactory方法。 该接口是对ConfigurableListableBeanFactory的一个扩展。 实例化bean 注入bean的属性 如果容器中有Aware的实现，那么执行各种Aware扩展实现方法,如BeanNameAware, BeanFactoryAware,ApplicationContextAware等扩展的setXXX方法 如果容器中有BeanPostProcessor，那么执行BeanPostProcessor的postProcessBeforeInitialization方法 执行bean指定的init方法,如果bean还实现了InitializingBean接口, 那么继续执行InitializingBean的afterPropertiesSet方法 如果容器中有BeanPostProcessor，那么执行BeanPostProcessor的postProcessAfterInitialization方法 bean可以被使用了 容器销毁后，执行bean指定的destroy方法，如果bean还实现了DisposableBean接口， 那么继续执行DisposableBean的destroy方法 Spring如何解决循环依赖? 循环依赖是指:A依赖B，并且B依赖A的情况。或者 A依赖B，B依赖C，C依赖A的情况。 构造器注入的循环依赖无法解决，直接抛出BeanCurrentlyInCreationException异常。 容器在创建Bean的时候，会将Bean添加到正在创建的Bean池中，如果在创建Bean的时候， 发现自己已经在创建的Bean池中，就说明Bean陷入循环依赖了， 直接抛出BeanCurrentlyInCreationException异常。 为什么构造器注入不能像Setter方法注入一样解决循环依赖问题? 因为Setter方法注入的前提是首先需要实例化这个对象，而构造器注入的参数正是bean， 怎么实例化，所以无法解决这个问题。 Setter方法注入的循环依赖可以通过缓存解决。 三级缓存： 初始化完成的Bean池； 实例化完成，但是没有填充属性的Bean池； 刚刚实例化完成的Bean的工厂缓存，用于提前曝光Bean。 Setter方法注入时，如果Bean A发现自己依赖于Bean B， 那么将自己实例化后并添加到第三级缓存(Bean 工厂)。 然后再初始化B,检查到B又依赖于A，于是到三级缓存里查询A,那么查询肯定是成功的, 于是将A设置为B的属性。当A初始化时， 发现B已经初始化完成,就可以直接将B设置为A的属性了。 非单例bean不能缓存，无法解决循环依赖: IOC容器是不会缓存非单例bean的，所以无法解决循环依赖问题。 事务的传播行为是什么?有哪些? 事务的传播行为是Spring提供的对事务增强的一种特性，不属于数据库事务特性。 事务的传播行为描述的是当多个事务同时存在时，这些事务该如何被处理。 Spring定义了7种事务的传播行为:REQUIRED,SUPPORTS,MANDATORY,REQUIRES_NEW,NOT_SUPPORTED,NEVER,NESTED REQUIRED: 当一个方法A(REQUIRED)被另一个方法B调用时，如果B没有开启事务， 那么A将自己开启事务,独立运行。如果B开启了事务，那么A就加入到B的事务中去， A和B要么同时成功，要么同时失败。 NESTED: NESTED与REQUIRED很相似。如果方法A(NESTED)被另一个方法B调用，如果B没有事务， 那么A将自己开启一个事务运行。如果B有事务，那么A将作为B的子事务运行，B失败，A也失败，但是A失败却不影响B。 A是作为B的嵌套事务运行的，所以并不会影响B。 SUPPORTS: 当一个方法A(SUPPORTS)被另一个方法B调用时，如果B开启了事务， 那么A就加入到B的事务中去。如果B没有开启事务,那就正常执行，不开启事务。 MANDATORY: 当一个方法A(MANDATORY)被另一个方法B调用时，如果B没有开启事务，那么A将抛出异常。 REQUIRES_NEW: 当一个方法A(REQUIRE_NEW)被另一个方法B调用时，无论B是否有事务， A都会开启自己的事务，与B的事务互不相干，隔离运行。 NOT_SUPPORTED: 当一个方法A(NOT_SUPPORTED)被另一个方法B调用时，如果B有事务，那么B的事务将挂起， 直到A执行完，B再以事务的方式运行。 NEVER: 当一个方法A(NEVER)被另一个方法B调用时，如果B有事务，那么A将抛出异常。 什么是AOP? AOP(Aspect Oriented Programming)面向切面编程，个人认为AOP是一种程序设计思想。 在AOP编程中，将系统的核心逻辑和辅助逻辑分离开来，并将通用的辅助逻辑封装成一个模块， 提高了代码的重用性和程序的可维护性，降低了系统模块之间的耦合度。 AOP的组成元素和概念有哪些? 连接点(join point): 连接点指程序执行的某个位置，能够执行辅助逻辑(通知/增强)。 如方法执行前，方法抛出异常时，方法执行完，方法返回后等等，这些点都被称为连接点。 通知/增强(advice): 通知/增强 可以理解为辅助逻辑，就是在连接点要做的事情。 切点(pointcut): 连接点可以看做是一个方法的执行辅助逻辑的不同位置的集合， 切入点指的就是这个方法。切入点会匹配 通知/增强 需要作用的类或方法。 切面(aspect): 切面是切入点的集合，可以看作是拥有多个切入点的类。 织入(weave): 织入是一个概念。它描述的是将切入点的 通知/增强 应用到连接点的过程。 AOP实现方式有哪些? 常见的AOP实现的方式有代理和织入。 代理分为静态代理和动态代理。 由于静态代理没有动态代理灵活，所以现在几乎都使用动态代理来实现AOP。 以动态代理实现AOP的框架主要有cglib和jdk原生的这2种。 织入可以理解为以操作字节码的方式对class源文件进行修改，从而实现通知/增强。 以织入实现AOP的框架主要有AspectJ。 AspectJ AOP 和 Spring AOP的区别? AspectJ AOP: AspectJ是一整套AOP的工具，它提供了切面语法(切入点表达式)以及织入等强大的功能。 Aspect提供文件和注解2种方式来进行AOP编程， 并且它允许在编译时，编译后和加载时织入， 但是需要使用它特定的ajc编译器才能实现织入这一功能。 Spring AOP: Spring AOP吸收了AspectJ的优点，采用了AspectJ的切入点语法以及AspectJ式的注解， 但却并未使用AspectJ的一整套工具, 而是集cglib和jdk于一体(动态代理)的方式来实现AOP功能，真的很强。 cglib动态代理和jdk动态代理的区别? jdk动态代理: jdk只提供基于接口式的动态代理来对目标进行增强。 cglib动态代理: cglib则是使用字节码技术，动态生成目标的子类，以继承的方式来对目标方法进行重写， 所以如果方法是final的，那么cglib将无法对方法进行增强。 在SpringAOP 中，如果目标类实现了接口，那么默认使用jdk动态代理来实现AOP， 如果目标类没有实现接口，那么将使用cglib来实现AOP。 "},"gitbook_doc/spring-learning/SpringMVC常见知识点.html":{"url":"gitbook_doc/spring-learning/SpringMVC常见知识点.html","title":"SpringMVC常见知识点","keywords":"","body":" Spring MVC常见知识点及源码解析 MVC 是什么 / 有什么优点? 什么是 Spring MVC? Spring MVC的优缺点? 什么是DispatcherServlet? Spring MVC有哪些组件?(见:DispatcherServlet源码) 简述SpringMVC原理/执行流程 Spring MVC 拦截器是什么 / 有什么作用 / 与 Filter有什么区别? @Component @Controller @Service @Repository 区别? Spring MVC常见知识点及源码解析 MVC 是什么 / 有什么优点? MVC是一种设计模式，遵循 模型(Model),视图(View) 和 控制器(Controller)的架构设计。 MVC的优点很明显: 应用层次分明，职责分明，使得系统的耦合性降低，并有利于系统的维护。 什么是 Spring MVC? Spring MVC是一个基于Spring框架的轻量级的MVC Web应用框架。 Spring MVC的优缺点? 优点： 基于Spring，拥有Spring的所有优点 Spring MVC中的组件:角色分明，耦合性低，非常有利于应用的维护。 支持多种视图技术:不仅支持JSP，还支持各种模板视图。 功能特性强大:轻松的文件上传，数据校验与格式转换，异常处理，RESTful风格的API等等。 支持前后端分离。 缺点: Spring MVC是基于Spring的，这既是它的优点也是它的缺点，它必须与Spring一起使用， 个人认为这应该是它最大的一个限制了。 什么是DispatcherServlet? DispatcherServlet是Spring MVC的核心, 可以说SpringMVC就是这个DispatcherServlet。 它是一个Servlet，负责拦截所有的请求，并以调用各种组件来对请求进行分发并处理。 Spring MVC有哪些组件?(见:DispatcherServlet源码) MultipartResolver: 核心组件之一，处理文件上传请求。MultipartResolver负责判断普通请求是否为文件上传请求， 并将普通请求(HttpServletRequest)解析为文件上传请求(MultipartHttpServletRequest)。 LocalResolver: 区域解析器。它主要被用于国际化的资源方面的解析。 ThemeResolver: 主题资源解析器。SpringMVC允许用户提供不同主题，主题就是一系列资源的集合使用这些主题可以提高用户体验。 ViewResolver: 核心组件之一，视图解析器。在Handler执行完请求后，ViewResolver将ModelAndView解析成物理视图， 并对物理视图进行model渲染。 HandlerMapping: 核心组件之一，请求处理器。根据用户的请求来匹配对应的Handler。 HandlerAdapter: 核心组件之一，Handler适配器。使用Handler处理请求，并返回处理后的视图(ModelAndView)。 HandlerExceptionResolver: 核心组件之一，异常处理解析器。在Handler执行请求的过程中可能出现异常， HandlerExceptionResolver就负责处理Handler执行请求过程中的异常。 RequestToViewNameTranslator: 核心组件之一,请求到视图的转换器。根据Request设置最终的视图名,当Handler执行完请求后，它会将Request解析成视图名。 FlashMapManager: 核心组件之一，在请求进行重定向时，FlashMapManager用于保存请求中的参数。 简述SpringMVC原理/执行流程 用户发出的请求被DispatcherServlet拦截。 DispatcherServlet使用HandlerMapping根据请求匹配到相应的Handler。Handler实际上是一个(HandlerMethod)。 DispatcherServlet根据Handler适配合适的HandlerAdapter。 HandlerAdapter使用Handler执行请求，并返回ModelAndView。 使用RequestToViewNameTranslator,HandlerExceptionResolver和ViewResolver等解析器， 解析并渲染ModelAndView，并处理相关异常信息。 渲染后的结果反馈给用户。 Spring MVC 拦截器是什么 / 有什么作用 / 与 Filter有什么区别? HandlerInterceptor: Spring MVC拦截器是Spring MVC提供的对用户请求的目标资源做出拦截扩展的处理器。 它允许在目标方法执行前后以及View渲染后做出处理。 Servlet Filter: Filter是Servlet提供的过滤器，它会在目标方法执行前后做出拦截处理。 要说Servlet Filter和HandlerInterceptor有啥区别， 个人认为除了它们提供的拦截时间不同，目的都是相同的，没啥区别。 @Component @Controller @Service @Repository 区别? @Component 声明一个类为IOC容器的组件，会被IOC容器管理。 而@Controller,@Service和@Repository则拥有更细分的语义。 @Controller通常用于Web应用，被@Controller注解的类，应该作为一个处理请求的控制器。 @Service则是声明一个类为Service类，处理业务逻辑。 被@Repository注解的类，应该被用于处理与数据库交互和持久化相关的功能。 "},"gitbook_doc/spring-learning/SpringMVC源码分析.html":{"url":"gitbook_doc/spring-learning/SpringMVC源码分析.html","title":"SpringMVC源码分析","keywords":"","body":"Spring的源码分析 在分析SpringMVC源码之前我想先回顾一下JavaWeb的知识.JavaWeb的核心是Servlet,一个Servlet对应一个URL, 每次一个Http请求访问,那么对应URL的Servlet就会调用service方法处理。 其实这里我是对SpringMVC的一个复习,所以我先说说就我目前SpringMVC的理解吧。 大家都知道SpringMVC是一个MVC框架,但它还是脱离不了Tomcat,Undertow,Jetty这样的Servlet容器, 因为SpringMVC的核心还是是Servlet。 在初学SpringMVC的时候,各位同学可能都在web.xml里配置过DispatcherServlet,可能当时都没有想过为什么要去配置这个类, 甚至把它拦截的url配置成/**,我当时确实也没有想过,不过后来在学习的时候,已经明白了为什么这样去做, 并且已经明白了SpringMVC的设计思想。 前方高能 SpringMVC通过一个DispatcherServlet拦截所有请求,也就是url为 /** 。 通过拦截所有请求,在内部通过路由匹配的方式把请求转给对应Controller的某个RequestMapping处理。 这就是SpringMVC的基本工作流程,我们传统的JavaWeb是一个Servlet对应一个URL, 而DispatcherServlet是一个Servlet拦截全部URL,并做分发处理. 这也是SpringMVC的设计的精妙之处。 当然上面只是简单的一个流程,在这个过程中肯定有很多细节值得我们细细揣摩。 我是以SpringBoot搭建的调试环境,再加上已经知晓DispatcherServlet是核心, 几乎可以直接定位到这个类了,但是在这之前可以看看DispatcherServlet的父类:FrameworkServlet。 上面说过,Servlet是以service方法处理请求的,所以直接定位到FrameworkServlet的service方法: protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); if (httpMethod != HttpMethod.PATCH && httpMethod != null) { super.service(request, response); } else { //就是你了,骚年 this.processRequest(request, response); } } 一个明显的方法 processRequest就进入了眼帘,看看这个processRequest做了什么吧: protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { ... try { //就是这个方法了 this.doService(request, response); } catch (IOException | ServletException var16) { failureCause = var16; throw var16; } catch (Throwable var17) { failureCause = var17; throw new NestedServletException(\"Request processing failed\", var17); } finally { this.resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) { requestAttributes.requestCompleted(); } this.logResult(request, response, (Throwable)failureCause, asyncManager); this.publishRequestHandledEvent(request, response, startTime, (Throwable)failureCause); } } 可以看到一大坨代码都是try这个doService方法,而这个doService方法肯定是核心了, 但是这个doService方法在FrameworkServlet类中是个abstract方法,所以直接回到 DispatcherServlet找到doService方法： protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { //...此处省略一大坨看不懂的代码 try { //从这里开始分析 this.doDispatch(request, response); } finally { if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted() && attributesSnapshot != null) { this.restoreAttributesAfterInclude(request, attributesSnapshot); } } } 已经找到了目标:doDispatch,听名字这个方法就是做事情的方法了, 所谓的做事情当然就是处理request了,如果各位同学学到现在, 肯定有一个意识:在SpringMVC框架中,所有的核心方法几乎都是do开头, 并且都有2个必要的参数:HttpServletRequest和HttpServletResponse. 但是DispatcherServlet是我接触的所有框架依赖不那么扯的, 就是这个doDispatch方法,它里面几乎包含了我们即将要学习的所有知识了, 所以接下来的核心就是doDispatch方法,各位同学在做源码阅读的时候,建议一行也不要放过(实在看不懂就别为难自己了^-^)。 不过在看DispatcherServlet源码之前,我们最后看下这个DispatcherServlet究竟何德何能, 能够这么厉害,可以完成我们几乎所有的需求方法: public class DispatcherServlet extends FrameworkServlet { .... @Nullable private MultipartResolver multipartResolver; @Nullable private LocaleResolver localeResolver; @Nullable private ThemeResolver themeResolver; @Nullable private List handlerMappings; @Nullable private List handlerAdapters; @Nullable private List handlerExceptionResolvers; @Nullable private RequestToViewNameTranslator viewNameTranslator; @Nullable private FlashMapManager flashMapManager; @Nullable private List viewResolvers; .... } 这就是DispatcherServlet的九大组件,正是这九大组件, DispatcherServlet才能在支持请求和相应的同时,对许多功能和细节做出完善。 再看看doDispatch方法的源码,其实都是上面组件之间的配合完成任务: protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; //核心对象:HanderExecutorChain HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; //管理异步请求 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { try { ModelAndView mv = null; Object dispatchException = null; try { //检查请求是否存在文件上传 processedRequest = this.checkMultipart(request); multipartRequestParsed = processedRequest != request; //getHandler方法是根据请求获取对应的Controller和方法 mappedHandler = this.getHandler(processedRequest); if (mappedHandler == null) { //如果没有获取到匹配的handler,就要么抛出异常要么设置响应码404 this.noHandlerFound(processedRequest, response); return; } //通过handler获取HandlerAdapter,由HandlerAdapter完成方法的执行 HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if ((new ServletWebRequest(request, response)).checkNotModified(lastModified) && isGet) { return; } } //执行拦截器的preHandle方法,它内部如果执行不成功就会先执行afterCompletion,然后返回false,然后程序就退出 //这也是为什么拦截器的前置方法为什么返回false,程序就不会执行我们的逻辑了,等下会分析源码 if (!mappedHandler.applyPreHandle(processedRequest, response)) { return; } //执行方法 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) { return; } //根据Request使用RequestToViewNameTranslator设置默认的视图 this.applyDefaultViewName(processedRequest, mv); //倒序执行拦截器的postHandle方法 mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Exception var20) { dispatchException = var20; } catch (Throwable var21) { dispatchException = new NestedServletException(\"Handler dispatch failed\", var21); } //解析并渲染ModelAndView this.processDispatchResult(processedRequest, response, mappedHandler, mv, (Exception)dispatchException); } catch (Exception var22) { //发生异常会倒序执行afterCompletion方法 this.triggerAfterCompletion(processedRequest, response, mappedHandler, var22); } catch (Throwable var23) { //发生异常会倒序执行afterCompletion方法 this.triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", var23)); } } finally { if (asyncManager.isConcurrentHandlingStarted()) { if (mappedHandler != null) { mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); } } else if (multipartRequestParsed) { this.cleanupMultipart(processedRequest); } } } 首先看看MultiPartResolver是如何检查文件上传请求的吧(checkMultipart方法): protected HttpServletRequest checkMultipart(HttpServletRequest request) throws MultipartException { //关键在isMultpart方法 if (this.multipartResolver != null && this.multipartResolver. isMultipart(request) ) { if (WebUtils.getNativeRequest(request, MultipartHttpServletRequest.class) != null) { if (request.getDispatcherType().equals(DispatcherType.REQUEST)) { this.logger.trace(\"Request already resolved to MultipartHttpServletRequest, e.g. by MultipartFilter\"); } } else if (this.hasMultipartException(request)) { this.logger.debug(\"Multipart resolution previously failed for current request - skipping re-resolution for undisturbed error rendering\"); } else { try { //执行到这里就说明HttpServletRequest是一个文件上传请求,那么就把HttpServletRequest包装成 //MultpartHttpServletRequest返回 return this.multipartResolver.resolveMultipart(request); } catch (MultipartException var3) { if (request.getAttribute(\"javax.servlet.error.exception\") == null) { throw var3; } } this.logger.debug(\"Multipart resolution failed for error dispatch\", var3); } } return request; } 先看看isMultiPart是怎么判断请求是否为文件上传请求的吧(isMultipart方法)： public boolean isMultipart(HttpServletRequest request) { //判断Http请求包头的Content-Type return StringUtils.startsWithIgnoreCase(request.getContentType(), \"multipart/\"); } 着重看看MultipartResolver是如何把普通请求包装成MultipartHttpServletRequest的吧(resolveMultipart方法): public MultipartHttpServletRequest resolveMultipart(HttpServletRequest request) throws MultipartException { //原来我们处理文件上传时拿到的请求是这个请求 return new StandardMultipartHttpServletRequest(request, this.resolveLazily); } 从上面代码分析出,文件上传时,拿到的请求被包装成了StandardMultipartHttpServletRequest, 但是我不再深入,因为MultipartResolver是DispatcherServlet的一个 组件而已,再深入,就跑题了...也不是说跑题,毕竟都是SpringMVC的组成, 只是相信各位同学看到这里已经有能力去看看这个源码了, 可以明确的告诉各位这个地方不存在什么封装之类的曲折,单纯的就是 StandardMultipartHttpServletRequest内部对请求做了解析,并使用集合把解析的结果存储起来了而已 . 回到doDispatch方法,在执行完checkMultipart方法后,就通过getHandler方法, 获取了mappedHandler(HandlerExecutionChain)对象,这个HandlerExecutionChain是什么, 为什么getHandler返回它?先看看HandlerExecutionChain类的源码吧: public class HandlerExecutionChain { private static final Log logger = LogFactory.getLog(HandlerExecutionChain.class); //handler,至于为什么设计成Object类型,我想可能是handler是执行method的关键,所以隐藏了细节,不对外暴露真实类型. //也有可能是在适配Controller的method的过程中需要多种类型的转换,总之不管哪种理由设计成Object类型,只有好好研究了. private final Object handler; @Nullable //一堆 HandlerInterceptor private HandlerInterceptor[] interceptors; @Nullable private List interceptorList; private int interceptorIndex; public HandlerExecutionChain(Object handler) { this(handler, (HandlerInterceptor[])null); } ... } 这个HandlerExecutionChain包含了handler和它的所有HandleInterceptor. 再看看DispatcherServlet是如何根据HttpServletRequest获取HandlerExecutionChain的吧(getHandler方法): protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { if (this.handlerMappings != null) { //之前说过HandlerMapping是DispatcherServlet的9大组件之一,所以这里它遍历HandlerMapping来获取 Iterator var2 = this.handlerMappings.iterator(); while(var2.hasNext()) { HandlerMapping mapping = (HandlerMapping)var2.next(); //调用HandlerMapping的getHandler方法来获取HandlerExecutionChain HandlerExecutionChain handler = mapping.getHandler(request); if (handler != null) { return handler; } } } return null; } 继续看看HandlerMapping的getHandler怎么实现的: public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { //首先就获取Handler Object handler = this.getHandlerInternal(request); if (handler == null) { handler = this.getDefaultHandler(); } if (handler == null) { return null; } else { if (handler instanceof String) { String handlerName = (String)handler; handler = this.obtainApplicationContext().getBean(handlerName); } //这一步就构造了HandlerExecutionChain HandlerExecutionChain executionChain = this.getHandlerExecutionChain(handler, request); if (this.logger.isTraceEnabled()) { this.logger.trace(\"Mapped to \" + handler); } else if (this.logger.isDebugEnabled() && !request.getDispatcherType().equals(DispatcherType.ASYNC)) { this.logger.debug(\"Mapped to \" + executionChain.getHandler()); } if (this.hasCorsConfigurationSource(handler)) { CorsConfiguration config = this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(request) : null; CorsConfiguration handlerConfig = this.getCorsConfiguration(handler, request); config = config != null ? config.combine(handlerConfig) : handlerConfig; executionChain = this.getCorsHandlerExecutionChain(request, executionChain, config); } return executionChain; } } 在说上面一段代码之前,先回顾下, 之前介绍了HandlerExecutionChain由Handler和HandlerInterceptor组成, 那么我们就需要在getHandler里找到这2个关键的地方. 而第一行的getHandlerInternal方法就获取到了Handler, 后面又通过getHandlerExecutionChain直接构造出来了HandlerExecutionChain, 所以可以肯定:getHandlerInternal是根据URL映射找到了Handler getHandlerExecutionChain通过HandlerInterceptor和Handler构造了HandlerExecutionChain对象, 至于我为什么这么肯定, 自然是因为我已经阅读过了源码啦...这里留个空子,希望有缘看到这里的同学能够自己看看实现的细节. 回到doDispatch方法,在获取到handler(HandlerExecutionChain)后, 紧接着判断获取的handler是否为空,如果为空,说明url不对, 没有匹配的handler,就会调用noHandlerFound方法处理. 接下来 DispatcherServlet调用了getHandlerAdapter方法获取了又一个9大组件, 开始的时候介绍过:HandlerMapping是通过Request获取匹配的handler(HandlerExecutionChain)对象, 而HandlerAdapter才是指挥handler干活的, 所以这一步相当重要,看看这个getHandlerAdapter是如何获 HandlerAdapter的吧： protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { if (this.handlerAdapters != null) { Iterator var2 = this.handlerAdapters.iterator(); while(var2.hasNext()) { HandlerAdapter adapter = (HandlerAdapter)var2.next(); //判断HandlerAdapter是否支持handler if (adapter.supports(handler)) { return adapter; } } } throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\"); } 可以看到getHandlerAdapter方法遍历DispatcherServlet的HandlerAdapter集合, 并且调用 HandlerAdapter 的 supports方法来选择合适的 HandlerAdapter,看看 supports 方法具体实现: public final boolean supports(Object handler) { //这里的主要是第一个判断: handler instanceof HandlerMethod return handler instanceof HandlerMethod && this.supportsInternal((HandlerMethod)handler); } //鉴于方便,我直接把supportsInternal方法贴过来 protected boolean supportsInternal(HandlerMethod handlerMethod) { return true; } 可以看到supportsInternal方法对于HandlerMethod类型的参数直接返回true,当然这只是一个HandlerAdapter的实现,但也足够说明问题了,最重要的是第一个判断: handler instanceof HandlerMethod 我们之前说过handler在HandlerExecutionChain内部是一个Object类型, 到了这里为什么就变成了HandlerMethod类型了。 其实早在getHandler那一步就变成了Handler, 到这一步只是适配确认一下.那来看看HandlerMethod是什么吧, 它为什么可以执行我们的RequestMapping方法呢? public class HandlerMethod { ... //bean既可以作为Controller,也可以作为Controller的name private final Object bean; //Controller所在的容器 private final BeanFactory beanFactory; //Controller的 Class private final Class beanType; //关键之处:requestmapping 对应的方法 private final Method method; //桥接方法,我google了下,他是起兼容作用的,应该是与method有互补作用 //这是那位大神的分析:[bregedmethod]( https://www.cnblogs.com/guangshan/p/4661305.html ) private final Method bridgedMethod; //方法的参数 private final MethodParameter[] parameters; //Http状态码 private HttpStatus responseStatus; //不得不说Spring真是流比,像我等之流,只能仰望,返回状态码还得给个原因 private String responseStatusReason; //保留的一份HandlerMethod,这个是解析当前HttpMethod实例的那个HttpMethod private HandlerMethod resolvedFromHandlerMethod; .... } 其实到这里基本就知道SpringMVC到底是怎么通过反射执行我们的方法了, 还是不断的封装和反射,对于这些框架来说,万物皆可封装, 你不服就封装的你服,不管你服不服,我是服了. 再回到doDispatcher方法吧,这个时候已经获取到了需要的handler了, 那么就该执行拦截器的preHandle方法了吧,看接下来的applyPreHandle方法: boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception { HandlerInterceptor[] interceptors = this.getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) { for(int i = 0; i 再回到doDispatcher方法,执行完拦截器的preHandle方法后 ,就直接调用HandlerAdapter的handle方法了： public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //调用了handleInternal方法 return this.handleInternal(request, response, (HandlerMethod)handler); } //handleInteral方法 protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception { //检查是否支持请求的类型和是否需要session this.checkRequest(request); ModelAndView mav; if (this.synchronizeOnSession) { HttpSession session = request.getSession(false); if (session != null) { Object mutex = WebUtils.getSessionMutex(session); synchronized(mutex) { //终于执行目标方法了 ~-~ mav = this.invokeHandlerMethod(request, response, handlerMethod); } } else { mav = this.invokeHandlerMethod(request, response, handlerMethod); } } else { mav = this.invokeHandlerMethod(request, response, handlerMethod); } if (!response.containsHeader(\"Cache-Control\")) { if (this.getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) { this.applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); } else { this.prepareResponse(response); } } return mav; } 直接看 invokeHandlerMethod ,到底是如何执行method的: protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception { ServletWebRequest webRequest = new ServletWebRequest(request, response); ModelAndView var15; try { WebDataBinderFactory binderFactory = this.getDataBinderFactory(handlerMethod); ModelFactory modelFactory = this.getModelFactory(handlerMethod, binderFactory); ServletInvocableHandlerMethod invocableMethod = this.createInvocableHandlerMethod(handlerMethod); if (this.argumentResolvers != null) { invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); } if (this.returnValueHandlers != null) { invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); } invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); Object result; if (asyncManager.hasConcurrentResult()) { result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer)asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); LogFormatUtils.traceDebug(this.logger, (traceOn) -> { String formatted = LogFormatUtils.formatValue(result, !traceOn); return \"Resume with async result [\" + formatted + \"]\"; }); invocableMethod = invocableMethod.wrapConcurrentResult(result); } invocableMethod.invokeAndHandle(webRequest, mavContainer, new Object[0]); if (asyncManager.isConcurrentHandlingStarted()) { result = null; return (ModelAndView)result; } var15 = this.getModelAndView(mavContainer, modelFactory, webRequest); } finally { webRequest.requestCompleted(); } return var15; } 上面这个代码...我哭了....^^^----^^^------^^^,总之我就看到了关于数据绑定, SpringMVC的异步核心管理器,ModelAndViewContainer(看名字就知道,容纳了当前handler的很多数据,恩...) 其实吧,我没哭,只是确实以我的功力, 还是有很多知识没有理解...好吧,我差点哭了.....(说好的轻量级框架呢?) 继续看doDispatcher,逻辑方法执行完了, RequestToViewNameTranslator 就会调用 applyDefaultViewName 方法设置默认的视图. 然后就会执行拦截器的 postHandle方法了: void applyPostHandle(HttpServletRequest request, HttpServletResponse response, @Nullable ModelAndView mv) throws Exception { HandlerInterceptor[] interceptors = this.getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) { for(int i = interceptors.length - 1; i >= 0; --i) { HandlerInterceptor interceptor = interceptors[i]; //执行postHandle方法 interceptor.postHandle(request, response, this.handler, mv); } } } 最后,会通过processDispatchResult方法处理最终的结果: private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception { boolean errorView = false; if (exception != null) { if (exception instanceof ModelAndViewDefiningException) { this.logger.debug(\"ModelAndViewDefiningException encountered\", exception); mv = ((ModelAndViewDefiningException)exception).getModelAndView(); } else { Object handler = mappedHandler != null ? mappedHandler.getHandler() : null; //通过HandlerExceptionResolver处理异常 mv = this.processHandlerException(request, response, handler, exception); errorView = mv != null; } } if (mv != null && !mv.wasCleared()) { //通过View的render方法渲染视图 this.render(mv, request, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } else if (this.logger.isTraceEnabled()) { this.logger.trace(\"No view rendering, null ModelAndView returned.\"); } if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) { if (mappedHandler != null) { mappedHandler.triggerAfterCompletion(request, response, (Exception)null); } } } 这样一份源码也算是勉勉强强过了一遍,其实我发现从这个项目的第一份源码分析起到现在, 其中的一些知识不懂不是我笨,其实顺藤蘑摸瓜倒也好寻到一些线索。 只是像这样的框架我发现我根本没有去了解它的全貌. 我说一个现象:可能有很多同学在分析一份源码的时候, 不知道从哪就蹦出来一个比较陌生的对象,你知道它大概是干什么的, 与哪些你认识的类有关,但是你就是不知道它哪来了,久而久之,就会对这些框架形成敬畏感。 其实我确实对这些框架有敬畏感,毕竟从代码量和各种设计来说,就不得不有敬畏感, 到了他们这个体量,也很难再通过HelloWorld去了解他们的全貌了。 简单总结下SpringMVC工作的流程: SpringMVC通过DispatcherServlet拦截所有的请求, 并通过HandlerMapping与指定的请求找出匹配的handler, handler实际是HandlerMethod对象。 再通过与handler适配的HandlerAdapter执行目标方法, 执行完目标方法后会返回ModelAndView对象, 最后通过ViewResolver解析ModelAndView的View视图。 "},"gitbook_doc/spring-learning/SpringBoot常见知识点.html":{"url":"gitbook_doc/spring-learning/SpringBoot常见知识点.html","title":"SpringBoot常见知识点","keywords":"","body":" SpringBoot常见知识点 什么是SpringBoot? SpringBoot的优点 SpringBoot缺点 SpringBoot的核心注解是哪个? Java API配置的好处 SpringBoot自动配置原理 SpringBoot配置文件加载顺序 SpringBoot 怎么切换生产环境和开发环境配置 SpringBoot是如何推断应用类型和main的 SpringBoot常见知识点 什么是SpringBoot? SpringBoot是Spring开源组织Pivotal为Spring应用提供的一站式解决方案， 简化了Spring应用开发的流程，并提供了非常多的相关生态组件，非常强大。 SpringBoot的优点 容易上手，编码简单: 只要学过Spring/SpringMVC，那么就能很快的编写出一个Spring应用。 内嵌Web容器: SpringBoot无需配置外部Servlet容器就可以轻松的编写出Web应用。 并且SpringBoot支持多种容器，如Tomcat，Undertow，jetty，netty等。 开箱即用，习惯大于配置: 即使你不做任何配置，也能够跑起来一个HelloWorld。 天然集成SpringCloud微服务 SpringBoot缺点 易学难精: 说SpringBoot开启了Java EE的新时代一点也不为过，但是它为我们带来这么多好处的同时， 我们想要真正了解他的全貌，已经是很难了。虽然上手容易，但是SpringBoot的特性之多， 恐怕需要很长时间了才能琢磨清楚。 SpringBoot的核心注解是哪个? 核心注解自然是启动SpringBoot应用的那个注解啦:@SpringBootApplication。 它由 @SpringBootConfiguration(@Configuration) @EnableAutoConfiguration @ComponentScan 3个核心注解组成。 @SpringBootConfiguration等同于@Configuration,它声明一个类为配置类。 @EnableAutoConfiguration是SpringBoot自动配置的核心注解，没有它， SpringBoot的自动配置就不会生效 @ComponentScan 容器组件扫描的注解，负责扫描所有的容器组件，也是最核心的注解之一。 Java API配置的好处 Spring应用有三种配置组件的方式:注解，Java API(Java Config)，XML. 其中注解和Java API的组合，完全可以干掉冗余的XML配置。 初学Spring的时候，见得最多的不是某行代码，而是XML配置啊。 有的同学恨不得要把Spring的约束文件给背下来了~_~。。 而@Configuration和@Bean的到来，无疑是开启了Spring应用配置方式的另一个时代。 Java配置的最大好处就是配置灵活，编写简单，其次是修改方便。 但是个人认为还是有缺点的，因为使用Java配置就意味着你需要创建很多的配置类， 如果把所有配置都写在一个类里面，那会变得很难维护，所以较好的选择是不同的配置， 创建不同的类，这样易于维护。 XML配置的优点就是很通俗易懂，不然XML语言不可能成为通用的数据传输语言。 但是想想一个应用里的配置何其多，这就是它最大的缺点:繁琐。 SpringBoot自动配置原理 @EnableAutoConfiguration使得容器会读取类路径下 META-INF/spring.factories 文件， 并导入文件中声明的自动配置类。 spring.factories里定义的都是扩展组件的自动配置类, 这些配置类往往都会依赖于XXXProperties.java的属性类， 我们在application.properties/yml文件里配置的属性， 就是配置的这些XXXProperties.java类的属性。 SpringBoot自动配置体现的是SPI(Service Provider Interface)的思想， 包括JDK中都大量使用到了这种思想。关于SPI可见: 知乎-SPI SpringBoot配置文件加载顺序 application.properties application.yml ... SpringBoot 怎么切换生产环境和开发环境配置 因为springboot优先读取application.properties, 所以可以在application.properties中配置spring.profile.active = dev/pro/... 来进行配置文件的切换。 SpringBoot是如何推断应用类型和main的 在SpringBoot中，有一个WebApplicationType的枚举类定义了3种Web类型: NONE SERVLET(Servlet 类型) REACTIVE(响应式类型)， SpringBoot在启动时会根据对应类型的核心类是否存在，据此判断应用的类型。 而判断main方法是根据异常堆栈来判断的。 "},"gitbook_doc/orm-learning/About.html":{"url":"gitbook_doc/orm-learning/About.html","title":"ORM框架部分","keywords":"","body":"关于本部分 orm-learning部分是对orm-learning 模块更细分的讲解。 ORM常见知识点一览: XMind下载: Java知识梳理之ORM - XMind "},"gitbook_doc/orm-learning/ORM.html":{"url":"gitbook_doc/orm-learning/ORM.html","title":"ORM","keywords":"","body":"ORM(Object Relational Mapping) 什么是ORM? Object Relational Mapping : 对象关系映射。 它是一种解决数据库与简单对象(entity)之间关系映射的技术。 简单理解: ORM通过简单对象(entity) 与 数据库之间的映射关系，将描述对象持久化到数据库中。 JDBC的缺点 频繁创建数据库连接,浪费连接资源,不易维护 SQL语句存在硬编码，不易维护 结果集处理过程繁琐 "},"gitbook_doc/orm-learning/Mybatis.html":{"url":"gitbook_doc/orm-learning/Mybatis.html","title":"Mybatis","keywords":"","body":"Mybatis 什么是Mybatis? Mybatis是一款优秀的轻量级的半ORM框架。 Mybatis最大的优点就是无需像JDBC一样采用硬编码的方式进行持久化操作， 它允许我们定制SQL和对象与数据库之间的高级映射关系，极大的提高了持久化操作的灵活性。 为什么说Mybatis是半ORM框架? 与Hibernate不同，Hibernate属于全自动ORM框架，无需手写SQL， 且能够自动建立对象与数据库之间的映射关系，很方便。 但无需手写SQL也就意味着SQL优化方面可能不如Mybatis那么出色。 Mybatis则属于半自动ORM框架，因为Mybatis仅仅给我们省去了JDBC硬编码的形式， 但是在定义SQL和建立对象持久化关系方面，仍然给了我们很大自由， 它相对Hibernate更加灵活，扩展性更强。 "},"gitbook_doc/orm-learning/Mybatis常见知识点.html":{"url":"gitbook_doc/orm-learning/Mybatis常见知识点.html","title":"Mybatis常见知识点","keywords":"","body":" Mybatis常见知识点 Mybatis优点 Mybatis缺点 Mybatis适用场景 Mybatis架构 Mybatis SQL执行流程 Executor的类型 什么是延迟加载? 延迟加载原理 ${} 和 #{}的区别 Mybatis 模糊查询LIKE怎么写 Mybatis是如何获取生成的主键的? Mybatis动态SQL是什么? Mybatis插件原理 Mybatis一级缓存 一级缓存的原理 使得Mybatis一级缓存失效的方法 Mybatis二级缓存 Mybatis二级缓存的原理 Mybatis缓存的缺点 Mybatis常见知识点 Mybatis优点 消除了JDBC硬编码，提高了应用的扩展性 自定义SQL和对象持久化关系，带来了灵活性 SQL和对象持久化关系都在配置里，解除了SQL与程序之间的耦合性 Mybatis缺点 配置繁琐 Mybatis适用场景 功能复杂的应用: Mybatis足够的灵活，这保证了它能够面对较为复杂的应用场景。 考虑SQL优化的应用: SQL优化是一个很常见的问题，Mybatis允许我们自己编写SQL，这样一来就可以轻松的更新和优化SQL了。 Mybatis架构 Mybatis架构图: Configuration: Configuration可以说是贯穿整个Mybatis生命周期的一个核心配置组件, 它存储着Mybatis所有需要的属性和组件。 从解析阶段开始，到获取Mapper，都需要Configuration。 Configuration内部属性一览： SQLSession: SQLSession是Mybatis最顶级的API接口， 它封装了SQL的增删查改功能，但最终还是交由Executor去执行逻辑。 Executor: Executor执行器，是Mybatis的核心组件之一， 它负责调度StatementHandler来维护和执行SQL。 StatementHandler: StatementHandler负责JDBC的statement的操作，如SQL入参，执行SQL，封装结果集。 ParameterHandler: ParameterHandler负责将用户传递的参数转换成statement所需的参数。 TypeHandler: TypeHandler负责Java数据类型与JDBC数据类型的转换。 ResultSetHandler: ResultSetHandler负责处理statement执行后返回的结果集。 Mybatis SQL执行流程 配置解析: 由XML解析器解析配置文件(总配置文件，mapper文件),并将解析的结果保存到Configuration中。 使用配置环境信息构建SQLSessionFactory工厂: SQLSessionFactory提供了构建SQLSession的多种方式，可以指定Executor的类型和事务隔离级别等。 使用SQLSessionFactory创建SQLSession会话: SQLSessionFactory创建SQLSession后，其实是创建的DefaultSQLSession，它包含了Mybatis的环境配置Configuration和Executor执行器。 使用SQLSession获取用户需要的Mapper类: Mybatis底层是使用了jdk动态代理来实现目标Mapper的执行的，获取Mapper实际上是获取Mapper的代理类。 使用MapperProxy执行目标方法: 实际上最终是Executor调度StatementHandler执行statement。 Executor调用StatementHandler对Statement做出处理(包括参数处理，执行，结果集处理)。 StatementHandler调用ParameterHandler装配SQL参数并执行,最后使用ResultSetHandler封装结果集返回。 Executor的类型 SimpleExecutor: 简单执行器。 每次执行SQL就开启一个statement，用完后就关闭掉。 ReuseExecutor: 可重用的执行器。每次执行SQL先去缓存(Map)中找SQL对应的statement， 如果不存在就新创建statement，用完后并不关闭，而是放入Map缓存中，以待下次使用。 BatchExecutor: 批处理执行器。执行SQL时，会将statement添加到批处理中，等到最终executeBatch时，一起执行。 什么是延迟加载? 延迟加载又称按需加载，即在关联查询中(一对一或一对多)， 如果指定了延迟加载，那么并不会一次就把对象关联的数据查出来， 而是等到对象需要使用关联的数据时才会进行查询。 延迟加载原理 Mybatis的底层原理是ResultSetHandler在封装结果时， 判断对象的属性是否有关联查询(嵌套查询)，如果有，则使用动态代理创建该对象作为结果。 当对象需要使用它的某个属性时，比如a调用getB方法， 那么getB方法就会进入代理方法，如果getB为空，就查询B，并setB，这样就可以获取到a的B属性了。 ${} 和 #{}的区别 ${} 是将传入的参数直接显示在SQL中;#{} 把传入的参数当做字符串，会给参数加上引号 假设有2条SQL如下: 1. SELECT * FROM table WHERE id =${id}; 2. SELECT * FROM table WHERE id = #{id}; 如果传入的参数为 1 , 那么第一条SQL会被拼接成: SELECT * FROM table WHERE id = 1; 第二条SQL会被编译成: SELECT * FROM table WHERE id = \"1\"; ${}属于拼接符，需要进行字符串拼接;#{} 属于占位符，需要预编译 ${} 则不能防止SQL注入;#{} 可以在很大程度上预防SQL注入 假如有一条SQL: SELECT * FROM table WHERE id = ${id} 假设传入的id为: 1 OR 1 = 1 ,那么字符串拼接后,SQL为: SELECT * FROM table WHERE id = 1 OR 1 = 1; 这条SQL无论如何都会执行成功。 如果将 ${id} 改为 #{id},那么经过预编译后，SQL为: SELECT * FROM table WHERE id = \"1 OR 1 = 1\"; 可以看到: #{} 是将参数作为一个字符串为条件的，这样就可以避免 OR 生效，防止SQL注入。 Mybatis 模糊查询LIKE怎么写 SELECT * FROM table WHERE name LIKE '%${name}%' (有注入风险) SELECT * FROM table WHERE name LIKE \"%\"#{name}\"%\" SELECT * FROM table WHERE name LIKE CONCAT('%',#{name},'%') Bind标签: select * from table where name like #{fuzzyName} Mybatis是如何获取生成的主键的? Mybatis有一个KeyGenerator接口，这个接口专门用于获取数据库生成的主键。 但其核心原理还是使用的JDBC 的 API : Statement的 getGeneratedKeys 方法获取的。 Mybatis动态SQL是什么? Mybatis允许我们在mapper文件内，以标签的形式编写动态SQL，用于逻辑判断和SQL拼接等功能。 Mybatis动态标签有: trim / where / set / if / choose / otherwise / bind / foreach 等。 实际上Mybatis的动态标签是依赖于OGNL的。 Mybatis插件原理 Mybatis允许我们编写插件对它核心的组件： Executor , StatementHandler, ParameterHandler, ResultSetHandler 这些核心组件的扩展 Mybatis底层实际上是使用jdk动态代理包装后的组件带替它原生的组件。 当执行这些组件的方法时，就会执行Interceptor的intercept方法。 当然，只是当执行我们指定要拦截的方法时，才会执行intercept方法。 见:Configuration: Mybatis一级缓存 一级缓存又称本地缓存，它属于SqlSession级别的缓存，默认是开启的。每个SqlSession都有自己的缓存。 同一个SqlSession查询到的数据都会放入它自己的缓存中，如果之后需要获取相同的数据， 那么会先从缓存中查找，如果没有才会去查询数据库，这样就降低了数据库的压力。 Mybatis一级缓存流程: Mybatis一级缓存源码: 一级缓存的原理 对于BaseExecutor来说，它内部维护了一个叫localCache的PerpetualCache对象。 PerpetualCache实现了Cache接口，它内部使用HashMap进行缓存。 所以可以简单理解为Mybatis的一级缓存是由HashMap存储的。 Mybatis一级存实现: 使得Mybatis一级缓存失效的方法 如果SQL相同，但是SQL的条件或参数不同，缓存会失效 在两次查询操作中间，如果进行了增删改操作，会清空本地缓存 不同的SqlSession，缓存会失效 手动清空SqlSession的缓存 Mybatis二级缓存 二级缓存又称全局缓存，它属于mapper级别的缓存,默认是关闭的，需要指定配置和标签才会开启。 多个SqlSession操作同一个Mapper是可以共享一个二级缓存的，但是要求Sql会话必须属于同一个Mapper。 Mybatis二级缓存流程: Mybatis二级缓存的原理 Mybatis二级缓存的Executor使用的是CachingExecutor， 在原生的Executor执行查询操作之前，它会先从二级缓存中查询，如果查询不到才会从一级缓存或数据库中查询。 Configuration创建CachingExecutor: Mybatis二级缓存源码: Mybatis缓存的缺点 Mybatis缓存设计缺陷: Mybatis的一级缓存是使用HashMap实现的，并没有指定容量限制， 虽然可以提高查询效率，但是设计上还有所欠缺。 容易引起脏读: Mybatis的缓存是属于Java进程内的缓存，在分布式环境下，缓存的不一致， 很容易引起数据的脏读。建议还是使用第三方容器，如Redis和Memcached等中间件存储缓存数据。 "},"gitbook_doc/orm-learning/Mybatis源码分析.html":{"url":"gitbook_doc/orm-learning/Mybatis源码分析.html","title":"Mybatis源码分析","keywords":"","body":" Mybatis源码分析 1. 解析配置文件，创建SQLSessionFactory 2. 开启java程序和数据库之间的会话： 3. 获取mapper代理对象: 4. 执行mapper接口方法: mybatis源码总结 Mybatis源码分析 1. 解析配置文件，创建SQLSessionFactory InputStream inputStream = CommonTest.class.getClassLoader().getResourceAsStream(\"mybatis-configuration.xml\"); SQLSessionFactory SQLSessionFactory = new SQLSessionFactoryBuilder().build(inputStream); 这一步首先读取了mybatis的configuration xml配置文件,用这个流构造了Factory的Builder,它底层是使用Mybatis自己的XMLConfigBuilder解析器去解析了这个Configuration文件, 然后调用了解析器的parse方法,SQLSessionFactory就被构造出来了: public SQLSessionFactory build(InputStream inputStream, String environment, Properties properties) { SQLSessionFactory var5; try { //文件解析器 XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); //构造SQLSessionFactory var5 = this.build(parser.parse()); } catch (Exception var14) { throw ExceptionFactory.wrapException(\"Error building SQLSession.\", var14); } finally { ErrorContext.instance().reset(); try { inputStream.close(); } catch (IOException var13) { } } return var5; } 根据上面代码可知,SQLSessionFactory被创建的核心是 XMLConfigBuilder的 parse方法, 也就是解析文件的那个步骤,它又是怎么解析的呢? 初次学Mybatis的时候,配置的那个Configuration全局文件里有很多属性对吧,各种节点, environment,mapper,setting...的,可想它内部肯定是对这些节点做了解析的: private void parseConfiguration(XNode root) { try { this.propertiesElement(root.evalNode(\"properties\")); Properties settings = this.settingsAsProperties(root.evalNode(\"settings\")); //解析全局配置文件的各个节点,并加载配置 this.loadCustomVfs(settings); this.loadCustomLogImpl(settings); this.typeAliasesElement(root.evalNode(\"typeAliases\")); this.pluginElement(root.evalNode(\"plugins\")); this.objectFactoryElement(root.evalNode(\"objectFactory\")); this.objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); this.reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); this.settingsElement(settings); this.environmentsElement(root.evalNode(\"environments\")); this.databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); this.typeHandlerElement(root.evalNode(\"typeHandlers\")); //解析mapper的各个元素(SQL,resultmap......) this.mapperElement(root.evalNode(\"mappers\")); } catch (Exception var3) { throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + var3, var3); } } 从上面代码可以分析,其实解析是大概分为2个部分的,一个是解析全局配置文件里的属性, 一个是解析mapper文件的各个属性,对已经学过mybatis的同学来说, 都知道mybatis底层是使用了动态代理模式来操作接口方法的,那么从第二个部分:解析mapper的部分就尤为重要了. 先看第一个部分,其实其第一个部分最重要的一点就是分析出了,mybatis所有的属性, 配置全部由一个Configuration对象保存了起来,随便抽一个方法: private void settingsElement(Properties props) { this.configuration.setAutoMappingBehavior(AutoMappingBehavior.valueOf(props.getProperty(\"autoMappingBehavior\", \"PARTIAL\"))); this.configuration.setAutoMappingUnknownColumnBehavior(AutoMappingUnknownColumnBehavior.valueOf(props.getProperty(\"autoMappingUnknownColumnBehavior\", \"NONE\"))); this.configuration.setCacheEnabled(this.booleanValueOf(props.getProperty(\"cacheEnabled\"), true)); this.configuration.setProxyFactory((ProxyFactory)this.createInstance(props.getProperty(\"proxyFactory\"))); this.configuration.setLazyLoadingEnabled(this.booleanValueOf(props.getProperty(\"lazyLoadingEnabled\"), false)); this.configuration.setAggressiveLazyLoading(this.booleanValueOf(props.getProperty(\"aggressiveLazyLoading\"), false)); this.configuration.setMultipleResultSetsEnabled(this.booleanValueOf(props.getProperty(\"multipleResultSetsEnabled\"), true)); this.configuration.setUseColumnLabel(this.booleanValueOf(props.getProperty(\"useColumnLabel\"), true)); this.configuration.setUseGeneratedKeys(this.booleanValueOf(props.getProperty(\"useGeneratedKeys\"), false)); ...... } 再看看Configuration类的属性,就印证了之前说过的, Configuration就是一个贯穿的mybatis整个生命周期的核心配置类: public class Configuration { protected Environment environment; protected boolean safeRowBoundsEnabled; protected boolean safeResultHandlerEnabled; protected boolean mapUnderscoreToCamelCase; protected boolean aggressiveLazyLoading; protected boolean multipleResultSetsEnabled; protected boolean useGeneratedKeys; protected boolean useColumnLabel; protected boolean cacheEnabled; protected boolean callSettersOnNulls; protected boolean useActualParamName; protected boolean returnInstanceForEmptyRow; protected String logPrefix; protected Class logImpl; protected Class vfsImpl; protected LocalCacheScope localCacheScope; protected JdbcType jdbcTypeForNull; protected Set lazyLoadTriggerMethods; ...... ...... } 之前说过,XMLConfigBuilder负责解析mybatis全局配置文件,而解析阶段又大致分为2个阶段:解析基本属性; 解析mapper文件.解析的基本属性都存放在了全局的Configuration之中. 再看mapperElement方法,也就是开始解析的那个方法,可以直接锁定XMLMapperBuilder类, 看这个类的名字就知道它是解析mapper文件的: private void mapperElement(XNode parent) throws Exception { if (parent != null) { Iterator var2 = parent.getChildren().iterator(); while(true) { while(var2.hasNext()) { XNode child = (XNode)var2.next(); String resource; if (\"package\".equals(child.getName())) { resource = child.getStringAttribute(\"name\"); this.configuration.addMappers(resource); } else { resource = child.getStringAttribute(\"resource\"); String url = child.getStringAttribute(\"url\"); String mapperClass = child.getStringAttribute(\"class\"); XMLMapperBuilder mapperParser; InputStream inputStream; if (resource != null && url == null && mapperClass == null) { ErrorContext.instance().resource(resource); inputStream = Resources.getResourceAsStream(resource); //开始解析mapper文件 mapperParser = new XMLMapperBuilder(inputStream, this.configuration, resource, this.configuration.getSQLFragments()); mapperParser.parse(); } else if (resource == null && url != null && mapperClass == null) { ErrorContext.instance().resource(url); inputStream = Resources.getUrlAsStream(url); mapperParser = new XMLMapperBuilder(inputStream, this.configuration, url, this.configuration.getSQLFragments()); mapperParser.parse(); } else { if (resource != null || url != null || mapperClass == null) { throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\"); } Class mapperInterface = Resources.classForName(mapperClass); this.configuration.addMapper(mapperInterface); } } } return; } } } 在说解析mapper文件之前,先想想mapper文件里有什么,最核心的就那几个:resultMap,statement(也就是SQL), cache缓存,那么XMLMapperBuilder肯定也是围绕那个几个去解析的,或者还解析了其他的东西: public void parse() { if (!this.configuration.isResourceLoaded(this.resource)) { //这里是解析Mapper文件的核心,它内部把Mapper的select,delete,update,insert这些 //标签添加到了MapperStatement内,也就是SQL语句 this.configurationElement(this.parser.evalNode(\"/mapper\")); this.configuration.addLoadedResource(this.resource); //这一步也是非常重要的,它绑定了mapper文件的命名空间 this.bindMapperForNamespace(); } //解析还没有解析的各个元素 this.parsePendingResultMaps(); this.parsePendingCacheRefs(); this.parsePendingStatements(); } 其实mybatis解析mapper文件的步骤还是比较深入的,这里由于篇幅关系,怕说长了,就脱离此文的目的,还是以理解为主,直到mybatis做了哪些事情就行,但还是需要去看看mybatis到底是如何解析mapp文件的,也就是 上面的: this.configurationElement(this.parser.evalNode(\"/mapper\")); ...... 最后,回到解析Configuration文件的起点,解析完文件后,SQLSessionFactory就被build方法构造出来了,其实他是个DefaultSQLSessionFactory: public SQLSessionFactory build(Configuration config) { return new DefaultSQLSessionFactory(config); } 总结下SQLSessionFactory被创建的过程: 首先Mybatis使用XMLConfigBuilder文件解析器,解析全局配置文件,XMLMapperBuilder,解析mapper文件,解析完后将所有的属性封装在了Configuration对象中,然后使用这个全局的Configuration对象构造了DefaultSQLSessionFactory. 2. 开启java程序和数据库之间的会话： SQLSession SQLSession = SQLSessionFactory.openSession(); 从第一步创建SQLSessionFactory的过程可知,SQLSessionFactory是一个DefaultSQLSessionFactory,所以openSession也是调用了DefaultSQLSessionFactory的openSession: public SQLSession openSession() { return this.openSessionFromDataSource(this.configuration.getDefaultExecutorType(), (TransactionIsolationLevel)null, false); } 可以看到openSession是调用了openSessionFromDataSource方法,那它是怎么实现的呢: private SQLSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; DefaultSQLSession var8; try { Environment environment = this.configuration.getEnvironment(); //事物管理 TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //核心Executor执行器 Executor executor = this.configuration.newExecutor(tx, execType); //SQLSession就是DefaultSQLSession var8 = new DefaultSQLSession(this.configuration, executor, autoCommit); } catch (Exception var12) { this.closeTransaction(tx); throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + var12, var12); } finally { ErrorContext.instance().reset(); } 从上面代码可以看出,SQLSession是DefaultSQLSession,然后还创建了一个Executor这个核心的执行器对象,那么首先看看这个Executor是什么,为什么说它是核心呢？ 首先看看它内部的方法吧: public interface Executor { ResultHandler NO_RESULT_HANDLER = null; int update(MappedStatement var1, Object var2) throws SQLException; List query(MappedStatement var1, Object var2, RowBounds var3, ResultHandler var4, CacheKey var5, BoundSQL var6) throws SQLException; List query(MappedStatement var1, Object var2, RowBounds var3, ResultHandler var4) throws SQLException; Cursor queryCursor(MappedStatement var1, Object var2, RowBounds var3) throws SQLException; List flushStatements() throws SQLException; void commit(boolean var1) throws SQLException; void rollback(boolean var1) throws SQLException; ... ... } 从Executor内部方法可以看出,它负责执行Statement的执行操作.既然它是一个接口,那么必然有对应的实现类,这里先看configuration的newExecutor方法是怎么创建它的吧: public Executor newExecutor(Transaction transaction, ExecutorType executorType) { executorType = executorType == null ? this.defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Object executor; //批处理的Executor if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); } //可复用的Executor else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } //简单的Executor,如果不做配置,那么就默认是它了 else { executor = new SimpleExecutor(this, transaction); } //缓存Executor,这里就是二级缓存的关键之处,把已经创建好的Executor,装成CachingExecutor if (this.cacheEnabled) { executor = new CachingExecutor((Executor)executor); } //插件拓展,原来插件是在创建Executor的时候被封装的. Executor executor = (Executor)this.interceptorChain.pluginAll(executor); return executor; } 从上面代码就可以分析出:创建SQLSession的时机其实是创建Executor的时机,也是封装plugin的时机, 也可以猜测Executor就是Mybatis的核心组件之一,负责执行一系列的SQL(Statement). 总结下第二步获取SQLSession的过程: 使用DefaultSQLSessionFactory的Configuration创建出对应类型的Executor, 并封装配置中的插件,再使用Executor和Configuration创建DefaultSQLSession, 由此可见Configuration从被构建出来,流转到了DefaultSQLSession之中. 3. 获取mapper代理对象: PersonMapper personMapper = SQLSession.getMapper(PersonMapper.class); 已经知到了上面返回的PersonMapper是一个MapperProxy对象,那么它是怎么被创建出来的呢? 回想下上面的几个步骤,DefaultSQLSession包含了Configuration,而Configuration是解析的全局配置文件和mapper文件被构造出来的,Configuration也包含了相应的属性, 所以MapperProxy应该也是从Configuration获取: public T getMapper(Class type) { return this.configuration.getMapper(type, this); } ----------------------------------------------------------- public T getMapper(Class type, SQLSession SQLSession) { return this.mapperRegistry.getMapper(type, SQLSession); } 可以看到最终是由MapperRegistry对象获取的,那MapperRegistry是如何获取的呢: ... private final Map, MapperProxyFactory> knownMappers = new HashMap(); public T getMapper(Class type, SQLSession SQLSession) { //获取mapper接口对应的工厂 MapperProxyFactory mapperProxyFactory = (MapperProxyFactory)this.knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); } else { try { //使用工厂创建mapper接口 return mapperProxyFactory.newInstance(SQLSession); } catch (Exception var5) { throw new BindingException(\"Error getting mapper instance. Cause: \" + var5, var5); } } } MapperRegistry内部有一个map,保存着mapper接口的class到相应的MapperProxyFactory的工厂,当我们需要获取某个mapper接口的时候,就利用相对的工厂创建mapper接口代理对象. 需要搞清楚的是MapperProxyFactory是如何创建Mapper接口代理对象的呢?直接锁定newInstance方法: protected T newInstance(MapperProxy mapperProxy) { //jdk动态代理 return Proxy.newProxyInstance(this.mapperInterface.getClassLoader(), new Class[]{this.mapperInterface}, mapperProxy); } public T newInstance(SQLSession SQLSession) { //首先创建MapperProxy对象,MapperProxy对象实现了InvocationalHandler接口,所以它可以被jdk动态代理 MapperProxy mapperProxy = new MapperProxy(SQLSession, this.mapperInterface, this.methodCache); return this.newInstance(mapperProxy); } 上面代码就不解释了,直接总结第3步吧: Configuration从MapperRegistry里获取对应的Mapper接口的代理工厂MapperProxyFactory,MapperProxyFactory使用jdk动态代理创建Mapper接口的动态代理对象. 4. 执行mapper接口方法: personMapper.selectPersonById(1L); 上面分析到由SQLSession获取的Mapper对象其实是MapperProxyFactory创建的MapperProxy代理对象,那么SQL代码的执行也肯定是在MapperProxy类的invoke中了,所以直接锁定MapperProxy类的invoke方法: public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { //如果是Object类的方法 if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } //jdk8后的接口允许默认方法,所以在这里做判断 if (method.isDefault()) { if (privateLookupInMethod == null) { return this.invokeDefaultMethodJava8(proxy, method, args); } return this.invokeDefaultMethodJava9(proxy, method, args); } } catch (Throwable var5) { throw ExceptionUtil.unwrapThrowable(var5); } MapperMethod mapperMethod = this.cachedMapperMethod(method); //真正执行Statement的入口 return mapperMethod.execute(this.SQLSession, args); } 根据invoke方法可以分析出,invoke方法执行的也就是MapperMethod的execute方法,那MapperMethod是什么呢?先猜下：在mybatis所有核心组件基本都是xxxHandler命名,所有与接口有关的基本都是mapperxx命名,mapperProxy是接口代理对象,mapperMethod就有可能是接口的执行方法. 看下mapperProxy的属性: public class MapperProxy implements InvocationHandler, Serializable { private static final long serialVersionUID = -6424540398559729838L; private static final int ALLOWED_MODES = 15; private static final Constructor lookupConstructor; private static final Method privateLookupInMethod; private final SQLSession SQLSession; private final Class mapperInterface; //存储着mapperProxy对应接口的方法 private final Map methodCache; .... } 再看刚才在invoke方法里的一个细节: public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { ..... //根据接口要调用的方法,获取对应的mapperMethod MapperMethod mapperMethod = this.cachedMapperMethod(method); //使用获取到的mapperMethod执行SQL return mapperMethod.execute(this.SQLSession, args); } 已经可以确定了,在调用mapper接口方法的时候,mapperProxy内部已经维护了对应接口的所有方法,只等我们调用的时候execute执行了. 那mapperMethod是如何执行的呢? public Object execute(SQLSession SQLSession, Object[] args) { Object result; Object param; switch(this.command.getType()) { //insert操作 case INSERT: param = this.method.convertArgsToSQLCommandParam(args); result = this.rowCountResult(SQLSession.insert(this.command.getName(), param)); break; //update操作 case UPDATE: param = this.method.convertArgsToSQLCommandParam(args); result = this.rowCountResult(SQLSession.update(this.command.getName(), param)); break; //delete操作 case DELETE: param = this.method.convertArgsToSQLCommandParam(args); result = this.rowCountResult(SQLSession.delete(this.command.getName(), param)); break; //select操作 case SELECT: if (this.method.returnsVoid() && this.method.hasResultHandler()) { this.executeWithResultHandler(SQLSession, args); result = null; } else if (this.method.returnsMany()) { result = this.executeForMany(SQLSession, args); } else if (this.method.returnsMap()) { result = this.executeForMap(SQLSession, args); } else if (this.method.returnsCursor()) { result = this.executeForCursor(SQLSession, args); } else { param = this.method.convertArgsToSQLCommandParam(args); result = SQLSession.selectOne(this.command.getName(), param); if (this.method.returnsOptional() && (result == null || !this.method.getReturnType().equals(result.getClass()))) { result = Optional.ofNullable(result); } } break; //flush操作 case FLUSH: result = SQLSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + this.command.getName()); } if (result == null && this.method.getReturnType().isPrimitive() && !this.method.returnsVoid()) { throw new BindingException(\"Mapper method '\" + this.command.getName() + \" attempted to return null from a method with a primitive return type (\" + this.method.getReturnType() + \").\"); } else { return result; } } 我的selectPersonById方法是SELECT,就看看SELECT执行的逻辑吧： case SELECT: //如果方法没有返回值 if (this.method.returnsVoid() && this.method.hasResultHandler()) { this.executeWithResultHandler(SQLSession, args); result = null; } //如果方法返回集合 else if (this.method.returnsMany()) { result = this.executeForMany(SQLSession, args); } //如果方法返回map else if (this.method.returnsMap()) { result = this.executeForMap(SQLSession, args); } //返回游标类 else if (this.method.returnsCursor()) { result = this.executeForCursor(SQLSession, args); } else { //正常普通返回值 //抓换 param = this.method.convertArgsToSQLCommandParam(args); result = SQLSession.selectOne(this.command.getName(), param); if (this.method.returnsOptional() && (result == null || !this.method.getReturnType().equals(result.getClass()))) { result = Optional.ofNullable(result); } } 锁定最后一个 selectOne 方法: public List selectList(String statement, Object parameter, RowBounds rowBounds) { List var5; try { //获取mapperStatement MappedStatement ms = this.configuration.getMappedStatement(statement); //执行器执行 var5 = this.executor.query(ms, this.wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception var9) { throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + var9, var9); } finally { ErrorContext.instance().reset(); } return var5; } 可以看到SQLSession的select还是代理到Executor的query方上了: public List query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { //获取SQL BoundSQL boundSQL = ms.getBoundSQL(parameter); //创建二级缓存的key,这个key非常长 CacheKey key = this.createCacheKey(ms, parameter, rowBounds, boundSQL); //查询 return this.query(ms, parameter, rowBounds, resultHandler, key, boundSQL); } 继续深入重载的query方法: public List query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSQL boundSQL) throws SQLException { ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (this.closed) { throw new ExecutorException(\"Executor was closed.\"); } else { //上一个缓存已经查询完成,并且标注了FlushCache=true的属性,那么清空本地缓存 if (this.queryStack == 0 && ms.isFlushCacheRequired()) { this.clearLocalCache(); } List list; try { ++this.queryStack; //如果没有指定resultHandler,那么线程本地缓存查询 list = resultHandler == null ? (List)this.localCache.getObject(key) : null; if (list != null) { //如果有缓存,就覆盖当前参数值,但只针对CALLABLE this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSQL); } else { //从数据库查询 list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSQL); } } finally { --this.queryStack; } if (this.queryStack == 0) { Iterator var8 = this.deferredLoads.iterator(); while(var8.hasNext()) { BaseExecutor.DeferredLoad deferredLoad = (BaseExecutor.DeferredLoad)var8.next(); deferredLoad.load(); } this.deferredLoads.clear(); //查询完清除缓存 if (this.configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) { this.clearLocalCache(); } } return list; } } 继续深入 queryFromDatabase 方法,看Executor到底是怎么查询的: private List queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSQL boundSQL) throws SQLException { this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER); List list; try { //又是一个接口方法,有需要深入 list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSQL); } finally { this.localCache.removeObject(key); } this.localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) { this.localOutputParameterCache.putObject(key, parameter); } return list; } 继续看doQuery方法,因为我没有指定Executor的类型,所以这个doQuery肯定是在SimpleExecutor中了: public List doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSQL boundSQL) throws SQLException { Statement stmt = null; List var9; try { Configuration configuration = ms.getConfiguration(); //来了,又是一个核心对象 StatementHandler handler = configuration.newStatementHandler(this.wrapper, ms, parameter, rowBounds, resultHandler, boundSQL); stmt = this.prepareStatement(handler, ms.getStatementLog()); var9 = handler.query(stmt, resultHandler); } finally { this.closeStatement(stmt); } return var9; } 在doQuery方法中根据Configuration创建了StatementHandler,它是SQL的处理器,看看Configuration是怎么创建它的: public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSQL boundSQL) { //RoutingStatementHandler StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSQL); //再次对插件进行了封装 StatementHandler statementHandler = (StatementHandler)this.interceptorChain.pluginAll(statementHandler); return statementHandler; } 上面最重要的创建RoutingStatementHandler那句代码,RoutingStatementHandler是个什么东西,看样子它是路由的StatementHandler,岂不是创建各种类型的StatementHandler: public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSQL boundSQL) { switch(ms.getStatementType()) { //普通的StatementHandler case STATEMENT: this.delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSQL); break; //预编译StatementHandler,也就是预编译的SQL case PREPARED: this.delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSQL); break; //CALLABLE类型的StatementHandler case CALLABLE: this.delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSQL); break; default: throw new ExecutorException(\"Unknown statement type: \" + ms.getStatementType()); } } 从RoutingStatementHandler的源码可知,它负责创建不同类型的SQL的StatementHandler. 那么创建完这个StatementHandler后,有啥用呢？ 回到doQuery方法: public List doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSQL boundSQL) throws SQLException { Statement stmt = null; List var9; try { Configuration configuration = ms.getConfiguration(); //创建StatementHandler StatementHandler handler = configuration.newStatementHandler(this.wrapper, ms, parameter, rowBounds, resultHandler, boundSQL); //预编译StatemenT stmt = this.prepareStatement(handler, ms.getStatementLog()); var9 = handler.query(stmt, resultHandler); } finally { this.closeStatement(stmt); } return var9; } 可以看到下面的一个 prepareStatement 方法直接预编译出来了一个Statement,Statement相信各位同学不陌生吧,java原生的SQL操作啊,由StatementHandler预编译成Statement这个方法肯定是做些事情的,到现在还没有设置参数呢,而且参数一直都随着那几颗方法： private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException { Connection connection = this.getConnection(statementLog); Statement stmt = handler.prepare(connection, this.transaction.getTimeout()); //设置参数 handler.parameterize(stmt); return stmt; } 看看parameterize是如何设置参数的吧: public void parameterize(Statement statement) throws SQLException { //ParameterHandler出来了,它时StatementHandler的一个属性,负责SQL的入参 this.parameterHandler.setParameters((PreparedStatement)statement); } 继续看看ParameterHandler是如何完成入参的吧： public void setParameters(PreparedStatement ps) { ErrorContext.instance().activity(\"setting parameters\").object(this.mappedStatement.getParameterMap().getId()); //从BoundSQL中获取ParameterMapping,也就是参数 List parameterMappings = this.boundSQL.getParameterMappings(); if (parameterMappings != null) { for(int i = 0; i 上面设置完参数后,回到doQuery方法,使用StatementHandler的query方法执行: public List query(Statement statement, ResultHandler resultHandler) throws SQLException { PreparedStatement ps = (PreparedStatement)statement; //执行 ps.execute(); //处理结果集 return this.resultSetHandler.handleResultSets(ps); } 最后看看ResultSetHandler是如何处理结果集的吧: public List handleResultSets(Statement stmt) throws SQLException { ErrorContext.instance().activity(\"handling results\").object(this.mappedStatement.getId()); List multipleResults = new ArrayList(); int resultSetCount = 0; //获取第一个结果集 ResultSetWrapper rsw = this.getFirstResultSet(stmt); List resultMaps = this.mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); this.validateResultMapsCount(rsw, resultMapCount); //一个resultMap对应一个结果集,不断遍历 while(rsw != null && resultMapCount > resultSetCount) { ResultMap resultMap = (ResultMap)resultMaps.get(resultSetCount); //处理结果集 this.handleResultSet(rsw, resultMap, multipleResults, (ResultMapping)null); //获取下一个结果集 rsw = this.getNextResultSet(stmt); this.cleanUpAfterHandlingResultSet(); ++resultSetCount; } String[] resultSets = this.mappedStatement.getResultSets(); if (resultSets != null) { while(rsw != null && resultSetCount 算是完成了对mybatis执行过程的一个简单的源码分析吧,由于我功力浅薄, 即使是分析出来了这么一个大致的运行流程,其中的大部分细节我仍然是不懂的,所以我会继续学习. mybatis源码总结 Mybatis最核心的对象莫过于Configuration了, Configuration在解析完配置文件和mapper文件后就一直流转于整个mybatis执行的生命周期内。 首先由Configuration创建出Executor,从而创建DefaultSQLSession, 又由Configuration内的MapperRegistry获取MapperProxy对象,执行SQL的时候, 也由Configuration创建StatementHandler,几乎可以说Configuration是无处不在。 然后说下Mybatis核心的组件:Executor。 负责调度StatementHandler。 StatementHandler负责调度ParameterHandler对Statement 进行参数处理,执行Statement调用ResultSetHandler对SQL执行的结果做出封装。 ParameterHandler负责Statement的参数处理, ResultSetHandler负责Statement执行后的结果集处理. 在分析mybatis源码的过程中,我觉得mybatis整个框架的设计和面向对象的思想是发挥的淋漓尽致的。 其实有很多人说mybatis不够智能化,但是我想说的是, Mybatis帮我们做掉这么多繁琐的事情,还能让我们灵活的掌握SQL，在设计上实属np。 听说Hibernate不需要写SQL,我没学过,不好妄下定论。 但是我觉得SQL本身就不属于Java语言这个范畴,如果连SQL都不需要写,是什么ORM框架,又怎么谈SQL优化呢? "}}